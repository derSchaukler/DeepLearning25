{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Cwq-uPYvpa"
      },
      "source": [
        "# Build basic 2-Layer MLP to solve the xor-Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "K4FDsqgaYvps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs #for data generatio\n",
        "from sklearn.model_selection import train_test_split #for test set generation\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "2x1wijYZYvpu"
      },
      "outputs": [],
      "source": [
        "X, y = make_blobs(n_samples=200, n_features=2, cluster_std=.1\n",
        "                  ,centers= [(1,1), (1,0), (0,0),(0,1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "aoAh4a4KYvpv"
      },
      "outputs": [],
      "source": [
        "#make blobs into binary problem\n",
        "y[y==2]=0\n",
        "y[y==3]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "RMPaCrKBYvpw",
        "outputId": "57d8606e-b1f2-4aa7-b7f9-c64aeabcaaf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7a8f04ef2d90>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.scatter(X[:,0],X[:,1],c=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q9Y4g0NYvpy"
      },
      "source": [
        "## Steps:\n",
        "* build train and test sets\n",
        "* write MLP class in Pytorch with two layers with adjustable number of perceptrons\n",
        "* use nn.linear and nn.Sigmoid() units\n",
        "* train your model\n",
        "* test your model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build MLP"
      ],
      "metadata": {
        "id": "nEDTWGzVE80b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbeOfPerceptrons = 2\n",
        "\n",
        "class MLP(torch.nn.Module): #all nets inherit from nn.Module\n",
        "    def __init__(self): #define layer types\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(2, numbeOfPerceptrons)  # First fully connected layer\n",
        "        self.activation1 = torch.nn.Sigmoid()  # Activation function for the first layer\n",
        "        self.fc2 = torch.nn.Linear(numbeOfPerceptrons, 1)  # Second fully connected layer\n",
        "        self.activation2 = torch.nn.Sigmoid()  # Activation function for the second layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.fc1(x)\n",
        "        output = self.activation1(output)\n",
        "        output = self.fc2(output)\n",
        "        output = self.activation2(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "piXsTVTrZssQ"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prepare training and test data"
      ],
      "metadata": {
        "id": "YLVKVz1NFVQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split in train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)#, random_state=42)\n",
        "\n",
        "#np->torch\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)"
      ],
      "metadata": {
        "id": "AWyOcaaaFSsQ"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get instance of model and set optimizer.  \n"
      ],
      "metadata": {
        "id": "WSEzlOf9FxsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get instance of perceptron model\n",
        "model = MLP()\n",
        "\n",
        "#define loss function\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "#define optimizer -> SGD with learning rate lr\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05)\n",
        "\n",
        "#run test data theogh untrained model\n",
        "model.eval() #set to eval mode\n",
        "model(X_test)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k1wySd6EFyEx",
        "outputId": "1440864a-8fc0-4007-ca86-b98571bacc88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3412],\n",
              "        [0.3470],\n",
              "        [0.3611],\n",
              "        [0.3617],\n",
              "        [0.3620],\n",
              "        [0.3426],\n",
              "        [0.3635],\n",
              "        [0.3607],\n",
              "        [0.3631],\n",
              "        [0.3483],\n",
              "        [0.3612],\n",
              "        [0.3603],\n",
              "        [0.3640],\n",
              "        [0.3462],\n",
              "        [0.3480],\n",
              "        [0.3482],\n",
              "        [0.3490],\n",
              "        [0.3621],\n",
              "        [0.3484],\n",
              "        [0.3619],\n",
              "        [0.3455],\n",
              "        [0.3473],\n",
              "        [0.3593],\n",
              "        [0.3492],\n",
              "        [0.3617],\n",
              "        [0.3466],\n",
              "        [0.3415],\n",
              "        [0.3612],\n",
              "        [0.3593],\n",
              "        [0.3472],\n",
              "        [0.3475],\n",
              "        [0.3460],\n",
              "        [0.3625],\n",
              "        [0.3494],\n",
              "        [0.3600],\n",
              "        [0.3485],\n",
              "        [0.3451],\n",
              "        [0.3431],\n",
              "        [0.3617],\n",
              "        [0.3476],\n",
              "        [0.3608],\n",
              "        [0.3467],\n",
              "        [0.3487],\n",
              "        [0.3641],\n",
              "        [0.3468],\n",
              "        [0.3472],\n",
              "        [0.3496],\n",
              "        [0.3622],\n",
              "        [0.3593],\n",
              "        [0.3492],\n",
              "        [0.3482],\n",
              "        [0.3467],\n",
              "        [0.3467],\n",
              "        [0.3449],\n",
              "        [0.3478],\n",
              "        [0.3447],\n",
              "        [0.3628],\n",
              "        [0.3622],\n",
              "        [0.3622],\n",
              "        [0.3603],\n",
              "        [0.3472],\n",
              "        [0.3469],\n",
              "        [0.3637],\n",
              "        [0.3616],\n",
              "        [0.3627],\n",
              "        [0.3593]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train\n"
      ],
      "metadata": {
        "id": "2_vlzoODIfyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() #set to train mode\n",
        "epoch = 50000\n",
        "for epoch in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(X_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    #make gradient update\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "WrdqX5UOI5nx",
        "outputId": "f4ef127d-c092-4a4c-9d0b-6b4513eb44ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "Epoch 4520: train loss: 0.6641550660133362\n",
            "Epoch 4521: train loss: 0.6641274094581604\n",
            "Epoch 4522: train loss: 0.6640998125076294\n",
            "Epoch 4523: train loss: 0.6640719771385193\n",
            "Epoch 4524: train loss: 0.6640442609786987\n",
            "Epoch 4525: train loss: 0.6640164852142334\n",
            "Epoch 4526: train loss: 0.6639887094497681\n",
            "Epoch 4527: train loss: 0.6639609932899475\n",
            "Epoch 4528: train loss: 0.6639331579208374\n",
            "Epoch 4529: train loss: 0.6639053225517273\n",
            "Epoch 4530: train loss: 0.6638774275779724\n",
            "Epoch 4531: train loss: 0.6638495326042175\n",
            "Epoch 4532: train loss: 0.6638216376304626\n",
            "Epoch 4533: train loss: 0.663793683052063\n",
            "Epoch 4534: train loss: 0.6637657880783081\n",
            "Epoch 4535: train loss: 0.6637377142906189\n",
            "Epoch 4536: train loss: 0.663709819316864\n",
            "Epoch 4537: train loss: 0.6636817455291748\n",
            "Epoch 4538: train loss: 0.6636537909507751\n",
            "Epoch 4539: train loss: 0.6636257171630859\n",
            "Epoch 4540: train loss: 0.6635977029800415\n",
            "Epoch 4541: train loss: 0.6635696291923523\n",
            "Epoch 4542: train loss: 0.6635414361953735\n",
            "Epoch 4543: train loss: 0.6635133028030396\n",
            "Epoch 4544: train loss: 0.6634851694107056\n",
            "Epoch 4545: train loss: 0.6634570360183716\n",
            "Epoch 4546: train loss: 0.663428783416748\n",
            "Epoch 4547: train loss: 0.6634005308151245\n",
            "Epoch 4548: train loss: 0.6633723378181458\n",
            "Epoch 4549: train loss: 0.6633440256118774\n",
            "Epoch 4550: train loss: 0.6633157134056091\n",
            "Epoch 4551: train loss: 0.6632874608039856\n",
            "Epoch 4552: train loss: 0.6632591485977173\n",
            "Epoch 4553: train loss: 0.6632307767868042\n",
            "Epoch 4554: train loss: 0.6632024049758911\n",
            "Epoch 4555: train loss: 0.663174033164978\n",
            "Epoch 4556: train loss: 0.6631456017494202\n",
            "Epoch 4557: train loss: 0.6631171703338623\n",
            "Epoch 4558: train loss: 0.6630887389183044\n",
            "Epoch 4559: train loss: 0.663060188293457\n",
            "Epoch 4560: train loss: 0.663031816482544\n",
            "Epoch 4561: train loss: 0.6630032062530518\n",
            "Epoch 4562: train loss: 0.6629747152328491\n",
            "Epoch 4563: train loss: 0.6629461050033569\n",
            "Epoch 4564: train loss: 0.6629175543785095\n",
            "Epoch 4565: train loss: 0.6628888845443726\n",
            "Epoch 4566: train loss: 0.6628603339195251\n",
            "Epoch 4567: train loss: 0.662831723690033\n",
            "Epoch 4568: train loss: 0.6628029942512512\n",
            "Epoch 4569: train loss: 0.6627742648124695\n",
            "Epoch 4570: train loss: 0.6627455949783325\n",
            "Epoch 4571: train loss: 0.6627168655395508\n",
            "Epoch 4572: train loss: 0.6626881957054138\n",
            "Epoch 4573: train loss: 0.6626593470573425\n",
            "Epoch 4574: train loss: 0.662630558013916\n",
            "Epoch 4575: train loss: 0.6626017093658447\n",
            "Epoch 4576: train loss: 0.6625728607177734\n",
            "Epoch 4577: train loss: 0.6625439524650574\n",
            "Epoch 4578: train loss: 0.6625151634216309\n",
            "Epoch 4579: train loss: 0.6624862551689148\n",
            "Epoch 4580: train loss: 0.6624573469161987\n",
            "Epoch 4581: train loss: 0.6624283790588379\n",
            "Epoch 4582: train loss: 0.6623993515968323\n",
            "Epoch 4583: train loss: 0.6623703837394714\n",
            "Epoch 4584: train loss: 0.6623414158821106\n",
            "Epoch 4585: train loss: 0.662312388420105\n",
            "Epoch 4586: train loss: 0.6622833609580994\n",
            "Epoch 4587: train loss: 0.6622542142868042\n",
            "Epoch 4588: train loss: 0.6622251272201538\n",
            "Epoch 4589: train loss: 0.6621960997581482\n",
            "Epoch 4590: train loss: 0.662166953086853\n",
            "Epoch 4591: train loss: 0.6621378064155579\n",
            "Epoch 4592: train loss: 0.6621086001396179\n",
            "Epoch 4593: train loss: 0.6620794534683228\n",
            "Epoch 4594: train loss: 0.6620502471923828\n",
            "Epoch 4595: train loss: 0.6620209217071533\n",
            "Epoch 4596: train loss: 0.6619916558265686\n",
            "Epoch 4597: train loss: 0.6619623899459839\n",
            "Epoch 4598: train loss: 0.6619331240653992\n",
            "Epoch 4599: train loss: 0.6619037389755249\n",
            "Epoch 4600: train loss: 0.6618744134902954\n",
            "Epoch 4601: train loss: 0.6618449687957764\n",
            "Epoch 4602: train loss: 0.6618155837059021\n",
            "Epoch 4603: train loss: 0.6617862582206726\n",
            "Epoch 4604: train loss: 0.6617567539215088\n",
            "Epoch 4605: train loss: 0.6617273092269897\n",
            "Epoch 4606: train loss: 0.6616978645324707\n",
            "Epoch 4607: train loss: 0.6616682410240173\n",
            "Epoch 4608: train loss: 0.6616387367248535\n",
            "Epoch 4609: train loss: 0.6616092920303345\n",
            "Epoch 4610: train loss: 0.6615797281265259\n",
            "Epoch 4611: train loss: 0.6615501642227173\n",
            "Epoch 4612: train loss: 0.6615204811096191\n",
            "Epoch 4613: train loss: 0.661490797996521\n",
            "Epoch 4614: train loss: 0.6614611744880676\n",
            "Epoch 4615: train loss: 0.6614315509796143\n",
            "Epoch 4616: train loss: 0.6614018082618713\n",
            "Epoch 4617: train loss: 0.6613721251487732\n",
            "Epoch 4618: train loss: 0.6613423824310303\n",
            "Epoch 4619: train loss: 0.6613126397132874\n",
            "Epoch 4620: train loss: 0.6612828969955444\n",
            "Epoch 4621: train loss: 0.661253035068512\n",
            "Epoch 4622: train loss: 0.6612232327461243\n",
            "Epoch 4623: train loss: 0.6611934304237366\n",
            "Epoch 4624: train loss: 0.6611635684967041\n",
            "Epoch 4625: train loss: 0.6611335873603821\n",
            "Epoch 4626: train loss: 0.6611037254333496\n",
            "Epoch 4627: train loss: 0.6610738039016724\n",
            "Epoch 4628: train loss: 0.6610438823699951\n",
            "Epoch 4629: train loss: 0.6610139012336731\n",
            "Epoch 4630: train loss: 0.6609839200973511\n",
            "Epoch 4631: train loss: 0.660953938961029\n",
            "Epoch 4632: train loss: 0.6609237790107727\n",
            "Epoch 4633: train loss: 0.6608937978744507\n",
            "Epoch 4634: train loss: 0.6608637571334839\n",
            "Epoch 4635: train loss: 0.6608335375785828\n",
            "Epoch 4636: train loss: 0.660803496837616\n",
            "Epoch 4637: train loss: 0.6607733368873596\n",
            "Epoch 4638: train loss: 0.6607431769371033\n",
            "Epoch 4639: train loss: 0.6607129573822021\n",
            "Epoch 4640: train loss: 0.6606827974319458\n",
            "Epoch 4641: train loss: 0.6606525182723999\n",
            "Epoch 4642: train loss: 0.6606222987174988\n",
            "Epoch 4643: train loss: 0.6605920195579529\n",
            "Epoch 4644: train loss: 0.660561740398407\n",
            "Epoch 4645: train loss: 0.6605314016342163\n",
            "Epoch 4646: train loss: 0.6605010628700256\n",
            "Epoch 4647: train loss: 0.6604707837104797\n",
            "Epoch 4648: train loss: 0.6604403853416443\n",
            "Epoch 4649: train loss: 0.6604099273681641\n",
            "Epoch 4650: train loss: 0.6603795289993286\n",
            "Epoch 4651: train loss: 0.6603491306304932\n",
            "Epoch 4652: train loss: 0.6603186130523682\n",
            "Epoch 4653: train loss: 0.6602881550788879\n",
            "Epoch 4654: train loss: 0.6602576971054077\n",
            "Epoch 4655: train loss: 0.6602271199226379\n",
            "Epoch 4656: train loss: 0.6601965427398682\n",
            "Epoch 4657: train loss: 0.6601660251617432\n",
            "Epoch 4658: train loss: 0.6601353883743286\n",
            "Epoch 4659: train loss: 0.6601047515869141\n",
            "Epoch 4660: train loss: 0.6600741147994995\n",
            "Epoch 4661: train loss: 0.660043478012085\n",
            "Epoch 4662: train loss: 0.6600127816200256\n",
            "Epoch 4663: train loss: 0.6599821448326111\n",
            "Epoch 4664: train loss: 0.659951388835907\n",
            "Epoch 4665: train loss: 0.6599206328392029\n",
            "Epoch 4666: train loss: 0.6598898768424988\n",
            "Epoch 4667: train loss: 0.6598591208457947\n",
            "Epoch 4668: train loss: 0.6598283052444458\n",
            "Epoch 4669: train loss: 0.6597974300384521\n",
            "Epoch 4670: train loss: 0.659766674041748\n",
            "Epoch 4671: train loss: 0.6597357988357544\n",
            "Epoch 4672: train loss: 0.659704864025116\n",
            "Epoch 4673: train loss: 0.6596739292144775\n",
            "Epoch 4674: train loss: 0.6596429944038391\n",
            "Epoch 4675: train loss: 0.6596120595932007\n",
            "Epoch 4676: train loss: 0.6595810651779175\n",
            "Epoch 4677: train loss: 0.659550130367279\n",
            "Epoch 4678: train loss: 0.6595190763473511\n",
            "Epoch 4679: train loss: 0.6594880223274231\n",
            "Epoch 4680: train loss: 0.6594569683074951\n",
            "Epoch 4681: train loss: 0.6594258546829224\n",
            "Epoch 4682: train loss: 0.6593948006629944\n",
            "Epoch 4683: train loss: 0.6593636274337769\n",
            "Epoch 4684: train loss: 0.6593325138092041\n",
            "Epoch 4685: train loss: 0.6593012809753418\n",
            "Epoch 4686: train loss: 0.6592701077461243\n",
            "Epoch 4687: train loss: 0.6592388153076172\n",
            "Epoch 4688: train loss: 0.6592077016830444\n",
            "Epoch 4689: train loss: 0.6591765284538269\n",
            "Epoch 4690: train loss: 0.6591451168060303\n",
            "Epoch 4691: train loss: 0.6591138243675232\n",
            "Epoch 4692: train loss: 0.6590825319290161\n",
            "Epoch 4693: train loss: 0.6590511798858643\n",
            "Epoch 4694: train loss: 0.6590198874473572\n",
            "Epoch 4695: train loss: 0.6589884161949158\n",
            "Epoch 4696: train loss: 0.6589570641517639\n",
            "Epoch 4697: train loss: 0.6589256525039673\n",
            "Epoch 4698: train loss: 0.6588941812515259\n",
            "Epoch 4699: train loss: 0.6588626503944397\n",
            "Epoch 4700: train loss: 0.6588311791419983\n",
            "Epoch 4701: train loss: 0.6587996482849121\n",
            "Epoch 4702: train loss: 0.6587681174278259\n",
            "Epoch 4703: train loss: 0.6587365865707397\n",
            "Epoch 4704: train loss: 0.6587049961090088\n",
            "Epoch 4705: train loss: 0.6586734056472778\n",
            "Epoch 4706: train loss: 0.6586417555809021\n",
            "Epoch 4707: train loss: 0.6586102247238159\n",
            "Epoch 4708: train loss: 0.6585785150527954\n",
            "Epoch 4709: train loss: 0.6585468649864197\n",
            "Epoch 4710: train loss: 0.6585151553153992\n",
            "Epoch 4711: train loss: 0.6584833860397339\n",
            "Epoch 4712: train loss: 0.6584516167640686\n",
            "Epoch 4713: train loss: 0.6584199070930481\n",
            "Epoch 4714: train loss: 0.6583881378173828\n",
            "Epoch 4715: train loss: 0.6583563089370728\n",
            "Epoch 4716: train loss: 0.6583244800567627\n",
            "Epoch 4717: train loss: 0.6582926511764526\n",
            "Epoch 4718: train loss: 0.6582607626914978\n",
            "Epoch 4719: train loss: 0.6582288146018982\n",
            "Epoch 4720: train loss: 0.6581969261169434\n",
            "Epoch 4721: train loss: 0.658164918422699\n",
            "Epoch 4722: train loss: 0.6581330299377441\n",
            "Epoch 4723: train loss: 0.6581010222434998\n",
            "Epoch 4724: train loss: 0.6580690145492554\n",
            "Epoch 4725: train loss: 0.658037006855011\n",
            "Epoch 4726: train loss: 0.6580049395561218\n",
            "Epoch 4727: train loss: 0.6579728722572327\n",
            "Epoch 4728: train loss: 0.6579407453536987\n",
            "Epoch 4729: train loss: 0.6579087376594543\n",
            "Epoch 4730: train loss: 0.6578765511512756\n",
            "Epoch 4731: train loss: 0.6578444242477417\n",
            "Epoch 4732: train loss: 0.6578121781349182\n",
            "Epoch 4733: train loss: 0.6577800512313843\n",
            "Epoch 4734: train loss: 0.657747745513916\n",
            "Epoch 4735: train loss: 0.6577155590057373\n",
            "Epoch 4736: train loss: 0.6576833128929138\n",
            "Epoch 4737: train loss: 0.6576510667800903\n",
            "Epoch 4738: train loss: 0.6576187610626221\n",
            "Epoch 4739: train loss: 0.657586395740509\n",
            "Epoch 4740: train loss: 0.6575539708137512\n",
            "Epoch 4741: train loss: 0.6575217247009277\n",
            "Epoch 4742: train loss: 0.6574892401695251\n",
            "Epoch 4743: train loss: 0.6574569344520569\n",
            "Epoch 4744: train loss: 0.6574244499206543\n",
            "Epoch 4745: train loss: 0.6573920249938965\n",
            "Epoch 4746: train loss: 0.6573595404624939\n",
            "Epoch 4747: train loss: 0.6573270559310913\n",
            "Epoch 4748: train loss: 0.6572945713996887\n",
            "Epoch 4749: train loss: 0.6572619676589966\n",
            "Epoch 4750: train loss: 0.657229483127594\n",
            "Epoch 4751: train loss: 0.6571968793869019\n",
            "Epoch 4752: train loss: 0.6571642756462097\n",
            "Epoch 4753: train loss: 0.6571316719055176\n",
            "Epoch 4754: train loss: 0.6570990085601807\n",
            "Epoch 4755: train loss: 0.6570663452148438\n",
            "Epoch 4756: train loss: 0.6570336818695068\n",
            "Epoch 4757: train loss: 0.6570009589195251\n",
            "Epoch 4758: train loss: 0.6569682359695435\n",
            "Epoch 4759: train loss: 0.6569355130195618\n",
            "Epoch 4760: train loss: 0.6569027304649353\n",
            "Epoch 4761: train loss: 0.6568698883056641\n",
            "Epoch 4762: train loss: 0.6568371057510376\n",
            "Epoch 4763: train loss: 0.6568043231964111\n",
            "Epoch 4764: train loss: 0.6567714214324951\n",
            "Epoch 4765: train loss: 0.6567386388778687\n",
            "Epoch 4766: train loss: 0.6567056775093079\n",
            "Epoch 4767: train loss: 0.6566727161407471\n",
            "Epoch 4768: train loss: 0.6566397547721863\n",
            "Epoch 4769: train loss: 0.6566068530082703\n",
            "Epoch 4770: train loss: 0.6565738320350647\n",
            "Epoch 4771: train loss: 0.6565408110618591\n",
            "Epoch 4772: train loss: 0.6565078496932983\n",
            "Epoch 4773: train loss: 0.6564748883247375\n",
            "Epoch 4774: train loss: 0.6564417481422424\n",
            "Epoch 4775: train loss: 0.6564086675643921\n",
            "Epoch 4776: train loss: 0.6563755869865417\n",
            "Epoch 4777: train loss: 0.6563424468040466\n",
            "Epoch 4778: train loss: 0.6563093066215515\n",
            "Epoch 4779: train loss: 0.6562761068344116\n",
            "Epoch 4780: train loss: 0.6562429666519165\n",
            "Epoch 4781: train loss: 0.6562097668647766\n",
            "Epoch 4782: train loss: 0.6561765074729919\n",
            "Epoch 4783: train loss: 0.6561432480812073\n",
            "Epoch 4784: train loss: 0.6561099290847778\n",
            "Epoch 4785: train loss: 0.6560766696929932\n",
            "Epoch 4786: train loss: 0.6560433506965637\n",
            "Epoch 4787: train loss: 0.656010091304779\n",
            "Epoch 4788: train loss: 0.6559765934944153\n",
            "Epoch 4789: train loss: 0.6559432148933411\n",
            "Epoch 4790: train loss: 0.6559098958969116\n",
            "Epoch 4791: train loss: 0.6558764576911926\n",
            "Epoch 4792: train loss: 0.6558430194854736\n",
            "Epoch 4793: train loss: 0.6558095216751099\n",
            "Epoch 4794: train loss: 0.6557760834693909\n",
            "Epoch 4795: train loss: 0.6557425856590271\n",
            "Epoch 4796: train loss: 0.6557089686393738\n",
            "Epoch 4797: train loss: 0.6556755304336548\n",
            "Epoch 4798: train loss: 0.6556419134140015\n",
            "Epoch 4799: train loss: 0.6556083559989929\n",
            "Epoch 4800: train loss: 0.6555746793746948\n",
            "Epoch 4801: train loss: 0.6555411219596863\n",
            "Epoch 4802: train loss: 0.6555074453353882\n",
            "Epoch 4803: train loss: 0.6554737091064453\n",
            "Epoch 4804: train loss: 0.6554400324821472\n",
            "Epoch 4805: train loss: 0.6554063558578491\n",
            "Epoch 4806: train loss: 0.6553725600242615\n",
            "Epoch 4807: train loss: 0.6553389430046082\n",
            "Epoch 4808: train loss: 0.6553051471710205\n",
            "Epoch 4809: train loss: 0.6552712917327881\n",
            "Epoch 4810: train loss: 0.6552374958992004\n",
            "Epoch 4811: train loss: 0.6552037000656128\n",
            "Epoch 4812: train loss: 0.6551697850227356\n",
            "Epoch 4813: train loss: 0.6551359295845032\n",
            "Epoch 4814: train loss: 0.655102014541626\n",
            "Epoch 4815: train loss: 0.6550680994987488\n",
            "Epoch 4816: train loss: 0.6550341844558716\n",
            "Epoch 4817: train loss: 0.6550001502037048\n",
            "Epoch 4818: train loss: 0.6549661755561829\n",
            "Epoch 4819: train loss: 0.6549322009086609\n",
            "Epoch 4820: train loss: 0.6548981070518494\n",
            "Epoch 4821: train loss: 0.6548640727996826\n",
            "Epoch 4822: train loss: 0.6548300385475159\n",
            "Epoch 4823: train loss: 0.6547959446907043\n",
            "Epoch 4824: train loss: 0.6547618508338928\n",
            "Epoch 4825: train loss: 0.6547277569770813\n",
            "Epoch 4826: train loss: 0.6546935439109802\n",
            "Epoch 4827: train loss: 0.6546593308448792\n",
            "Epoch 4828: train loss: 0.6546252369880676\n",
            "Epoch 4829: train loss: 0.6545909643173218\n",
            "Epoch 4830: train loss: 0.6545566916465759\n",
            "Epoch 4831: train loss: 0.6545224785804749\n",
            "Epoch 4832: train loss: 0.6544882655143738\n",
            "Epoch 4833: train loss: 0.6544538736343384\n",
            "Epoch 4834: train loss: 0.6544196009635925\n",
            "Epoch 4835: train loss: 0.6543852090835571\n",
            "Epoch 4836: train loss: 0.6543508768081665\n",
            "Epoch 4837: train loss: 0.6543166041374207\n",
            "Epoch 4838: train loss: 0.6542820930480957\n",
            "Epoch 4839: train loss: 0.6542477011680603\n",
            "Epoch 4840: train loss: 0.6542131900787354\n",
            "Epoch 4841: train loss: 0.6541787981987\n",
            "Epoch 4842: train loss: 0.654144287109375\n",
            "Epoch 4843: train loss: 0.65410977602005\n",
            "Epoch 4844: train loss: 0.6540752053260803\n",
            "Epoch 4845: train loss: 0.6540406346321106\n",
            "Epoch 4846: train loss: 0.6540061831474304\n",
            "Epoch 4847: train loss: 0.6539715528488159\n",
            "Epoch 4848: train loss: 0.6539369225502014\n",
            "Epoch 4849: train loss: 0.6539022326469421\n",
            "Epoch 4850: train loss: 0.6538677215576172\n",
            "Epoch 4851: train loss: 0.6538330316543579\n",
            "Epoch 4852: train loss: 0.6537983417510986\n",
            "Epoch 4853: train loss: 0.6537635922431946\n",
            "Epoch 4854: train loss: 0.6537289023399353\n",
            "Epoch 4855: train loss: 0.6536940932273865\n",
            "Epoch 4856: train loss: 0.6536593437194824\n",
            "Epoch 4857: train loss: 0.6536245942115784\n",
            "Epoch 4858: train loss: 0.6535897254943848\n",
            "Epoch 4859: train loss: 0.6535549163818359\n",
            "Epoch 4860: train loss: 0.6535200476646423\n",
            "Epoch 4861: train loss: 0.6534852385520935\n",
            "Epoch 4862: train loss: 0.6534503102302551\n",
            "Epoch 4863: train loss: 0.653415322303772\n",
            "Epoch 4864: train loss: 0.6533804535865784\n",
            "Epoch 4865: train loss: 0.6533454656600952\n",
            "Epoch 4866: train loss: 0.6533104777336121\n",
            "Epoch 4867: train loss: 0.6532754302024841\n",
            "Epoch 4868: train loss: 0.6532405018806458\n",
            "Epoch 4869: train loss: 0.6532054543495178\n",
            "Epoch 4870: train loss: 0.6531704068183899\n",
            "Epoch 4871: train loss: 0.6531352996826172\n",
            "Epoch 4872: train loss: 0.6531002521514893\n",
            "Epoch 4873: train loss: 0.6530651450157166\n",
            "Epoch 4874: train loss: 0.6530299186706543\n",
            "Epoch 4875: train loss: 0.6529948115348816\n",
            "Epoch 4876: train loss: 0.6529596447944641\n",
            "Epoch 4877: train loss: 0.6529243588447571\n",
            "Epoch 4878: train loss: 0.6528892517089844\n",
            "Epoch 4879: train loss: 0.6528539657592773\n",
            "Epoch 4880: train loss: 0.6528186798095703\n",
            "Epoch 4881: train loss: 0.6527833938598633\n",
            "Epoch 4882: train loss: 0.6527481079101562\n",
            "Epoch 4883: train loss: 0.6527128219604492\n",
            "Epoch 4884: train loss: 0.6526774764060974\n",
            "Epoch 4885: train loss: 0.652642011642456\n",
            "Epoch 4886: train loss: 0.6526066064834595\n",
            "Epoch 4887: train loss: 0.6525712609291077\n",
            "Epoch 4888: train loss: 0.6525359749794006\n",
            "Epoch 4889: train loss: 0.6525005102157593\n",
            "Epoch 4890: train loss: 0.6524649858474731\n",
            "Epoch 4891: train loss: 0.6524295210838318\n",
            "Epoch 4892: train loss: 0.6523940563201904\n",
            "Epoch 4893: train loss: 0.6523584723472595\n",
            "Epoch 4894: train loss: 0.6523228883743286\n",
            "Epoch 4895: train loss: 0.6522873044013977\n",
            "Epoch 4896: train loss: 0.6522517800331116\n",
            "Epoch 4897: train loss: 0.6522161960601807\n",
            "Epoch 4898: train loss: 0.6521806120872498\n",
            "Epoch 4899: train loss: 0.6521449089050293\n",
            "Epoch 4900: train loss: 0.6521092057228088\n",
            "Epoch 4901: train loss: 0.6520735621452332\n",
            "Epoch 4902: train loss: 0.6520378589630127\n",
            "Epoch 4903: train loss: 0.6520021557807922\n",
            "Epoch 4904: train loss: 0.651966392993927\n",
            "Epoch 4905: train loss: 0.651930570602417\n",
            "Epoch 4906: train loss: 0.651894748210907\n",
            "Epoch 4907: train loss: 0.6518589854240417\n",
            "Epoch 4908: train loss: 0.6518232226371765\n",
            "Epoch 4909: train loss: 0.6517873406410217\n",
            "Epoch 4910: train loss: 0.6517515182495117\n",
            "Epoch 4911: train loss: 0.6517155766487122\n",
            "Epoch 4912: train loss: 0.6516796946525574\n",
            "Epoch 4913: train loss: 0.6516437530517578\n",
            "Epoch 4914: train loss: 0.6516078114509583\n",
            "Epoch 4915: train loss: 0.6515719890594482\n",
            "Epoch 4916: train loss: 0.6515358686447144\n",
            "Epoch 4917: train loss: 0.6514999866485596\n",
            "Epoch 4918: train loss: 0.6514638662338257\n",
            "Epoch 4919: train loss: 0.6514277458190918\n",
            "Epoch 4920: train loss: 0.6513918042182922\n",
            "Epoch 4921: train loss: 0.6513556838035583\n",
            "Epoch 4922: train loss: 0.6513195037841797\n",
            "Epoch 4923: train loss: 0.6512833833694458\n",
            "Epoch 4924: train loss: 0.6512473225593567\n",
            "Epoch 4925: train loss: 0.6512112021446228\n",
            "Epoch 4926: train loss: 0.6511748433113098\n",
            "Epoch 4927: train loss: 0.6511387825012207\n",
            "Epoch 4928: train loss: 0.6511025428771973\n",
            "Epoch 4929: train loss: 0.6510663032531738\n",
            "Epoch 4930: train loss: 0.6510300040245056\n",
            "Epoch 4931: train loss: 0.6509937644004822\n",
            "Epoch 4932: train loss: 0.650957465171814\n",
            "Epoch 4933: train loss: 0.650921106338501\n",
            "Epoch 4934: train loss: 0.6508848071098328\n",
            "Epoch 4935: train loss: 0.6508484482765198\n",
            "Epoch 4936: train loss: 0.650812029838562\n",
            "Epoch 4937: train loss: 0.6507756114006042\n",
            "Epoch 4938: train loss: 0.6507392525672913\n",
            "Epoch 4939: train loss: 0.6507027745246887\n",
            "Epoch 4940: train loss: 0.6506662964820862\n",
            "Epoch 4941: train loss: 0.6506298184394836\n",
            "Epoch 4942: train loss: 0.6505933403968811\n",
            "Epoch 4943: train loss: 0.6505568623542786\n",
            "Epoch 4944: train loss: 0.6505202054977417\n",
            "Epoch 4945: train loss: 0.6504837870597839\n",
            "Epoch 4946: train loss: 0.6504471302032471\n",
            "Epoch 4947: train loss: 0.6504104733467102\n",
            "Epoch 4948: train loss: 0.6503738760948181\n",
            "Epoch 4949: train loss: 0.6503373384475708\n",
            "Epoch 4950: train loss: 0.6503006815910339\n",
            "Epoch 4951: train loss: 0.6502640247344971\n",
            "Epoch 4952: train loss: 0.6502273082733154\n",
            "Epoch 4953: train loss: 0.650190532207489\n",
            "Epoch 4954: train loss: 0.6501538157463074\n",
            "Epoch 4955: train loss: 0.6501170992851257\n",
            "Epoch 4956: train loss: 0.6500802636146545\n",
            "Epoch 4957: train loss: 0.6500435471534729\n",
            "Epoch 4958: train loss: 0.6500067710876465\n",
            "Epoch 4959: train loss: 0.6499699354171753\n",
            "Epoch 4960: train loss: 0.6499330401420593\n",
            "Epoch 4961: train loss: 0.6498962044715881\n",
            "Epoch 4962: train loss: 0.6498593688011169\n",
            "Epoch 4963: train loss: 0.649822473526001\n",
            "Epoch 4964: train loss: 0.6497855186462402\n",
            "Epoch 4965: train loss: 0.6497485041618347\n",
            "Epoch 4966: train loss: 0.649711549282074\n",
            "Epoch 4967: train loss: 0.6496745944023132\n",
            "Epoch 4968: train loss: 0.6496375799179077\n",
            "Epoch 4969: train loss: 0.6496005654335022\n",
            "Epoch 4970: train loss: 0.6495635509490967\n",
            "Epoch 4971: train loss: 0.6495265364646912\n",
            "Epoch 4972: train loss: 0.6494893431663513\n",
            "Epoch 4973: train loss: 0.6494523286819458\n",
            "Epoch 4974: train loss: 0.6494151949882507\n",
            "Epoch 4975: train loss: 0.6493780016899109\n",
            "Epoch 4976: train loss: 0.6493409276008606\n",
            "Epoch 4977: train loss: 0.6493037343025208\n",
            "Epoch 4978: train loss: 0.6492666006088257\n",
            "Epoch 4979: train loss: 0.6492293477058411\n",
            "Epoch 4980: train loss: 0.6491921544075012\n",
            "Epoch 4981: train loss: 0.6491548418998718\n",
            "Epoch 4982: train loss: 0.6491175889968872\n",
            "Epoch 4983: train loss: 0.6490803360939026\n",
            "Epoch 4984: train loss: 0.649043083190918\n",
            "Epoch 4985: train loss: 0.649005651473999\n",
            "Epoch 4986: train loss: 0.6489683985710144\n",
            "Epoch 4987: train loss: 0.6489309668540955\n",
            "Epoch 4988: train loss: 0.6488935947418213\n",
            "Epoch 4989: train loss: 0.6488561630249023\n",
            "Epoch 4990: train loss: 0.648818850517273\n",
            "Epoch 4991: train loss: 0.648781418800354\n",
            "Epoch 4992: train loss: 0.6487438678741455\n",
            "Epoch 4993: train loss: 0.6487063765525818\n",
            "Epoch 4994: train loss: 0.6486688852310181\n",
            "Epoch 4995: train loss: 0.6486313939094543\n",
            "Epoch 4996: train loss: 0.6485938429832458\n",
            "Epoch 4997: train loss: 0.6485563516616821\n",
            "Epoch 4998: train loss: 0.6485187411308289\n",
            "Epoch 4999: train loss: 0.6484811305999756\n",
            "Epoch 5000: train loss: 0.6484435200691223\n",
            "Epoch 5001: train loss: 0.648405909538269\n",
            "Epoch 5002: train loss: 0.6483682990074158\n",
            "Epoch 5003: train loss: 0.6483306288719177\n",
            "Epoch 5004: train loss: 0.6482929587364197\n",
            "Epoch 5005: train loss: 0.6482551693916321\n",
            "Epoch 5006: train loss: 0.6482174396514893\n",
            "Epoch 5007: train loss: 0.648179829120636\n",
            "Epoch 5008: train loss: 0.6481420397758484\n",
            "Epoch 5009: train loss: 0.648104190826416\n",
            "Epoch 5010: train loss: 0.6480664014816284\n",
            "Epoch 5011: train loss: 0.6480286121368408\n",
            "Epoch 5012: train loss: 0.6479907631874084\n",
            "Epoch 5013: train loss: 0.6479529738426208\n",
            "Epoch 5014: train loss: 0.6479151248931885\n",
            "Epoch 5015: train loss: 0.6478772163391113\n",
            "Epoch 5016: train loss: 0.6478392481803894\n",
            "Epoch 5017: train loss: 0.6478012800216675\n",
            "Epoch 5018: train loss: 0.6477634906768799\n",
            "Epoch 5019: train loss: 0.6477254629135132\n",
            "Epoch 5020: train loss: 0.647687554359436\n",
            "Epoch 5021: train loss: 0.6476495265960693\n",
            "Epoch 5022: train loss: 0.6476114392280579\n",
            "Epoch 5023: train loss: 0.6475734710693359\n",
            "Epoch 5024: train loss: 0.6475353837013245\n",
            "Epoch 5025: train loss: 0.647497296333313\n",
            "Epoch 5026: train loss: 0.6474592089653015\n",
            "Epoch 5027: train loss: 0.6474210619926453\n",
            "Epoch 5028: train loss: 0.6473829746246338\n",
            "Epoch 5029: train loss: 0.6473448276519775\n",
            "Epoch 5030: train loss: 0.6473067402839661\n",
            "Epoch 5031: train loss: 0.647268533706665\n",
            "Epoch 5032: train loss: 0.647230327129364\n",
            "Epoch 5033: train loss: 0.647192120552063\n",
            "Epoch 5034: train loss: 0.647153913974762\n",
            "Epoch 5035: train loss: 0.6471157073974609\n",
            "Epoch 5036: train loss: 0.6470774412155151\n",
            "Epoch 5037: train loss: 0.6470390558242798\n",
            "Epoch 5038: train loss: 0.647000789642334\n",
            "Epoch 5039: train loss: 0.6469624042510986\n",
            "Epoch 5040: train loss: 0.6469240784645081\n",
            "Epoch 5041: train loss: 0.6468856930732727\n",
            "Epoch 5042: train loss: 0.6468474268913269\n",
            "Epoch 5043: train loss: 0.6468089818954468\n",
            "Epoch 5044: train loss: 0.6467705965042114\n",
            "Epoch 5045: train loss: 0.6467321515083313\n",
            "Epoch 5046: train loss: 0.6466936469078064\n",
            "Epoch 5047: train loss: 0.646655261516571\n",
            "Epoch 5048: train loss: 0.6466167569160461\n",
            "Epoch 5049: train loss: 0.6465781927108765\n",
            "Epoch 5050: train loss: 0.6465396881103516\n",
            "Epoch 5051: train loss: 0.6465012431144714\n",
            "Epoch 5052: train loss: 0.6464625597000122\n",
            "Epoch 5053: train loss: 0.6464239954948425\n",
            "Epoch 5054: train loss: 0.6463854312896729\n",
            "Epoch 5055: train loss: 0.6463467478752136\n",
            "Epoch 5056: train loss: 0.6463082432746887\n",
            "Epoch 5057: train loss: 0.6462695598602295\n",
            "Epoch 5058: train loss: 0.6462308168411255\n",
            "Epoch 5059: train loss: 0.646192193031311\n",
            "Epoch 5060: train loss: 0.6461535096168518\n",
            "Epoch 5061: train loss: 0.6461148262023926\n",
            "Epoch 5062: train loss: 0.6460760235786438\n",
            "Epoch 5063: train loss: 0.6460373401641846\n",
            "Epoch 5064: train loss: 0.6459985375404358\n",
            "Epoch 5065: train loss: 0.6459597945213318\n",
            "Epoch 5066: train loss: 0.6459209322929382\n",
            "Epoch 5067: train loss: 0.6458821892738342\n",
            "Epoch 5068: train loss: 0.6458433270454407\n",
            "Epoch 5069: train loss: 0.6458044052124023\n",
            "Epoch 5070: train loss: 0.6457656025886536\n",
            "Epoch 5071: train loss: 0.6457266807556152\n",
            "Epoch 5072: train loss: 0.6456877589225769\n",
            "Epoch 5073: train loss: 0.6456488370895386\n",
            "Epoch 5074: train loss: 0.645609974861145\n",
            "Epoch 5075: train loss: 0.6455709338188171\n",
            "Epoch 5076: train loss: 0.645531952381134\n",
            "Epoch 5077: train loss: 0.6454930305480957\n",
            "Epoch 5078: train loss: 0.645453929901123\n",
            "Epoch 5079: train loss: 0.6454148888587952\n",
            "Epoch 5080: train loss: 0.6453759074211121\n",
            "Epoch 5081: train loss: 0.6453367471694946\n",
            "Epoch 5082: train loss: 0.6452977061271667\n",
            "Epoch 5083: train loss: 0.6452586650848389\n",
            "Epoch 5084: train loss: 0.6452195048332214\n",
            "Epoch 5085: train loss: 0.6451804041862488\n",
            "Epoch 5086: train loss: 0.6451411843299866\n",
            "Epoch 5087: train loss: 0.6451020240783691\n",
            "Epoch 5088: train loss: 0.6450628638267517\n",
            "Epoch 5089: train loss: 0.645023763179779\n",
            "Epoch 5090: train loss: 0.6449844241142273\n",
            "Epoch 5091: train loss: 0.6449451446533203\n",
            "Epoch 5092: train loss: 0.6449059247970581\n",
            "Epoch 5093: train loss: 0.6448667049407959\n",
            "Epoch 5094: train loss: 0.6448273062705994\n",
            "Epoch 5095: train loss: 0.6447880268096924\n",
            "Epoch 5096: train loss: 0.6447488069534302\n",
            "Epoch 5097: train loss: 0.6447094082832336\n",
            "Epoch 5098: train loss: 0.6446701288223267\n",
            "Epoch 5099: train loss: 0.6446306705474854\n",
            "Epoch 5100: train loss: 0.6445913910865784\n",
            "Epoch 5101: train loss: 0.6445518732070923\n",
            "Epoch 5102: train loss: 0.6445125341415405\n",
            "Epoch 5103: train loss: 0.6444730758666992\n",
            "Epoch 5104: train loss: 0.6444336771965027\n",
            "Epoch 5105: train loss: 0.6443941593170166\n",
            "Epoch 5106: train loss: 0.6443546414375305\n",
            "Epoch 5107: train loss: 0.6443151831626892\n",
            "Epoch 5108: train loss: 0.6442755460739136\n",
            "Epoch 5109: train loss: 0.6442360877990723\n",
            "Epoch 5110: train loss: 0.6441964507102966\n",
            "Epoch 5111: train loss: 0.6441569328308105\n",
            "Epoch 5112: train loss: 0.6441173553466797\n",
            "Epoch 5113: train loss: 0.6440777778625488\n",
            "Epoch 5114: train loss: 0.644038200378418\n",
            "Epoch 5115: train loss: 0.6439985036849976\n",
            "Epoch 5116: train loss: 0.6439588069915771\n",
            "Epoch 5117: train loss: 0.6439191102981567\n",
            "Epoch 5118: train loss: 0.6438795328140259\n",
            "Epoch 5119: train loss: 0.6438397169113159\n",
            "Epoch 5120: train loss: 0.6438000798225403\n",
            "Epoch 5121: train loss: 0.6437602639198303\n",
            "Epoch 5122: train loss: 0.6437205076217651\n",
            "Epoch 5123: train loss: 0.6436807513237\n",
            "Epoch 5124: train loss: 0.6436409950256348\n",
            "Epoch 5125: train loss: 0.64360111951828\n",
            "Epoch 5126: train loss: 0.6435613036155701\n",
            "Epoch 5127: train loss: 0.6435215473175049\n",
            "Epoch 5128: train loss: 0.6434816122055054\n",
            "Epoch 5129: train loss: 0.6434417963027954\n",
            "Epoch 5130: train loss: 0.6434018611907959\n",
            "Epoch 5131: train loss: 0.6433620452880859\n",
            "Epoch 5132: train loss: 0.6433221101760864\n",
            "Epoch 5133: train loss: 0.6432821750640869\n",
            "Epoch 5134: train loss: 0.6432421803474426\n",
            "Epoch 5135: train loss: 0.6432021260261536\n",
            "Epoch 5136: train loss: 0.6431623101234436\n",
            "Epoch 5137: train loss: 0.6431222558021545\n",
            "Epoch 5138: train loss: 0.6430822014808655\n",
            "Epoch 5139: train loss: 0.6430422067642212\n",
            "Epoch 5140: train loss: 0.6430022120475769\n",
            "Epoch 5141: train loss: 0.6429620981216431\n",
            "Epoch 5142: train loss: 0.642922043800354\n",
            "Epoch 5143: train loss: 0.6428819298744202\n",
            "Epoch 5144: train loss: 0.6428417563438416\n",
            "Epoch 5145: train loss: 0.6428016424179077\n",
            "Epoch 5146: train loss: 0.6427615880966187\n",
            "Epoch 5147: train loss: 0.6427213549613953\n",
            "Epoch 5148: train loss: 0.6426812410354614\n",
            "Epoch 5149: train loss: 0.6426410675048828\n",
            "Epoch 5150: train loss: 0.6426007747650146\n",
            "Epoch 5151: train loss: 0.642560601234436\n",
            "Epoch 5152: train loss: 0.6425202488899231\n",
            "Epoch 5153: train loss: 0.6424800753593445\n",
            "Epoch 5154: train loss: 0.6424399018287659\n",
            "Epoch 5155: train loss: 0.6423996090888977\n",
            "Epoch 5156: train loss: 0.6423592567443848\n",
            "Epoch 5157: train loss: 0.6423189640045166\n",
            "Epoch 5158: train loss: 0.6422786116600037\n",
            "Epoch 5159: train loss: 0.642238199710846\n",
            "Epoch 5160: train loss: 0.6421979069709778\n",
            "Epoch 5161: train loss: 0.6421575546264648\n",
            "Epoch 5162: train loss: 0.6421171426773071\n",
            "Epoch 5163: train loss: 0.6420767307281494\n",
            "Epoch 5164: train loss: 0.6420362591743469\n",
            "Epoch 5165: train loss: 0.6419957876205444\n",
            "Epoch 5166: train loss: 0.6419554948806763\n",
            "Epoch 5167: train loss: 0.6419149041175842\n",
            "Epoch 5168: train loss: 0.641874372959137\n",
            "Epoch 5169: train loss: 0.6418339610099792\n",
            "Epoch 5170: train loss: 0.641793429851532\n",
            "Epoch 5171: train loss: 0.6417528986930847\n",
            "Epoch 5172: train loss: 0.6417123675346375\n",
            "Epoch 5173: train loss: 0.6416717171669006\n",
            "Epoch 5174: train loss: 0.6416313052177429\n",
            "Epoch 5175: train loss: 0.6415907144546509\n",
            "Epoch 5176: train loss: 0.6415500640869141\n",
            "Epoch 5177: train loss: 0.6415094137191772\n",
            "Epoch 5178: train loss: 0.6414687633514404\n",
            "Epoch 5179: train loss: 0.6414280533790588\n",
            "Epoch 5180: train loss: 0.6413874626159668\n",
            "Epoch 5181: train loss: 0.64134681224823\n",
            "Epoch 5182: train loss: 0.6413060426712036\n",
            "Epoch 5183: train loss: 0.6412652730941772\n",
            "Epoch 5184: train loss: 0.6412245631217957\n",
            "Epoch 5185: train loss: 0.6411838531494141\n",
            "Epoch 5186: train loss: 0.6411431431770325\n",
            "Epoch 5187: train loss: 0.6411023139953613\n",
            "Epoch 5188: train loss: 0.641061544418335\n",
            "Epoch 5189: train loss: 0.6410207748413086\n",
            "Epoch 5190: train loss: 0.6409798860549927\n",
            "Epoch 5191: train loss: 0.6409391164779663\n",
            "Epoch 5192: train loss: 0.6408982872962952\n",
            "Epoch 5193: train loss: 0.6408573985099792\n",
            "Epoch 5194: train loss: 0.6408165097236633\n",
            "Epoch 5195: train loss: 0.6407756805419922\n",
            "Epoch 5196: train loss: 0.6407347917556763\n",
            "Epoch 5197: train loss: 0.6406937837600708\n",
            "Epoch 5198: train loss: 0.6406528353691101\n",
            "Epoch 5199: train loss: 0.6406119465827942\n",
            "Epoch 5200: train loss: 0.6405709385871887\n",
            "Epoch 5201: train loss: 0.640529990196228\n",
            "Epoch 5202: train loss: 0.6404889225959778\n",
            "Epoch 5203: train loss: 0.6404479742050171\n",
            "Epoch 5204: train loss: 0.6404069662094116\n",
            "Epoch 5205: train loss: 0.6403658986091614\n",
            "Epoch 5206: train loss: 0.6403247714042664\n",
            "Epoch 5207: train loss: 0.6402837038040161\n",
            "Epoch 5208: train loss: 0.6402427554130554\n",
            "Epoch 5209: train loss: 0.6402016282081604\n",
            "Epoch 5210: train loss: 0.6401605010032654\n",
            "Epoch 5211: train loss: 0.6401194334030151\n",
            "Epoch 5212: train loss: 0.6400783061981201\n",
            "Epoch 5213: train loss: 0.6400370001792908\n",
            "Epoch 5214: train loss: 0.6399959325790405\n",
            "Epoch 5215: train loss: 0.639954686164856\n",
            "Epoch 5216: train loss: 0.6399135589599609\n",
            "Epoch 5217: train loss: 0.6398723125457764\n",
            "Epoch 5218: train loss: 0.6398311257362366\n",
            "Epoch 5219: train loss: 0.639789879322052\n",
            "Epoch 5220: train loss: 0.6397485733032227\n",
            "Epoch 5221: train loss: 0.6397074460983276\n",
            "Epoch 5222: train loss: 0.6396660804748535\n",
            "Epoch 5223: train loss: 0.639624834060669\n",
            "Epoch 5224: train loss: 0.6395834684371948\n",
            "Epoch 5225: train loss: 0.6395421624183655\n",
            "Epoch 5226: train loss: 0.6395008563995361\n",
            "Epoch 5227: train loss: 0.639459490776062\n",
            "Epoch 5228: train loss: 0.6394181251525879\n",
            "Epoch 5229: train loss: 0.6393767595291138\n",
            "Epoch 5230: train loss: 0.6393353343009949\n",
            "Epoch 5231: train loss: 0.6392939686775208\n",
            "Epoch 5232: train loss: 0.6392524838447571\n",
            "Epoch 5233: train loss: 0.6392110586166382\n",
            "Epoch 5234: train loss: 0.6391696333885193\n",
            "Epoch 5235: train loss: 0.6391281485557556\n",
            "Epoch 5236: train loss: 0.6390867829322815\n",
            "Epoch 5237: train loss: 0.6390451788902283\n",
            "Epoch 5238: train loss: 0.6390036940574646\n",
            "Epoch 5239: train loss: 0.6389622092247009\n",
            "Epoch 5240: train loss: 0.6389206647872925\n",
            "Epoch 5241: train loss: 0.6388792395591736\n",
            "Epoch 5242: train loss: 0.6388375759124756\n",
            "Epoch 5243: train loss: 0.6387960314750671\n",
            "Epoch 5244: train loss: 0.6387544274330139\n",
            "Epoch 5245: train loss: 0.6387128829956055\n",
            "Epoch 5246: train loss: 0.6386712193489075\n",
            "Epoch 5247: train loss: 0.6386296153068542\n",
            "Epoch 5248: train loss: 0.638588011264801\n",
            "Epoch 5249: train loss: 0.6385464072227478\n",
            "Epoch 5250: train loss: 0.638504683971405\n",
            "Epoch 5251: train loss: 0.6384629607200623\n",
            "Epoch 5252: train loss: 0.6384212970733643\n",
            "Epoch 5253: train loss: 0.6383795738220215\n",
            "Epoch 5254: train loss: 0.6383379101753235\n",
            "Epoch 5255: train loss: 0.6382961273193359\n",
            "Epoch 5256: train loss: 0.6382544040679932\n",
            "Epoch 5257: train loss: 0.6382125616073608\n",
            "Epoch 5258: train loss: 0.6381708383560181\n",
            "Epoch 5259: train loss: 0.6381291151046753\n",
            "Epoch 5260: train loss: 0.6380873322486877\n",
            "Epoch 5261: train loss: 0.6380455493927002\n",
            "Epoch 5262: train loss: 0.6380036473274231\n",
            "Epoch 5263: train loss: 0.6379618048667908\n",
            "Epoch 5264: train loss: 0.6379200220108032\n",
            "Epoch 5265: train loss: 0.6378781795501709\n",
            "Epoch 5266: train loss: 0.6378362774848938\n",
            "Epoch 5267: train loss: 0.6377944350242615\n",
            "Epoch 5268: train loss: 0.6377524733543396\n",
            "Epoch 5269: train loss: 0.6377105712890625\n",
            "Epoch 5270: train loss: 0.6376686692237854\n",
            "Epoch 5271: train loss: 0.6376267671585083\n",
            "Epoch 5272: train loss: 0.6375848054885864\n",
            "Epoch 5273: train loss: 0.6375428438186646\n",
            "Epoch 5274: train loss: 0.6375008821487427\n",
            "Epoch 5275: train loss: 0.6374588012695312\n",
            "Epoch 5276: train loss: 0.6374167799949646\n",
            "Epoch 5277: train loss: 0.6373748779296875\n",
            "Epoch 5278: train loss: 0.6373327970504761\n",
            "Epoch 5279: train loss: 0.6372907757759094\n",
            "Epoch 5280: train loss: 0.6372487545013428\n",
            "Epoch 5281: train loss: 0.6372066140174866\n",
            "Epoch 5282: train loss: 0.6371645927429199\n",
            "Epoch 5283: train loss: 0.6371225118637085\n",
            "Epoch 5284: train loss: 0.6370804905891418\n",
            "Epoch 5285: train loss: 0.6370382905006409\n",
            "Epoch 5286: train loss: 0.6369961500167847\n",
            "Epoch 5287: train loss: 0.6369540691375732\n",
            "Epoch 5288: train loss: 0.6369118690490723\n",
            "Epoch 5289: train loss: 0.6368697285652161\n",
            "Epoch 5290: train loss: 0.6368275880813599\n",
            "Epoch 5291: train loss: 0.6367853879928589\n",
            "Epoch 5292: train loss: 0.6367432475090027\n",
            "Epoch 5293: train loss: 0.6367009878158569\n",
            "Epoch 5294: train loss: 0.636658787727356\n",
            "Epoch 5295: train loss: 0.6366165280342102\n",
            "Epoch 5296: train loss: 0.6365742683410645\n",
            "Epoch 5297: train loss: 0.6365320682525635\n",
            "Epoch 5298: train loss: 0.636489748954773\n",
            "Epoch 5299: train loss: 0.6364474296569824\n",
            "Epoch 5300: train loss: 0.6364052891731262\n",
            "Epoch 5301: train loss: 0.6363628506660461\n",
            "Epoch 5302: train loss: 0.6363205909729004\n",
            "Epoch 5303: train loss: 0.6362782716751099\n",
            "Epoch 5304: train loss: 0.6362358927726746\n",
            "Epoch 5305: train loss: 0.636193573474884\n",
            "Epoch 5306: train loss: 0.6361511945724487\n",
            "Epoch 5307: train loss: 0.6361088156700134\n",
            "Epoch 5308: train loss: 0.6360664963722229\n",
            "Epoch 5309: train loss: 0.636023998260498\n",
            "Epoch 5310: train loss: 0.6359816193580627\n",
            "Epoch 5311: train loss: 0.6359391808509827\n",
            "Epoch 5312: train loss: 0.6358967423439026\n",
            "Epoch 5313: train loss: 0.6358543038368225\n",
            "Epoch 5314: train loss: 0.6358118653297424\n",
            "Epoch 5315: train loss: 0.6357694864273071\n",
            "Epoch 5316: train loss: 0.6357269287109375\n",
            "Epoch 5317: train loss: 0.6356843113899231\n",
            "Epoch 5318: train loss: 0.6356419324874878\n",
            "Epoch 5319: train loss: 0.6355994343757629\n",
            "Epoch 5320: train loss: 0.6355568766593933\n",
            "Epoch 5321: train loss: 0.6355143189430237\n",
            "Epoch 5322: train loss: 0.635471761226654\n",
            "Epoch 5323: train loss: 0.6354291439056396\n",
            "Epoch 5324: train loss: 0.6353866457939148\n",
            "Epoch 5325: train loss: 0.6353440284729004\n",
            "Epoch 5326: train loss: 0.6353015303611755\n",
            "Epoch 5327: train loss: 0.6352588534355164\n",
            "Epoch 5328: train loss: 0.6352162957191467\n",
            "Epoch 5329: train loss: 0.6351736187934875\n",
            "Epoch 5330: train loss: 0.6351310610771179\n",
            "Epoch 5331: train loss: 0.635088324546814\n",
            "Epoch 5332: train loss: 0.6350457072257996\n",
            "Epoch 5333: train loss: 0.6350030303001404\n",
            "Epoch 5334: train loss: 0.6349602937698364\n",
            "Epoch 5335: train loss: 0.6349176168441772\n",
            "Epoch 5336: train loss: 0.6348749399185181\n",
            "Epoch 5337: train loss: 0.6348322033882141\n",
            "Epoch 5338: train loss: 0.6347894072532654\n",
            "Epoch 5339: train loss: 0.6347467303276062\n",
            "Epoch 5340: train loss: 0.6347039937973022\n",
            "Epoch 5341: train loss: 0.6346611976623535\n",
            "Epoch 5342: train loss: 0.6346185207366943\n",
            "Epoch 5343: train loss: 0.6345756649971008\n",
            "Epoch 5344: train loss: 0.6345328688621521\n",
            "Epoch 5345: train loss: 0.6344900727272034\n",
            "Epoch 5346: train loss: 0.6344472765922546\n",
            "Epoch 5347: train loss: 0.6344045400619507\n",
            "Epoch 5348: train loss: 0.6343616247177124\n",
            "Epoch 5349: train loss: 0.6343187689781189\n",
            "Epoch 5350: train loss: 0.6342759728431702\n",
            "Epoch 5351: train loss: 0.6342331171035767\n",
            "Epoch 5352: train loss: 0.6341902017593384\n",
            "Epoch 5353: train loss: 0.6341472864151001\n",
            "Epoch 5354: train loss: 0.6341044306755066\n",
            "Epoch 5355: train loss: 0.6340614557266235\n",
            "Epoch 5356: train loss: 0.63401859998703\n",
            "Epoch 5357: train loss: 0.6339756846427917\n",
            "Epoch 5358: train loss: 0.6339327692985535\n",
            "Epoch 5359: train loss: 0.6338897347450256\n",
            "Epoch 5360: train loss: 0.6338468194007874\n",
            "Epoch 5361: train loss: 0.6338038444519043\n",
            "Epoch 5362: train loss: 0.633760929107666\n",
            "Epoch 5363: train loss: 0.6337178945541382\n",
            "Epoch 5364: train loss: 0.6336749196052551\n",
            "Epoch 5365: train loss: 0.6336318850517273\n",
            "Epoch 5366: train loss: 0.6335888504981995\n",
            "Epoch 5367: train loss: 0.6335458159446716\n",
            "Epoch 5368: train loss: 0.6335027813911438\n",
            "Epoch 5369: train loss: 0.633459746837616\n",
            "Epoch 5370: train loss: 0.6334167122840881\n",
            "Epoch 5371: train loss: 0.6333736181259155\n",
            "Epoch 5372: train loss: 0.6333305239677429\n",
            "Epoch 5373: train loss: 0.6332874894142151\n",
            "Epoch 5374: train loss: 0.6332443952560425\n",
            "Epoch 5375: train loss: 0.6332012414932251\n",
            "Epoch 5376: train loss: 0.6331581473350525\n",
            "Epoch 5377: train loss: 0.6331149935722351\n",
            "Epoch 5378: train loss: 0.6330718994140625\n",
            "Epoch 5379: train loss: 0.6330286860466003\n",
            "Epoch 5380: train loss: 0.632985532283783\n",
            "Epoch 5381: train loss: 0.6329424381256104\n",
            "Epoch 5382: train loss: 0.6328992247581482\n",
            "Epoch 5383: train loss: 0.6328560709953308\n",
            "Epoch 5384: train loss: 0.6328129172325134\n",
            "Epoch 5385: train loss: 0.6327696442604065\n",
            "Epoch 5386: train loss: 0.6327264308929443\n",
            "Epoch 5387: train loss: 0.632683277130127\n",
            "Epoch 5388: train loss: 0.6326399445533752\n",
            "Epoch 5389: train loss: 0.6325967311859131\n",
            "Epoch 5390: train loss: 0.6325535178184509\n",
            "Epoch 5391: train loss: 0.632510244846344\n",
            "Epoch 5392: train loss: 0.6324669718742371\n",
            "Epoch 5393: train loss: 0.6324236392974854\n",
            "Epoch 5394: train loss: 0.6323804259300232\n",
            "Epoch 5395: train loss: 0.6323370933532715\n",
            "Epoch 5396: train loss: 0.6322938203811646\n",
            "Epoch 5397: train loss: 0.6322504281997681\n",
            "Epoch 5398: train loss: 0.6322071552276611\n",
            "Epoch 5399: train loss: 0.6321637630462646\n",
            "Epoch 5400: train loss: 0.6321204304695129\n",
            "Epoch 5401: train loss: 0.6320770978927612\n",
            "Epoch 5402: train loss: 0.6320337057113647\n",
            "Epoch 5403: train loss: 0.631990373134613\n",
            "Epoch 5404: train loss: 0.6319469809532166\n",
            "Epoch 5405: train loss: 0.6319035887718201\n",
            "Epoch 5406: train loss: 0.6318601965904236\n",
            "Epoch 5407: train loss: 0.6318168044090271\n",
            "Epoch 5408: train loss: 0.6317733526229858\n",
            "Epoch 5409: train loss: 0.6317299604415894\n",
            "Epoch 5410: train loss: 0.6316866278648376\n",
            "Epoch 5411: train loss: 0.6316431760787964\n",
            "Epoch 5412: train loss: 0.6315996646881104\n",
            "Epoch 5413: train loss: 0.6315561532974243\n",
            "Epoch 5414: train loss: 0.6315127611160278\n",
            "Epoch 5415: train loss: 0.6314692497253418\n",
            "Epoch 5416: train loss: 0.6314257979393005\n",
            "Epoch 5417: train loss: 0.6313822865486145\n",
            "Epoch 5418: train loss: 0.6313387751579285\n",
            "Epoch 5419: train loss: 0.6312952637672424\n",
            "Epoch 5420: train loss: 0.6312516927719116\n",
            "Epoch 5421: train loss: 0.6312082409858704\n",
            "Epoch 5422: train loss: 0.6311647295951843\n",
            "Epoch 5423: train loss: 0.6311211585998535\n",
            "Epoch 5424: train loss: 0.6310775876045227\n",
            "Epoch 5425: train loss: 0.6310341358184814\n",
            "Epoch 5426: train loss: 0.6309905052185059\n",
            "Epoch 5427: train loss: 0.630946934223175\n",
            "Epoch 5428: train loss: 0.6309033036231995\n",
            "Epoch 5429: train loss: 0.6308597326278687\n",
            "Epoch 5430: train loss: 0.6308161616325378\n",
            "Epoch 5431: train loss: 0.6307724714279175\n",
            "Epoch 5432: train loss: 0.6307289004325867\n",
            "Epoch 5433: train loss: 0.6306852698326111\n",
            "Epoch 5434: train loss: 0.6306415796279907\n",
            "Epoch 5435: train loss: 0.6305980682373047\n",
            "Epoch 5436: train loss: 0.6305543780326843\n",
            "Epoch 5437: train loss: 0.6305106282234192\n",
            "Epoch 5438: train loss: 0.6304669976234436\n",
            "Epoch 5439: train loss: 0.630423367023468\n",
            "Epoch 5440: train loss: 0.6303796172142029\n",
            "Epoch 5441: train loss: 0.6303360462188721\n",
            "Epoch 5442: train loss: 0.6302922368049622\n",
            "Epoch 5443: train loss: 0.6302485466003418\n",
            "Epoch 5444: train loss: 0.6302048563957214\n",
            "Epoch 5445: train loss: 0.6301611661911011\n",
            "Epoch 5446: train loss: 0.6301174163818359\n",
            "Epoch 5447: train loss: 0.6300737261772156\n",
            "Epoch 5448: train loss: 0.6300299763679504\n",
            "Epoch 5449: train loss: 0.6299862265586853\n",
            "Epoch 5450: train loss: 0.6299424767494202\n",
            "Epoch 5451: train loss: 0.629898726940155\n",
            "Epoch 5452: train loss: 0.6298549175262451\n",
            "Epoch 5453: train loss: 0.6298111081123352\n",
            "Epoch 5454: train loss: 0.6297673583030701\n",
            "Epoch 5455: train loss: 0.6297236084938049\n",
            "Epoch 5456: train loss: 0.629679799079895\n",
            "Epoch 5457: train loss: 0.6296359300613403\n",
            "Epoch 5458: train loss: 0.6295921802520752\n",
            "Epoch 5459: train loss: 0.6295483112335205\n",
            "Epoch 5460: train loss: 0.6295045018196106\n",
            "Epoch 5461: train loss: 0.6294606924057007\n",
            "Epoch 5462: train loss: 0.6294167637825012\n",
            "Epoch 5463: train loss: 0.6293729543685913\n",
            "Epoch 5464: train loss: 0.6293290257453918\n",
            "Epoch 5465: train loss: 0.6292852759361267\n",
            "Epoch 5466: train loss: 0.6292413473129272\n",
            "Epoch 5467: train loss: 0.6291974782943726\n",
            "Epoch 5468: train loss: 0.6291535496711731\n",
            "Epoch 5469: train loss: 0.6291097402572632\n",
            "Epoch 5470: train loss: 0.6290658116340637\n",
            "Epoch 5471: train loss: 0.629021942615509\n",
            "Epoch 5472: train loss: 0.6289780139923096\n",
            "Epoch 5473: train loss: 0.6289340257644653\n",
            "Epoch 5474: train loss: 0.6288902163505554\n",
            "Epoch 5475: train loss: 0.6288461685180664\n",
            "Epoch 5476: train loss: 0.6288021802902222\n",
            "Epoch 5477: train loss: 0.6287583112716675\n",
            "Epoch 5478: train loss: 0.628714382648468\n",
            "Epoch 5479: train loss: 0.6286703944206238\n",
            "Epoch 5480: train loss: 0.6286263465881348\n",
            "Epoch 5481: train loss: 0.6285824775695801\n",
            "Epoch 5482: train loss: 0.6285384297370911\n",
            "Epoch 5483: train loss: 0.6284945011138916\n",
            "Epoch 5484: train loss: 0.6284504532814026\n",
            "Epoch 5485: train loss: 0.6284064650535583\n",
            "Epoch 5486: train loss: 0.6283624768257141\n",
            "Epoch 5487: train loss: 0.6283184885978699\n",
            "Epoch 5488: train loss: 0.6282744407653809\n",
            "Epoch 5489: train loss: 0.6282303929328918\n",
            "Epoch 5490: train loss: 0.6281863451004028\n",
            "Epoch 5491: train loss: 0.6281422972679138\n",
            "Epoch 5492: train loss: 0.6280982494354248\n",
            "Epoch 5493: train loss: 0.6280542612075806\n",
            "Epoch 5494: train loss: 0.6280102133750916\n",
            "Epoch 5495: train loss: 0.6279661059379578\n",
            "Epoch 5496: train loss: 0.6279220581054688\n",
            "Epoch 5497: train loss: 0.6278780102729797\n",
            "Epoch 5498: train loss: 0.627833902835846\n",
            "Epoch 5499: train loss: 0.6277897357940674\n",
            "Epoch 5500: train loss: 0.6277458071708679\n",
            "Epoch 5501: train loss: 0.6277016401290894\n",
            "Epoch 5502: train loss: 0.6276575326919556\n",
            "Epoch 5503: train loss: 0.6276134252548218\n",
            "Epoch 5504: train loss: 0.6275692582130432\n",
            "Epoch 5505: train loss: 0.6275251507759094\n",
            "Epoch 5506: train loss: 0.6274810433387756\n",
            "Epoch 5507: train loss: 0.6274369359016418\n",
            "Epoch 5508: train loss: 0.6273927688598633\n",
            "Epoch 5509: train loss: 0.6273484826087952\n",
            "Epoch 5510: train loss: 0.6273044347763062\n",
            "Epoch 5511: train loss: 0.6272602081298828\n",
            "Epoch 5512: train loss: 0.627216100692749\n",
            "Epoch 5513: train loss: 0.6271719336509705\n",
            "Epoch 5514: train loss: 0.6271278262138367\n",
            "Epoch 5515: train loss: 0.6270835995674133\n",
            "Epoch 5516: train loss: 0.62703937292099\n",
            "Epoch 5517: train loss: 0.6269952058792114\n",
            "Epoch 5518: train loss: 0.6269510388374329\n",
            "Epoch 5519: train loss: 0.6269068717956543\n",
            "Epoch 5520: train loss: 0.6268625855445862\n",
            "Epoch 5521: train loss: 0.6268184185028076\n",
            "Epoch 5522: train loss: 0.6267741322517395\n",
            "Epoch 5523: train loss: 0.6267299652099609\n",
            "Epoch 5524: train loss: 0.6266857981681824\n",
            "Epoch 5525: train loss: 0.6266415119171143\n",
            "Epoch 5526: train loss: 0.6265972256660461\n",
            "Epoch 5527: train loss: 0.6265529990196228\n",
            "Epoch 5528: train loss: 0.6265087127685547\n",
            "Epoch 5529: train loss: 0.6264644861221313\n",
            "Epoch 5530: train loss: 0.6264201998710632\n",
            "Epoch 5531: train loss: 0.6263759732246399\n",
            "Epoch 5532: train loss: 0.6263317465782166\n",
            "Epoch 5533: train loss: 0.6262874603271484\n",
            "Epoch 5534: train loss: 0.6262431740760803\n",
            "Epoch 5535: train loss: 0.6261988878250122\n",
            "Epoch 5536: train loss: 0.6261546611785889\n",
            "Epoch 5537: train loss: 0.626110315322876\n",
            "Epoch 5538: train loss: 0.6260659694671631\n",
            "Epoch 5539: train loss: 0.626021683216095\n",
            "Epoch 5540: train loss: 0.6259773373603821\n",
            "Epoch 5541: train loss: 0.625933051109314\n",
            "Epoch 5542: train loss: 0.6258886456489563\n",
            "Epoch 5543: train loss: 0.625844419002533\n",
            "Epoch 5544: train loss: 0.6258000731468201\n",
            "Epoch 5545: train loss: 0.625755786895752\n",
            "Epoch 5546: train loss: 0.6257114410400391\n",
            "Epoch 5547: train loss: 0.6256670355796814\n",
            "Epoch 5548: train loss: 0.6256226301193237\n",
            "Epoch 5549: train loss: 0.6255783438682556\n",
            "Epoch 5550: train loss: 0.6255340576171875\n",
            "Epoch 5551: train loss: 0.6254896521568298\n",
            "Epoch 5552: train loss: 0.6254453063011169\n",
            "Epoch 5553: train loss: 0.625400960445404\n",
            "Epoch 5554: train loss: 0.6253565549850464\n",
            "Epoch 5555: train loss: 0.6253121495246887\n",
            "Epoch 5556: train loss: 0.6252678036689758\n",
            "Epoch 5557: train loss: 0.6252234578132629\n",
            "Epoch 5558: train loss: 0.6251790523529053\n",
            "Epoch 5559: train loss: 0.6251346468925476\n",
            "Epoch 5560: train loss: 0.6250901818275452\n",
            "Epoch 5561: train loss: 0.625045895576477\n",
            "Epoch 5562: train loss: 0.6250014901161194\n",
            "Epoch 5563: train loss: 0.6249570846557617\n",
            "Epoch 5564: train loss: 0.624912679195404\n",
            "Epoch 5565: train loss: 0.6248682141304016\n",
            "Epoch 5566: train loss: 0.624823808670044\n",
            "Epoch 5567: train loss: 0.6247793436050415\n",
            "Epoch 5568: train loss: 0.6247349381446838\n",
            "Epoch 5569: train loss: 0.6246904134750366\n",
            "Epoch 5570: train loss: 0.624646008014679\n",
            "Epoch 5571: train loss: 0.6246016025543213\n",
            "Epoch 5572: train loss: 0.6245571374893188\n",
            "Epoch 5573: train loss: 0.6245127320289612\n",
            "Epoch 5574: train loss: 0.624468207359314\n",
            "Epoch 5575: train loss: 0.6244238018989563\n",
            "Epoch 5576: train loss: 0.6243793368339539\n",
            "Epoch 5577: train loss: 0.6243349313735962\n",
            "Epoch 5578: train loss: 0.6242904663085938\n",
            "Epoch 5579: train loss: 0.6242459416389465\n",
            "Epoch 5580: train loss: 0.6242014765739441\n",
            "Epoch 5581: train loss: 0.6241569519042969\n",
            "Epoch 5582: train loss: 0.6241125464439392\n",
            "Epoch 5583: train loss: 0.624068021774292\n",
            "Epoch 5584: train loss: 0.6240236163139343\n",
            "Epoch 5585: train loss: 0.6239790916442871\n",
            "Epoch 5586: train loss: 0.6239345669746399\n",
            "Epoch 5587: train loss: 0.6238900423049927\n",
            "Epoch 5588: train loss: 0.6238455772399902\n",
            "Epoch 5589: train loss: 0.623801052570343\n",
            "Epoch 5590: train loss: 0.6237565875053406\n",
            "Epoch 5591: train loss: 0.6237120032310486\n",
            "Epoch 5592: train loss: 0.6236675381660461\n",
            "Epoch 5593: train loss: 0.6236229538917542\n",
            "Epoch 5594: train loss: 0.6235784888267517\n",
            "Epoch 5595: train loss: 0.6235339641571045\n",
            "Epoch 5596: train loss: 0.6234893798828125\n",
            "Epoch 5597: train loss: 0.6234448552131653\n",
            "Epoch 5598: train loss: 0.6234003305435181\n",
            "Epoch 5599: train loss: 0.6233558058738708\n",
            "Epoch 5600: train loss: 0.6233112812042236\n",
            "Epoch 5601: train loss: 0.6232667565345764\n",
            "Epoch 5602: train loss: 0.6232221722602844\n",
            "Epoch 5603: train loss: 0.6231776475906372\n",
            "Epoch 5604: train loss: 0.6231330633163452\n",
            "Epoch 5605: train loss: 0.623088538646698\n",
            "Epoch 5606: train loss: 0.6230440139770508\n",
            "Epoch 5607: train loss: 0.6229994297027588\n",
            "Epoch 5608: train loss: 0.6229549050331116\n",
            "Epoch 5609: train loss: 0.6229102611541748\n",
            "Epoch 5610: train loss: 0.6228657364845276\n",
            "Epoch 5611: train loss: 0.6228211522102356\n",
            "Epoch 5612: train loss: 0.6227765679359436\n",
            "Epoch 5613: train loss: 0.6227320432662964\n",
            "Epoch 5614: train loss: 0.6226875185966492\n",
            "Epoch 5615: train loss: 0.6226428747177124\n",
            "Epoch 5616: train loss: 0.6225982308387756\n",
            "Epoch 5617: train loss: 0.6225537061691284\n",
            "Epoch 5618: train loss: 0.6225091218948364\n",
            "Epoch 5619: train loss: 0.6224645376205444\n",
            "Epoch 5620: train loss: 0.6224198937416077\n",
            "Epoch 5621: train loss: 0.6223752498626709\n",
            "Epoch 5622: train loss: 0.6223307251930237\n",
            "Epoch 5623: train loss: 0.6222861409187317\n",
            "Epoch 5624: train loss: 0.6222415566444397\n",
            "Epoch 5625: train loss: 0.6221969127655029\n",
            "Epoch 5626: train loss: 0.6221523284912109\n",
            "Epoch 5627: train loss: 0.6221076846122742\n",
            "Epoch 5628: train loss: 0.622063159942627\n",
            "Epoch 5629: train loss: 0.6220185160636902\n",
            "Epoch 5630: train loss: 0.6219739317893982\n",
            "Epoch 5631: train loss: 0.6219292283058167\n",
            "Epoch 5632: train loss: 0.6218846440315247\n",
            "Epoch 5633: train loss: 0.6218400597572327\n",
            "Epoch 5634: train loss: 0.6217953562736511\n",
            "Epoch 5635: train loss: 0.6217507719993591\n",
            "Epoch 5636: train loss: 0.6217061877250671\n",
            "Epoch 5637: train loss: 0.6216614842414856\n",
            "Epoch 5638: train loss: 0.6216169595718384\n",
            "Epoch 5639: train loss: 0.6215723156929016\n",
            "Epoch 5640: train loss: 0.6215277314186096\n",
            "Epoch 5641: train loss: 0.6214830279350281\n",
            "Epoch 5642: train loss: 0.6214383840560913\n",
            "Epoch 5643: train loss: 0.6213937401771545\n",
            "Epoch 5644: train loss: 0.6213491559028625\n",
            "Epoch 5645: train loss: 0.621304452419281\n",
            "Epoch 5646: train loss: 0.6212598085403442\n",
            "Epoch 5647: train loss: 0.6212152242660522\n",
            "Epoch 5648: train loss: 0.6211705207824707\n",
            "Epoch 5649: train loss: 0.6211259365081787\n",
            "Epoch 5650: train loss: 0.6210812926292419\n",
            "Epoch 5651: train loss: 0.6210366487503052\n",
            "Epoch 5652: train loss: 0.6209920048713684\n",
            "Epoch 5653: train loss: 0.6209473013877869\n",
            "Epoch 5654: train loss: 0.6209026575088501\n",
            "Epoch 5655: train loss: 0.6208580136299133\n",
            "Epoch 5656: train loss: 0.6208133697509766\n",
            "Epoch 5657: train loss: 0.6207687258720398\n",
            "Epoch 5658: train loss: 0.620724081993103\n",
            "Epoch 5659: train loss: 0.6206793785095215\n",
            "Epoch 5660: train loss: 0.6206347942352295\n",
            "Epoch 5661: train loss: 0.6205900311470032\n",
            "Epoch 5662: train loss: 0.6205453872680664\n",
            "Epoch 5663: train loss: 0.6205006837844849\n",
            "Epoch 5664: train loss: 0.6204560399055481\n",
            "Epoch 5665: train loss: 0.6204114556312561\n",
            "Epoch 5666: train loss: 0.6203666925430298\n",
            "Epoch 5667: train loss: 0.620322048664093\n",
            "Epoch 5668: train loss: 0.6202774047851562\n",
            "Epoch 5669: train loss: 0.6202327013015747\n",
            "Epoch 5670: train loss: 0.6201879978179932\n",
            "Epoch 5671: train loss: 0.6201433539390564\n",
            "Epoch 5672: train loss: 0.6200987696647644\n",
            "Epoch 5673: train loss: 0.6200540661811829\n",
            "Epoch 5674: train loss: 0.6200093626976013\n",
            "Epoch 5675: train loss: 0.619964599609375\n",
            "Epoch 5676: train loss: 0.619920015335083\n",
            "Epoch 5677: train loss: 0.6198753118515015\n",
            "Epoch 5678: train loss: 0.6198306679725647\n",
            "Epoch 5679: train loss: 0.6197859644889832\n",
            "Epoch 5680: train loss: 0.6197413802146912\n",
            "Epoch 5681: train loss: 0.6196966171264648\n",
            "Epoch 5682: train loss: 0.6196519136428833\n",
            "Epoch 5683: train loss: 0.6196073293685913\n",
            "Epoch 5684: train loss: 0.6195626258850098\n",
            "Epoch 5685: train loss: 0.6195179224014282\n",
            "Epoch 5686: train loss: 0.6194731593132019\n",
            "Epoch 5687: train loss: 0.6194286346435547\n",
            "Epoch 5688: train loss: 0.6193839311599731\n",
            "Epoch 5689: train loss: 0.6193392276763916\n",
            "Epoch 5690: train loss: 0.6192945241928101\n",
            "Epoch 5691: train loss: 0.6192498207092285\n",
            "Epoch 5692: train loss: 0.6192051768302917\n",
            "Epoch 5693: train loss: 0.6191604137420654\n",
            "Epoch 5694: train loss: 0.6191158294677734\n",
            "Epoch 5695: train loss: 0.6190711259841919\n",
            "Epoch 5696: train loss: 0.6190264225006104\n",
            "Epoch 5697: train loss: 0.6189817786216736\n",
            "Epoch 5698: train loss: 0.618937075138092\n",
            "Epoch 5699: train loss: 0.6188923716545105\n",
            "Epoch 5700: train loss: 0.618847668170929\n",
            "Epoch 5701: train loss: 0.6188030242919922\n",
            "Epoch 5702: train loss: 0.6187583804130554\n",
            "Epoch 5703: train loss: 0.6187136769294739\n",
            "Epoch 5704: train loss: 0.6186689734458923\n",
            "Epoch 5705: train loss: 0.6186242699623108\n",
            "Epoch 5706: train loss: 0.618579626083374\n",
            "Epoch 5707: train loss: 0.6185349225997925\n",
            "Epoch 5708: train loss: 0.6184902191162109\n",
            "Epoch 5709: train loss: 0.618445634841919\n",
            "Epoch 5710: train loss: 0.6184008717536926\n",
            "Epoch 5711: train loss: 0.6183562874794006\n",
            "Epoch 5712: train loss: 0.6183115243911743\n",
            "Epoch 5713: train loss: 0.6182668209075928\n",
            "Epoch 5714: train loss: 0.6182221174240112\n",
            "Epoch 5715: train loss: 0.6181774735450745\n",
            "Epoch 5716: train loss: 0.6181328296661377\n",
            "Epoch 5717: train loss: 0.6180881857872009\n",
            "Epoch 5718: train loss: 0.6180435419082642\n",
            "Epoch 5719: train loss: 0.6179987192153931\n",
            "Epoch 5720: train loss: 0.6179541349411011\n",
            "Epoch 5721: train loss: 0.6179094314575195\n",
            "Epoch 5722: train loss: 0.617864727973938\n",
            "Epoch 5723: train loss: 0.6178200840950012\n",
            "Epoch 5724: train loss: 0.6177754998207092\n",
            "Epoch 5725: train loss: 0.6177307963371277\n",
            "Epoch 5726: train loss: 0.6176860928535461\n",
            "Epoch 5727: train loss: 0.6176413893699646\n",
            "Epoch 5728: train loss: 0.6175967454910278\n",
            "Epoch 5729: train loss: 0.6175521016120911\n",
            "Epoch 5730: train loss: 0.6175073385238647\n",
            "Epoch 5731: train loss: 0.6174627542495728\n",
            "Epoch 5732: train loss: 0.6174180507659912\n",
            "Epoch 5733: train loss: 0.6173734068870544\n",
            "Epoch 5734: train loss: 0.6173287034034729\n",
            "Epoch 5735: train loss: 0.6172840595245361\n",
            "Epoch 5736: train loss: 0.6172394156455994\n",
            "Epoch 5737: train loss: 0.6171947717666626\n",
            "Epoch 5738: train loss: 0.617150068283081\n",
            "Epoch 5739: train loss: 0.6171054244041443\n",
            "Epoch 5740: train loss: 0.6170607805252075\n",
            "Epoch 5741: train loss: 0.617016077041626\n",
            "Epoch 5742: train loss: 0.6169714331626892\n",
            "Epoch 5743: train loss: 0.6169267892837524\n",
            "Epoch 5744: train loss: 0.6168820858001709\n",
            "Epoch 5745: train loss: 0.6168374419212341\n",
            "Epoch 5746: train loss: 0.6167927980422974\n",
            "Epoch 5747: train loss: 0.6167481541633606\n",
            "Epoch 5748: train loss: 0.6167035102844238\n",
            "Epoch 5749: train loss: 0.6166588664054871\n",
            "Epoch 5750: train loss: 0.6166142821311951\n",
            "Epoch 5751: train loss: 0.6165696382522583\n",
            "Epoch 5752: train loss: 0.6165249347686768\n",
            "Epoch 5753: train loss: 0.6164802312850952\n",
            "Epoch 5754: train loss: 0.6164356470108032\n",
            "Epoch 5755: train loss: 0.6163910031318665\n",
            "Epoch 5756: train loss: 0.6163464188575745\n",
            "Epoch 5757: train loss: 0.6163017749786377\n",
            "Epoch 5758: train loss: 0.6162571310997009\n",
            "Epoch 5759: train loss: 0.6162125468254089\n",
            "Epoch 5760: train loss: 0.6161679029464722\n",
            "Epoch 5761: train loss: 0.6161232590675354\n",
            "Epoch 5762: train loss: 0.6160786151885986\n",
            "Epoch 5763: train loss: 0.6160339713096619\n",
            "Epoch 5764: train loss: 0.6159893274307251\n",
            "Epoch 5765: train loss: 0.6159446835517883\n",
            "Epoch 5766: train loss: 0.6159000992774963\n",
            "Epoch 5767: train loss: 0.6158555150032043\n",
            "Epoch 5768: train loss: 0.6158109307289124\n",
            "Epoch 5769: train loss: 0.6157662868499756\n",
            "Epoch 5770: train loss: 0.6157217025756836\n",
            "Epoch 5771: train loss: 0.6156771183013916\n",
            "Epoch 5772: train loss: 0.6156324744224548\n",
            "Epoch 5773: train loss: 0.6155878305435181\n",
            "Epoch 5774: train loss: 0.6155433058738708\n",
            "Epoch 5775: train loss: 0.6154986619949341\n",
            "Epoch 5776: train loss: 0.6154540777206421\n",
            "Epoch 5777: train loss: 0.6154094338417053\n",
            "Epoch 5778: train loss: 0.6153649091720581\n",
            "Epoch 5779: train loss: 0.6153202652931213\n",
            "Epoch 5780: train loss: 0.6152756810188293\n",
            "Epoch 5781: train loss: 0.6152310967445374\n",
            "Epoch 5782: train loss: 0.6151865720748901\n",
            "Epoch 5783: train loss: 0.6151419878005981\n",
            "Epoch 5784: train loss: 0.6150973439216614\n",
            "Epoch 5785: train loss: 0.6150528192520142\n",
            "Epoch 5786: train loss: 0.6150081753730774\n",
            "Epoch 5787: train loss: 0.614963710308075\n",
            "Epoch 5788: train loss: 0.6149190664291382\n",
            "Epoch 5789: train loss: 0.6148744225502014\n",
            "Epoch 5790: train loss: 0.6148298978805542\n",
            "Epoch 5791: train loss: 0.614785373210907\n",
            "Epoch 5792: train loss: 0.614740788936615\n",
            "Epoch 5793: train loss: 0.6146962642669678\n",
            "Epoch 5794: train loss: 0.6146516799926758\n",
            "Epoch 5795: train loss: 0.6146070957183838\n",
            "Epoch 5796: train loss: 0.6145625710487366\n",
            "Epoch 5797: train loss: 0.6145180463790894\n",
            "Epoch 5798: train loss: 0.6144734621047974\n",
            "Epoch 5799: train loss: 0.6144289374351501\n",
            "Epoch 5800: train loss: 0.6143843531608582\n",
            "Epoch 5801: train loss: 0.6143398284912109\n",
            "Epoch 5802: train loss: 0.6142953634262085\n",
            "Epoch 5803: train loss: 0.6142508387565613\n",
            "Epoch 5804: train loss: 0.6142063140869141\n",
            "Epoch 5805: train loss: 0.6141617894172668\n",
            "Epoch 5806: train loss: 0.6141172647476196\n",
            "Epoch 5807: train loss: 0.6140727400779724\n",
            "Epoch 5808: train loss: 0.6140282154083252\n",
            "Epoch 5809: train loss: 0.6139837503433228\n",
            "Epoch 5810: train loss: 0.6139392256736755\n",
            "Epoch 5811: train loss: 0.6138947606086731\n",
            "Epoch 5812: train loss: 0.6138501763343811\n",
            "Epoch 5813: train loss: 0.6138057112693787\n",
            "Epoch 5814: train loss: 0.6137612462043762\n",
            "Epoch 5815: train loss: 0.613716721534729\n",
            "Epoch 5816: train loss: 0.6136722564697266\n",
            "Epoch 5817: train loss: 0.6136277318000793\n",
            "Epoch 5818: train loss: 0.6135832667350769\n",
            "Epoch 5819: train loss: 0.6135387420654297\n",
            "Epoch 5820: train loss: 0.6134942173957825\n",
            "Epoch 5821: train loss: 0.61344975233078\n",
            "Epoch 5822: train loss: 0.6134052872657776\n",
            "Epoch 5823: train loss: 0.6133608222007751\n",
            "Epoch 5824: train loss: 0.6133164167404175\n",
            "Epoch 5825: train loss: 0.6132718920707703\n",
            "Epoch 5826: train loss: 0.6132274270057678\n",
            "Epoch 5827: train loss: 0.6131829619407654\n",
            "Epoch 5828: train loss: 0.6131385564804077\n",
            "Epoch 5829: train loss: 0.6130940914154053\n",
            "Epoch 5830: train loss: 0.6130496263504028\n",
            "Epoch 5831: train loss: 0.6130052804946899\n",
            "Epoch 5832: train loss: 0.6129608154296875\n",
            "Epoch 5833: train loss: 0.6129163503646851\n",
            "Epoch 5834: train loss: 0.6128719449043274\n",
            "Epoch 5835: train loss: 0.612827479839325\n",
            "Epoch 5836: train loss: 0.6127830743789673\n",
            "Epoch 5837: train loss: 0.6127386093139648\n",
            "Epoch 5838: train loss: 0.6126942038536072\n",
            "Epoch 5839: train loss: 0.6126498579978943\n",
            "Epoch 5840: train loss: 0.6126053929328918\n",
            "Epoch 5841: train loss: 0.612561047077179\n",
            "Epoch 5842: train loss: 0.6125165820121765\n",
            "Epoch 5843: train loss: 0.6124722361564636\n",
            "Epoch 5844: train loss: 0.612427830696106\n",
            "Epoch 5845: train loss: 0.6123834252357483\n",
            "Epoch 5846: train loss: 0.6123390793800354\n",
            "Epoch 5847: train loss: 0.6122947335243225\n",
            "Epoch 5848: train loss: 0.6122502684593201\n",
            "Epoch 5849: train loss: 0.6122059226036072\n",
            "Epoch 5850: train loss: 0.6121615767478943\n",
            "Epoch 5851: train loss: 0.6121171712875366\n",
            "Epoch 5852: train loss: 0.6120728850364685\n",
            "Epoch 5853: train loss: 0.6120284795761108\n",
            "Epoch 5854: train loss: 0.611984133720398\n",
            "Epoch 5855: train loss: 0.6119397878646851\n",
            "Epoch 5856: train loss: 0.6118953824043274\n",
            "Epoch 5857: train loss: 0.611851155757904\n",
            "Epoch 5858: train loss: 0.6118067502975464\n",
            "Epoch 5859: train loss: 0.6117624640464783\n",
            "Epoch 5860: train loss: 0.6117181181907654\n",
            "Epoch 5861: train loss: 0.6116738319396973\n",
            "Epoch 5862: train loss: 0.6116294264793396\n",
            "Epoch 5863: train loss: 0.6115851998329163\n",
            "Epoch 5864: train loss: 0.6115408539772034\n",
            "Epoch 5865: train loss: 0.6114965677261353\n",
            "Epoch 5866: train loss: 0.6114522218704224\n",
            "Epoch 5867: train loss: 0.611407995223999\n",
            "Epoch 5868: train loss: 0.6113637089729309\n",
            "Epoch 5869: train loss: 0.611319363117218\n",
            "Epoch 5870: train loss: 0.6112750768661499\n",
            "Epoch 5871: train loss: 0.6112308502197266\n",
            "Epoch 5872: train loss: 0.6111865043640137\n",
            "Epoch 5873: train loss: 0.6111422777175903\n",
            "Epoch 5874: train loss: 0.6110979318618774\n",
            "Epoch 5875: train loss: 0.6110537052154541\n",
            "Epoch 5876: train loss: 0.6110094785690308\n",
            "Epoch 5877: train loss: 0.6109652519226074\n",
            "Epoch 5878: train loss: 0.6109210252761841\n",
            "Epoch 5879: train loss: 0.610876739025116\n",
            "Epoch 5880: train loss: 0.6108324527740479\n",
            "Epoch 5881: train loss: 0.6107882261276245\n",
            "Epoch 5882: train loss: 0.6107439994812012\n",
            "Epoch 5883: train loss: 0.6106997728347778\n",
            "Epoch 5884: train loss: 0.6106555461883545\n",
            "Epoch 5885: train loss: 0.6106113791465759\n",
            "Epoch 5886: train loss: 0.6105671525001526\n",
            "Epoch 5887: train loss: 0.610522985458374\n",
            "Epoch 5888: train loss: 0.6104788184165955\n",
            "Epoch 5889: train loss: 0.6104345321655273\n",
            "Epoch 5890: train loss: 0.6103903651237488\n",
            "Epoch 5891: train loss: 0.610346257686615\n",
            "Epoch 5892: train loss: 0.6103020906448364\n",
            "Epoch 5893: train loss: 0.6102579236030579\n",
            "Epoch 5894: train loss: 0.6102136969566345\n",
            "Epoch 5895: train loss: 0.610169529914856\n",
            "Epoch 5896: train loss: 0.6101254224777222\n",
            "Epoch 5897: train loss: 0.6100812554359436\n",
            "Epoch 5898: train loss: 0.610037088394165\n",
            "Epoch 5899: train loss: 0.6099929809570312\n",
            "Epoch 5900: train loss: 0.6099488735198975\n",
            "Epoch 5901: train loss: 0.6099045872688293\n",
            "Epoch 5902: train loss: 0.6098605394363403\n",
            "Epoch 5903: train loss: 0.6098164916038513\n",
            "Epoch 5904: train loss: 0.6097723841667175\n",
            "Epoch 5905: train loss: 0.609728217124939\n",
            "Epoch 5906: train loss: 0.60968416929245\n",
            "Epoch 5907: train loss: 0.6096400618553162\n",
            "Epoch 5908: train loss: 0.6095958948135376\n",
            "Epoch 5909: train loss: 0.6095518469810486\n",
            "Epoch 5910: train loss: 0.6095077991485596\n",
            "Epoch 5911: train loss: 0.609463632106781\n",
            "Epoch 5912: train loss: 0.609419584274292\n",
            "Epoch 5913: train loss: 0.609375536441803\n",
            "Epoch 5914: train loss: 0.6093314290046692\n",
            "Epoch 5915: train loss: 0.609287440776825\n",
            "Epoch 5916: train loss: 0.6092433929443359\n",
            "Epoch 5917: train loss: 0.6091993451118469\n",
            "Epoch 5918: train loss: 0.6091552972793579\n",
            "Epoch 5919: train loss: 0.6091111898422241\n",
            "Epoch 5920: train loss: 0.6090672612190247\n",
            "Epoch 5921: train loss: 0.6090232729911804\n",
            "Epoch 5922: train loss: 0.6089792251586914\n",
            "Epoch 5923: train loss: 0.6089351773262024\n",
            "Epoch 5924: train loss: 0.6088911890983582\n",
            "Epoch 5925: train loss: 0.6088471412658691\n",
            "Epoch 5926: train loss: 0.6088031530380249\n",
            "Epoch 5927: train loss: 0.6087591648101807\n",
            "Epoch 5928: train loss: 0.6087151765823364\n",
            "Epoch 5929: train loss: 0.6086711883544922\n",
            "Epoch 5930: train loss: 0.6086273193359375\n",
            "Epoch 5931: train loss: 0.6085833311080933\n",
            "Epoch 5932: train loss: 0.6085394024848938\n",
            "Epoch 5933: train loss: 0.6084953546524048\n",
            "Epoch 5934: train loss: 0.6084514856338501\n",
            "Epoch 5935: train loss: 0.6084075570106506\n",
            "Epoch 5936: train loss: 0.6083636283874512\n",
            "Epoch 5937: train loss: 0.6083196997642517\n",
            "Epoch 5938: train loss: 0.6082757115364075\n",
            "Epoch 5939: train loss: 0.6082318425178528\n",
            "Epoch 5940: train loss: 0.6081879138946533\n",
            "Epoch 5941: train loss: 0.6081440448760986\n",
            "Epoch 5942: train loss: 0.608100175857544\n",
            "Epoch 5943: train loss: 0.6080561876296997\n",
            "Epoch 5944: train loss: 0.608012318611145\n",
            "Epoch 5945: train loss: 0.6079684495925903\n",
            "Epoch 5946: train loss: 0.6079246401786804\n",
            "Epoch 5947: train loss: 0.6078807711601257\n",
            "Epoch 5948: train loss: 0.607836902141571\n",
            "Epoch 5949: train loss: 0.6077929735183716\n",
            "Epoch 5950: train loss: 0.6077492237091064\n",
            "Epoch 5951: train loss: 0.6077053546905518\n",
            "Epoch 5952: train loss: 0.6076614856719971\n",
            "Epoch 5953: train loss: 0.6076176762580872\n",
            "Epoch 5954: train loss: 0.6075738668441772\n",
            "Epoch 5955: train loss: 0.6075300574302673\n",
            "Epoch 5956: train loss: 0.6074861884117126\n",
            "Epoch 5957: train loss: 0.6074424982070923\n",
            "Epoch 5958: train loss: 0.6073986291885376\n",
            "Epoch 5959: train loss: 0.6073548197746277\n",
            "Epoch 5960: train loss: 0.6073111295700073\n",
            "Epoch 5961: train loss: 0.6072673201560974\n",
            "Epoch 5962: train loss: 0.6072235107421875\n",
            "Epoch 5963: train loss: 0.6071797609329224\n",
            "Epoch 5964: train loss: 0.6071360111236572\n",
            "Epoch 5965: train loss: 0.6070922017097473\n",
            "Epoch 5966: train loss: 0.6070485711097717\n",
            "Epoch 5967: train loss: 0.6070047616958618\n",
            "Epoch 5968: train loss: 0.6069610118865967\n",
            "Epoch 5969: train loss: 0.6069173812866211\n",
            "Epoch 5970: train loss: 0.6068735718727112\n",
            "Epoch 5971: train loss: 0.6068299412727356\n",
            "Epoch 5972: train loss: 0.6067861914634705\n",
            "Epoch 5973: train loss: 0.6067425012588501\n",
            "Epoch 5974: train loss: 0.6066988706588745\n",
            "Epoch 5975: train loss: 0.6066551804542542\n",
            "Epoch 5976: train loss: 0.606611430644989\n",
            "Epoch 5977: train loss: 0.6065678000450134\n",
            "Epoch 5978: train loss: 0.6065241098403931\n",
            "Epoch 5979: train loss: 0.6064804196357727\n",
            "Epoch 5980: train loss: 0.6064368486404419\n",
            "Epoch 5981: train loss: 0.6063931584358215\n",
            "Epoch 5982: train loss: 0.6063495874404907\n",
            "Epoch 5983: train loss: 0.6063060164451599\n",
            "Epoch 5984: train loss: 0.6062623262405396\n",
            "Epoch 5985: train loss: 0.606218695640564\n",
            "Epoch 5986: train loss: 0.6061751246452332\n",
            "Epoch 5987: train loss: 0.6061315536499023\n",
            "Epoch 5988: train loss: 0.606087863445282\n",
            "Epoch 5989: train loss: 0.6060442328453064\n",
            "Epoch 5990: train loss: 0.6060007810592651\n",
            "Epoch 5991: train loss: 0.6059571504592896\n",
            "Epoch 5992: train loss: 0.6059136390686035\n",
            "Epoch 5993: train loss: 0.6058700680732727\n",
            "Epoch 5994: train loss: 0.6058265566825867\n",
            "Epoch 5995: train loss: 0.6057829260826111\n",
            "Epoch 5996: train loss: 0.6057394742965698\n",
            "Epoch 5997: train loss: 0.6056958436965942\n",
            "Epoch 5998: train loss: 0.605652391910553\n",
            "Epoch 5999: train loss: 0.6056088805198669\n",
            "Epoch 6000: train loss: 0.6055654287338257\n",
            "Epoch 6001: train loss: 0.6055219173431396\n",
            "Epoch 6002: train loss: 0.6054783463478088\n",
            "Epoch 6003: train loss: 0.6054349541664124\n",
            "Epoch 6004: train loss: 0.6053914427757263\n",
            "Epoch 6005: train loss: 0.6053479909896851\n",
            "Epoch 6006: train loss: 0.6053045392036438\n",
            "Epoch 6007: train loss: 0.6052610278129578\n",
            "Epoch 6008: train loss: 0.6052176356315613\n",
            "Epoch 6009: train loss: 0.60517418384552\n",
            "Epoch 6010: train loss: 0.6051307916641235\n",
            "Epoch 6011: train loss: 0.6050872802734375\n",
            "Epoch 6012: train loss: 0.605043888092041\n",
            "Epoch 6013: train loss: 0.6050004959106445\n",
            "Epoch 6014: train loss: 0.604957103729248\n",
            "Epoch 6015: train loss: 0.6049137115478516\n",
            "Epoch 6016: train loss: 0.6048703789710999\n",
            "Epoch 6017: train loss: 0.6048269867897034\n",
            "Epoch 6018: train loss: 0.6047835350036621\n",
            "Epoch 6019: train loss: 0.6047402620315552\n",
            "Epoch 6020: train loss: 0.6046969294548035\n",
            "Epoch 6021: train loss: 0.604653537273407\n",
            "Epoch 6022: train loss: 0.6046102046966553\n",
            "Epoch 6023: train loss: 0.6045668721199036\n",
            "Epoch 6024: train loss: 0.6045234799385071\n",
            "Epoch 6025: train loss: 0.6044802069664001\n",
            "Epoch 6026: train loss: 0.6044369339942932\n",
            "Epoch 6027: train loss: 0.6043936014175415\n",
            "Epoch 6028: train loss: 0.6043503284454346\n",
            "Epoch 6029: train loss: 0.6043070554733276\n",
            "Epoch 6030: train loss: 0.6042637825012207\n",
            "Epoch 6031: train loss: 0.6042205095291138\n",
            "Epoch 6032: train loss: 0.6041772961616516\n",
            "Epoch 6033: train loss: 0.6041340231895447\n",
            "Epoch 6034: train loss: 0.6040908098220825\n",
            "Epoch 6035: train loss: 0.6040475368499756\n",
            "Epoch 6036: train loss: 0.6040042638778687\n",
            "Epoch 6037: train loss: 0.6039610505104065\n",
            "Epoch 6038: train loss: 0.6039178967475891\n",
            "Epoch 6039: train loss: 0.603874683380127\n",
            "Epoch 6040: train loss: 0.6038315296173096\n",
            "Epoch 6041: train loss: 0.6037883162498474\n",
            "Epoch 6042: train loss: 0.6037451028823853\n",
            "Epoch 6043: train loss: 0.6037018895149231\n",
            "Epoch 6044: train loss: 0.6036587357521057\n",
            "Epoch 6045: train loss: 0.6036155819892883\n",
            "Epoch 6046: train loss: 0.603572428226471\n",
            "Epoch 6047: train loss: 0.6035292744636536\n",
            "Epoch 6048: train loss: 0.603486180305481\n",
            "Epoch 6049: train loss: 0.6034430861473083\n",
            "Epoch 6050: train loss: 0.603399932384491\n",
            "Epoch 6051: train loss: 0.6033568382263184\n",
            "Epoch 6052: train loss: 0.6033138036727905\n",
            "Epoch 6053: train loss: 0.6032707095146179\n",
            "Epoch 6054: train loss: 0.6032276153564453\n",
            "Epoch 6055: train loss: 0.6031844615936279\n",
            "Epoch 6056: train loss: 0.6031414270401001\n",
            "Epoch 6057: train loss: 0.6030983328819275\n",
            "Epoch 6058: train loss: 0.6030553579330444\n",
            "Epoch 6059: train loss: 0.6030123233795166\n",
            "Epoch 6060: train loss: 0.6029692888259888\n",
            "Epoch 6061: train loss: 0.6029262542724609\n",
            "Epoch 6062: train loss: 0.6028832197189331\n",
            "Epoch 6063: train loss: 0.6028403043746948\n",
            "Epoch 6064: train loss: 0.6027972102165222\n",
            "Epoch 6065: train loss: 0.6027542352676392\n",
            "Epoch 6066: train loss: 0.6027112603187561\n",
            "Epoch 6067: train loss: 0.602668285369873\n",
            "Epoch 6068: train loss: 0.6026253700256348\n",
            "Epoch 6069: train loss: 0.6025823950767517\n",
            "Epoch 6070: train loss: 0.6025394201278687\n",
            "Epoch 6071: train loss: 0.6024964451789856\n",
            "Epoch 6072: train loss: 0.6024535298347473\n",
            "Epoch 6073: train loss: 0.6024106740951538\n",
            "Epoch 6074: train loss: 0.6023676991462708\n",
            "Epoch 6075: train loss: 0.6023247838020325\n",
            "Epoch 6076: train loss: 0.602281928062439\n",
            "Epoch 6077: train loss: 0.6022390127182007\n",
            "Epoch 6078: train loss: 0.602196216583252\n",
            "Epoch 6079: train loss: 0.6021532416343689\n",
            "Epoch 6080: train loss: 0.6021103858947754\n",
            "Epoch 6081: train loss: 0.6020676493644714\n",
            "Epoch 6082: train loss: 0.6020247936248779\n",
            "Epoch 6083: train loss: 0.6019819974899292\n",
            "Epoch 6084: train loss: 0.6019391417503357\n",
            "Epoch 6085: train loss: 0.6018962860107422\n",
            "Epoch 6086: train loss: 0.6018534302711487\n",
            "Epoch 6087: train loss: 0.6018106937408447\n",
            "Epoch 6088: train loss: 0.6017678380012512\n",
            "Epoch 6089: train loss: 0.6017251014709473\n",
            "Epoch 6090: train loss: 0.6016823649406433\n",
            "Epoch 6091: train loss: 0.6016395688056946\n",
            "Epoch 6092: train loss: 0.6015968322753906\n",
            "Epoch 6093: train loss: 0.6015540957450867\n",
            "Epoch 6094: train loss: 0.6015113592147827\n",
            "Epoch 6095: train loss: 0.6014686822891235\n",
            "Epoch 6096: train loss: 0.6014258861541748\n",
            "Epoch 6097: train loss: 0.6013832688331604\n",
            "Epoch 6098: train loss: 0.6013405919075012\n",
            "Epoch 6099: train loss: 0.6012977957725525\n",
            "Epoch 6100: train loss: 0.6012551784515381\n",
            "Epoch 6101: train loss: 0.6012124419212341\n",
            "Epoch 6102: train loss: 0.6011698246002197\n",
            "Epoch 6103: train loss: 0.601127028465271\n",
            "Epoch 6104: train loss: 0.6010845303535461\n",
            "Epoch 6105: train loss: 0.601041853427887\n",
            "Epoch 6106: train loss: 0.6009992957115173\n",
            "Epoch 6107: train loss: 0.6009566187858582\n",
            "Epoch 6108: train loss: 0.6009140014648438\n",
            "Epoch 6109: train loss: 0.6008713841438293\n",
            "Epoch 6110: train loss: 0.6008288264274597\n",
            "Epoch 6111: train loss: 0.6007862091064453\n",
            "Epoch 6112: train loss: 0.6007437109947205\n",
            "Epoch 6113: train loss: 0.6007011532783508\n",
            "Epoch 6114: train loss: 0.6006585955619812\n",
            "Epoch 6115: train loss: 0.6006159782409668\n",
            "Epoch 6116: train loss: 0.6005734801292419\n",
            "Epoch 6117: train loss: 0.6005309224128723\n",
            "Epoch 6118: train loss: 0.6004884839057922\n",
            "Epoch 6119: train loss: 0.6004459857940674\n",
            "Epoch 6120: train loss: 0.6004034876823425\n",
            "Epoch 6121: train loss: 0.6003609299659729\n",
            "Epoch 6122: train loss: 0.6003184914588928\n",
            "Epoch 6123: train loss: 0.6002761125564575\n",
            "Epoch 6124: train loss: 0.6002335548400879\n",
            "Epoch 6125: train loss: 0.6001911163330078\n",
            "Epoch 6126: train loss: 0.6001486778259277\n",
            "Epoch 6127: train loss: 0.6001061797142029\n",
            "Epoch 6128: train loss: 0.6000638604164124\n",
            "Epoch 6129: train loss: 0.6000213623046875\n",
            "Epoch 6130: train loss: 0.5999789834022522\n",
            "Epoch 6131: train loss: 0.5999366641044617\n",
            "Epoch 6132: train loss: 0.5998942255973816\n",
            "Epoch 6133: train loss: 0.5998518466949463\n",
            "Epoch 6134: train loss: 0.5998095870018005\n",
            "Epoch 6135: train loss: 0.5997671484947205\n",
            "Epoch 6136: train loss: 0.5997247695922852\n",
            "Epoch 6137: train loss: 0.5996825098991394\n",
            "Epoch 6138: train loss: 0.5996401309967041\n",
            "Epoch 6139: train loss: 0.5995978116989136\n",
            "Epoch 6140: train loss: 0.599555492401123\n",
            "Epoch 6141: train loss: 0.5995131731033325\n",
            "Epoch 6142: train loss: 0.5994709730148315\n",
            "Epoch 6143: train loss: 0.5994287133216858\n",
            "Epoch 6144: train loss: 0.5993863940238953\n",
            "Epoch 6145: train loss: 0.5993441939353943\n",
            "Epoch 6146: train loss: 0.5993019342422485\n",
            "Epoch 6147: train loss: 0.599259614944458\n",
            "Epoch 6148: train loss: 0.599217414855957\n",
            "Epoch 6149: train loss: 0.599175214767456\n",
            "Epoch 6150: train loss: 0.5991330742835999\n",
            "Epoch 6151: train loss: 0.5990908145904541\n",
            "Epoch 6152: train loss: 0.5990485548973083\n",
            "Epoch 6153: train loss: 0.5990064144134521\n",
            "Epoch 6154: train loss: 0.598964273929596\n",
            "Epoch 6155: train loss: 0.598922073841095\n",
            "Epoch 6156: train loss: 0.5988799929618835\n",
            "Epoch 6157: train loss: 0.5988378524780273\n",
            "Epoch 6158: train loss: 0.5987957119941711\n",
            "Epoch 6159: train loss: 0.5987535715103149\n",
            "Epoch 6160: train loss: 0.5987114906311035\n",
            "Epoch 6161: train loss: 0.5986694097518921\n",
            "Epoch 6162: train loss: 0.5986272096633911\n",
            "Epoch 6163: train loss: 0.5985852479934692\n",
            "Epoch 6164: train loss: 0.5985431671142578\n",
            "Epoch 6165: train loss: 0.5985010862350464\n",
            "Epoch 6166: train loss: 0.5984590649604797\n",
            "Epoch 6167: train loss: 0.5984169840812683\n",
            "Epoch 6168: train loss: 0.5983750224113464\n",
            "Epoch 6169: train loss: 0.598332941532135\n",
            "Epoch 6170: train loss: 0.5982909202575684\n",
            "Epoch 6171: train loss: 0.5982488989830017\n",
            "Epoch 6172: train loss: 0.5982069373130798\n",
            "Epoch 6173: train loss: 0.5981649160385132\n",
            "Epoch 6174: train loss: 0.5981229543685913\n",
            "Epoch 6175: train loss: 0.5980809330940247\n",
            "Epoch 6176: train loss: 0.5980390906333923\n",
            "Epoch 6177: train loss: 0.5979971885681152\n",
            "Epoch 6178: train loss: 0.5979552268981934\n",
            "Epoch 6179: train loss: 0.5979133248329163\n",
            "Epoch 6180: train loss: 0.5978713631629944\n",
            "Epoch 6181: train loss: 0.5978294610977173\n",
            "Epoch 6182: train loss: 0.597787618637085\n",
            "Epoch 6183: train loss: 0.5977457165718079\n",
            "Epoch 6184: train loss: 0.5977039337158203\n",
            "Epoch 6185: train loss: 0.5976619720458984\n",
            "Epoch 6186: train loss: 0.5976200699806213\n",
            "Epoch 6187: train loss: 0.5975783467292786\n",
            "Epoch 6188: train loss: 0.5975363850593567\n",
            "Epoch 6189: train loss: 0.5974946618080139\n",
            "Epoch 6190: train loss: 0.5974528193473816\n",
            "Epoch 6191: train loss: 0.5974110960960388\n",
            "Epoch 6192: train loss: 0.5973692536354065\n",
            "Epoch 6193: train loss: 0.597327470779419\n",
            "Epoch 6194: train loss: 0.5972856879234314\n",
            "Epoch 6195: train loss: 0.5972439646720886\n",
            "Epoch 6196: train loss: 0.5972022414207458\n",
            "Epoch 6197: train loss: 0.5971605181694031\n",
            "Epoch 6198: train loss: 0.5971187949180603\n",
            "Epoch 6199: train loss: 0.5970770716667175\n",
            "Epoch 6200: train loss: 0.5970353484153748\n",
            "Epoch 6201: train loss: 0.596993625164032\n",
            "Epoch 6202: train loss: 0.596951961517334\n",
            "Epoch 6203: train loss: 0.596910297870636\n",
            "Epoch 6204: train loss: 0.596868634223938\n",
            "Epoch 6205: train loss: 0.59682697057724\n",
            "Epoch 6206: train loss: 0.5967853665351868\n",
            "Epoch 6207: train loss: 0.5967437624931335\n",
            "Epoch 6208: train loss: 0.5967020988464355\n",
            "Epoch 6209: train loss: 0.5966604351997375\n",
            "Epoch 6210: train loss: 0.5966188907623291\n",
            "Epoch 6211: train loss: 0.5965773463249207\n",
            "Epoch 6212: train loss: 0.5965357422828674\n",
            "Epoch 6213: train loss: 0.596494197845459\n",
            "Epoch 6214: train loss: 0.5964526534080505\n",
            "Epoch 6215: train loss: 0.5964110493659973\n",
            "Epoch 6216: train loss: 0.5963695049285889\n",
            "Epoch 6217: train loss: 0.5963280200958252\n",
            "Epoch 6218: train loss: 0.5962864756584167\n",
            "Epoch 6219: train loss: 0.5962449312210083\n",
            "Epoch 6220: train loss: 0.5962035059928894\n",
            "Epoch 6221: train loss: 0.5961620211601257\n",
            "Epoch 6222: train loss: 0.5961205959320068\n",
            "Epoch 6223: train loss: 0.5960791110992432\n",
            "Epoch 6224: train loss: 0.5960376262664795\n",
            "Epoch 6225: train loss: 0.5959961414337158\n",
            "Epoch 6226: train loss: 0.5959547162055969\n",
            "Epoch 6227: train loss: 0.5959133505821228\n",
            "Epoch 6228: train loss: 0.5958719253540039\n",
            "Epoch 6229: train loss: 0.5958305597305298\n",
            "Epoch 6230: train loss: 0.5957891345024109\n",
            "Epoch 6231: train loss: 0.5957478284835815\n",
            "Epoch 6232: train loss: 0.5957064032554626\n",
            "Epoch 6233: train loss: 0.5956650972366333\n",
            "Epoch 6234: train loss: 0.5956237316131592\n",
            "Epoch 6235: train loss: 0.5955824255943298\n",
            "Epoch 6236: train loss: 0.5955410599708557\n",
            "Epoch 6237: train loss: 0.5954997539520264\n",
            "Epoch 6238: train loss: 0.595458447933197\n",
            "Epoch 6239: train loss: 0.5954172015190125\n",
            "Epoch 6240: train loss: 0.5953758955001831\n",
            "Epoch 6241: train loss: 0.5953346490859985\n",
            "Epoch 6242: train loss: 0.595293402671814\n",
            "Epoch 6243: train loss: 0.5952521562576294\n",
            "Epoch 6244: train loss: 0.5952109098434448\n",
            "Epoch 6245: train loss: 0.5951696634292603\n",
            "Epoch 6246: train loss: 0.5951284766197205\n",
            "Epoch 6247: train loss: 0.5950872898101807\n",
            "Epoch 6248: train loss: 0.5950460433959961\n",
            "Epoch 6249: train loss: 0.5950049161911011\n",
            "Epoch 6250: train loss: 0.5949637293815613\n",
            "Epoch 6251: train loss: 0.5949226021766663\n",
            "Epoch 6252: train loss: 0.5948814153671265\n",
            "Epoch 6253: train loss: 0.5948403477668762\n",
            "Epoch 6254: train loss: 0.5947991609573364\n",
            "Epoch 6255: train loss: 0.5947579741477966\n",
            "Epoch 6256: train loss: 0.5947169065475464\n",
            "Epoch 6257: train loss: 0.5946758389472961\n",
            "Epoch 6258: train loss: 0.5946347713470459\n",
            "Epoch 6259: train loss: 0.5945937037467957\n",
            "Epoch 6260: train loss: 0.5945526361465454\n",
            "Epoch 6261: train loss: 0.5945115685462952\n",
            "Epoch 6262: train loss: 0.5944705605506897\n",
            "Epoch 6263: train loss: 0.594429612159729\n",
            "Epoch 6264: train loss: 0.5943885445594788\n",
            "Epoch 6265: train loss: 0.5943474769592285\n",
            "Epoch 6266: train loss: 0.5943065881729126\n",
            "Epoch 6267: train loss: 0.5942655801773071\n",
            "Epoch 6268: train loss: 0.5942245721817017\n",
            "Epoch 6269: train loss: 0.594183623790741\n",
            "Epoch 6270: train loss: 0.5941426753997803\n",
            "Epoch 6271: train loss: 0.5941017270088196\n",
            "Epoch 6272: train loss: 0.5940608978271484\n",
            "Epoch 6273: train loss: 0.594019889831543\n",
            "Epoch 6274: train loss: 0.5939789414405823\n",
            "Epoch 6275: train loss: 0.5939381122589111\n",
            "Epoch 6276: train loss: 0.5938972234725952\n",
            "Epoch 6277: train loss: 0.5938563346862793\n",
            "Epoch 6278: train loss: 0.5938155055046082\n",
            "Epoch 6279: train loss: 0.593774676322937\n",
            "Epoch 6280: train loss: 0.5937338471412659\n",
            "Epoch 6281: train loss: 0.5936930179595947\n",
            "Epoch 6282: train loss: 0.5936521887779236\n",
            "Epoch 6283: train loss: 0.5936113595962524\n",
            "Epoch 6284: train loss: 0.5935705900192261\n",
            "Epoch 6285: train loss: 0.5935297608375549\n",
            "Epoch 6286: train loss: 0.5934890508651733\n",
            "Epoch 6287: train loss: 0.593448281288147\n",
            "Epoch 6288: train loss: 0.5934075117111206\n",
            "Epoch 6289: train loss: 0.593366801738739\n",
            "Epoch 6290: train loss: 0.5933260321617126\n",
            "Epoch 6291: train loss: 0.593285322189331\n",
            "Epoch 6292: train loss: 0.5932446122169495\n",
            "Epoch 6293: train loss: 0.5932039618492126\n",
            "Epoch 6294: train loss: 0.593163251876831\n",
            "Epoch 6295: train loss: 0.5931225419044495\n",
            "Epoch 6296: train loss: 0.5930819511413574\n",
            "Epoch 6297: train loss: 0.5930413007736206\n",
            "Epoch 6298: train loss: 0.5930006504058838\n",
            "Epoch 6299: train loss: 0.592960000038147\n",
            "Epoch 6300: train loss: 0.5929194688796997\n",
            "Epoch 6301: train loss: 0.5928788781166077\n",
            "Epoch 6302: train loss: 0.5928382277488708\n",
            "Epoch 6303: train loss: 0.5927976965904236\n",
            "Epoch 6304: train loss: 0.5927571654319763\n",
            "Epoch 6305: train loss: 0.5927165746688843\n",
            "Epoch 6306: train loss: 0.5926761031150818\n",
            "Epoch 6307: train loss: 0.5926355123519897\n",
            "Epoch 6308: train loss: 0.5925949811935425\n",
            "Epoch 6309: train loss: 0.5925544500350952\n",
            "Epoch 6310: train loss: 0.5925139784812927\n",
            "Epoch 6311: train loss: 0.592473566532135\n",
            "Epoch 6312: train loss: 0.5924330353736877\n",
            "Epoch 6313: train loss: 0.59239262342453\n",
            "Epoch 6314: train loss: 0.5923520922660828\n",
            "Epoch 6315: train loss: 0.592311680316925\n",
            "Epoch 6316: train loss: 0.5922712683677673\n",
            "Epoch 6317: train loss: 0.5922308564186096\n",
            "Epoch 6318: train loss: 0.5921904444694519\n",
            "Epoch 6319: train loss: 0.5921500325202942\n",
            "Epoch 6320: train loss: 0.5921096801757812\n",
            "Epoch 6321: train loss: 0.5920693278312683\n",
            "Epoch 6322: train loss: 0.5920289158821106\n",
            "Epoch 6323: train loss: 0.5919885635375977\n",
            "Epoch 6324: train loss: 0.5919482707977295\n",
            "Epoch 6325: train loss: 0.5919079184532166\n",
            "Epoch 6326: train loss: 0.5918676257133484\n",
            "Epoch 6327: train loss: 0.5918272733688354\n",
            "Epoch 6328: train loss: 0.5917869806289673\n",
            "Epoch 6329: train loss: 0.5917467474937439\n",
            "Epoch 6330: train loss: 0.5917064547538757\n",
            "Epoch 6331: train loss: 0.5916662812232971\n",
            "Epoch 6332: train loss: 0.5916259288787842\n",
            "Epoch 6333: train loss: 0.5915857553482056\n",
            "Epoch 6334: train loss: 0.591545581817627\n",
            "Epoch 6335: train loss: 0.5915052890777588\n",
            "Epoch 6336: train loss: 0.5914651155471802\n",
            "Epoch 6337: train loss: 0.5914249420166016\n",
            "Epoch 6338: train loss: 0.591384768486023\n",
            "Epoch 6339: train loss: 0.5913445949554443\n",
            "Epoch 6340: train loss: 0.591304361820221\n",
            "Epoch 6341: train loss: 0.5912643671035767\n",
            "Epoch 6342: train loss: 0.5912241339683533\n",
            "Epoch 6343: train loss: 0.591184139251709\n",
            "Epoch 6344: train loss: 0.5911439657211304\n",
            "Epoch 6345: train loss: 0.5911038517951965\n",
            "Epoch 6346: train loss: 0.5910637974739075\n",
            "Epoch 6347: train loss: 0.5910237431526184\n",
            "Epoch 6348: train loss: 0.5909836888313293\n",
            "Epoch 6349: train loss: 0.5909436941146851\n",
            "Epoch 6350: train loss: 0.590903639793396\n",
            "Epoch 6351: train loss: 0.5908635854721069\n",
            "Epoch 6352: train loss: 0.5908235907554626\n",
            "Epoch 6353: train loss: 0.5907835364341736\n",
            "Epoch 6354: train loss: 0.5907436013221741\n",
            "Epoch 6355: train loss: 0.5907036066055298\n",
            "Epoch 6356: train loss: 0.5906636714935303\n",
            "Epoch 6357: train loss: 0.5906237959861755\n",
            "Epoch 6358: train loss: 0.5905837416648865\n",
            "Epoch 6359: train loss: 0.5905438661575317\n",
            "Epoch 6360: train loss: 0.5905039310455322\n",
            "Epoch 6361: train loss: 0.5904640555381775\n",
            "Epoch 6362: train loss: 0.5904242396354675\n",
            "Epoch 6363: train loss: 0.5903842449188232\n",
            "Epoch 6364: train loss: 0.5903443694114685\n",
            "Epoch 6365: train loss: 0.5903045535087585\n",
            "Epoch 6366: train loss: 0.5902647376060486\n",
            "Epoch 6367: train loss: 0.5902248024940491\n",
            "Epoch 6368: train loss: 0.5901850461959839\n",
            "Epoch 6369: train loss: 0.5901452898979187\n",
            "Epoch 6370: train loss: 0.590105414390564\n",
            "Epoch 6371: train loss: 0.5900656580924988\n",
            "Epoch 6372: train loss: 0.5900259017944336\n",
            "Epoch 6373: train loss: 0.5899861454963684\n",
            "Epoch 6374: train loss: 0.5899463891983032\n",
            "Epoch 6375: train loss: 0.5899066925048828\n",
            "Epoch 6376: train loss: 0.5898669958114624\n",
            "Epoch 6377: train loss: 0.5898272395133972\n",
            "Epoch 6378: train loss: 0.589787483215332\n",
            "Epoch 6379: train loss: 0.5897477865219116\n",
            "Epoch 6380: train loss: 0.5897082090377808\n",
            "Epoch 6381: train loss: 0.5896684527397156\n",
            "Epoch 6382: train loss: 0.5896288752555847\n",
            "Epoch 6383: train loss: 0.5895891785621643\n",
            "Epoch 6384: train loss: 0.5895495414733887\n",
            "Epoch 6385: train loss: 0.5895099639892578\n",
            "Epoch 6386: train loss: 0.5894703269004822\n",
            "Epoch 6387: train loss: 0.5894307494163513\n",
            "Epoch 6388: train loss: 0.5893912315368652\n",
            "Epoch 6389: train loss: 0.5893515944480896\n",
            "Epoch 6390: train loss: 0.5893120169639587\n",
            "Epoch 6391: train loss: 0.5892724394798279\n",
            "Epoch 6392: train loss: 0.5892329812049866\n",
            "Epoch 6393: train loss: 0.5891934633255005\n",
            "Epoch 6394: train loss: 0.5891539454460144\n",
            "Epoch 6395: train loss: 0.5891144871711731\n",
            "Epoch 6396: train loss: 0.589074969291687\n",
            "Epoch 6397: train loss: 0.5890355110168457\n",
            "Epoch 6398: train loss: 0.5889960527420044\n",
            "Epoch 6399: train loss: 0.5889565944671631\n",
            "Epoch 6400: train loss: 0.5889171361923218\n",
            "Epoch 6401: train loss: 0.58887779712677\n",
            "Epoch 6402: train loss: 0.5888383388519287\n",
            "Epoch 6403: train loss: 0.5887989401817322\n",
            "Epoch 6404: train loss: 0.5887595415115356\n",
            "Epoch 6405: train loss: 0.5887201428413391\n",
            "Epoch 6406: train loss: 0.5886808037757874\n",
            "Epoch 6407: train loss: 0.5886414051055908\n",
            "Epoch 6408: train loss: 0.5886020660400391\n",
            "Epoch 6409: train loss: 0.5885626673698425\n",
            "Epoch 6410: train loss: 0.5885233879089355\n",
            "Epoch 6411: train loss: 0.5884841084480286\n",
            "Epoch 6412: train loss: 0.5884448289871216\n",
            "Epoch 6413: train loss: 0.5884055495262146\n",
            "Epoch 6414: train loss: 0.5883662700653076\n",
            "Epoch 6415: train loss: 0.5883270502090454\n",
            "Epoch 6416: train loss: 0.5882877111434937\n",
            "Epoch 6417: train loss: 0.5882485508918762\n",
            "Epoch 6418: train loss: 0.588209331035614\n",
            "Epoch 6419: train loss: 0.588170051574707\n",
            "Epoch 6420: train loss: 0.5881309509277344\n",
            "Epoch 6421: train loss: 0.5880917310714722\n",
            "Epoch 6422: train loss: 0.5880525708198547\n",
            "Epoch 6423: train loss: 0.5880134701728821\n",
            "Epoch 6424: train loss: 0.5879741907119751\n",
            "Epoch 6425: train loss: 0.5879351496696472\n",
            "Epoch 6426: train loss: 0.5878959894180298\n",
            "Epoch 6427: train loss: 0.5878568887710571\n",
            "Epoch 6428: train loss: 0.5878177285194397\n",
            "Epoch 6429: train loss: 0.5877786874771118\n",
            "Epoch 6430: train loss: 0.5877395868301392\n",
            "Epoch 6431: train loss: 0.5877005457878113\n",
            "Epoch 6432: train loss: 0.5876614451408386\n",
            "Epoch 6433: train loss: 0.5876224637031555\n",
            "Epoch 6434: train loss: 0.5875834226608276\n",
            "Epoch 6435: train loss: 0.5875443816184998\n",
            "Epoch 6436: train loss: 0.5875053405761719\n",
            "Epoch 6437: train loss: 0.5874664187431335\n",
            "Epoch 6438: train loss: 0.5874273777008057\n",
            "Epoch 6439: train loss: 0.5873884558677673\n",
            "Epoch 6440: train loss: 0.587349534034729\n",
            "Epoch 6441: train loss: 0.5873105525970459\n",
            "Epoch 6442: train loss: 0.5872716307640076\n",
            "Epoch 6443: train loss: 0.5872326493263245\n",
            "Epoch 6444: train loss: 0.5871937870979309\n",
            "Epoch 6445: train loss: 0.5871549248695374\n",
            "Epoch 6446: train loss: 0.587116003036499\n",
            "Epoch 6447: train loss: 0.5870771408081055\n",
            "Epoch 6448: train loss: 0.5870382189750671\n",
            "Epoch 6449: train loss: 0.5869994163513184\n",
            "Epoch 6450: train loss: 0.5869606137275696\n",
            "Epoch 6451: train loss: 0.5869218707084656\n",
            "Epoch 6452: train loss: 0.5868829488754272\n",
            "Epoch 6453: train loss: 0.5868441462516785\n",
            "Epoch 6454: train loss: 0.5868054032325745\n",
            "Epoch 6455: train loss: 0.5867666602134705\n",
            "Epoch 6456: train loss: 0.5867278575897217\n",
            "Epoch 6457: train loss: 0.5866891145706177\n",
            "Epoch 6458: train loss: 0.5866504311561584\n",
            "Epoch 6459: train loss: 0.5866117477416992\n",
            "Epoch 6460: train loss: 0.5865729451179504\n",
            "Epoch 6461: train loss: 0.5865342617034912\n",
            "Epoch 6462: train loss: 0.586495578289032\n",
            "Epoch 6463: train loss: 0.5864569544792175\n",
            "Epoch 6464: train loss: 0.5864182710647583\n",
            "Epoch 6465: train loss: 0.5863795876502991\n",
            "Epoch 6466: train loss: 0.5863410234451294\n",
            "Epoch 6467: train loss: 0.5863023400306702\n",
            "Epoch 6468: train loss: 0.5862636566162109\n",
            "Epoch 6469: train loss: 0.586225152015686\n",
            "Epoch 6470: train loss: 0.5861865282058716\n",
            "Epoch 6471: train loss: 0.5861479640007019\n",
            "Epoch 6472: train loss: 0.5861093997955322\n",
            "Epoch 6473: train loss: 0.5860707759857178\n",
            "Epoch 6474: train loss: 0.5860322713851929\n",
            "Epoch 6475: train loss: 0.585993766784668\n",
            "Epoch 6476: train loss: 0.5859552621841431\n",
            "Epoch 6477: train loss: 0.5859166979789734\n",
            "Epoch 6478: train loss: 0.585878312587738\n",
            "Epoch 6479: train loss: 0.5858398079872131\n",
            "Epoch 6480: train loss: 0.5858013033866882\n",
            "Epoch 6481: train loss: 0.5857627987861633\n",
            "Epoch 6482: train loss: 0.5857243537902832\n",
            "Epoch 6483: train loss: 0.5856860280036926\n",
            "Epoch 6484: train loss: 0.5856475830078125\n",
            "Epoch 6485: train loss: 0.5856091380119324\n",
            "Epoch 6486: train loss: 0.585570752620697\n",
            "Epoch 6487: train loss: 0.5855323672294617\n",
            "Epoch 6488: train loss: 0.5854940414428711\n",
            "Epoch 6489: train loss: 0.5854556560516357\n",
            "Epoch 6490: train loss: 0.5854172706604004\n",
            "Epoch 6491: train loss: 0.5853789448738098\n",
            "Epoch 6492: train loss: 0.585340678691864\n",
            "Epoch 6493: train loss: 0.5853023529052734\n",
            "Epoch 6494: train loss: 0.5852641463279724\n",
            "Epoch 6495: train loss: 0.5852258205413818\n",
            "Epoch 6496: train loss: 0.585187554359436\n",
            "Epoch 6497: train loss: 0.5851492881774902\n",
            "Epoch 6498: train loss: 0.5851110219955444\n",
            "Epoch 6499: train loss: 0.5850728154182434\n",
            "Epoch 6500: train loss: 0.5850346088409424\n",
            "Epoch 6501: train loss: 0.5849963426589966\n",
            "Epoch 6502: train loss: 0.5849581360816956\n",
            "Epoch 6503: train loss: 0.5849199295043945\n",
            "Epoch 6504: train loss: 0.5848817825317383\n",
            "Epoch 6505: train loss: 0.584843635559082\n",
            "Epoch 6506: train loss: 0.5848054885864258\n",
            "Epoch 6507: train loss: 0.5847673416137695\n",
            "Epoch 6508: train loss: 0.5847292542457581\n",
            "Epoch 6509: train loss: 0.5846911668777466\n",
            "Epoch 6510: train loss: 0.5846530199050903\n",
            "Epoch 6511: train loss: 0.5846149921417236\n",
            "Epoch 6512: train loss: 0.5845768451690674\n",
            "Epoch 6513: train loss: 0.5845388174057007\n",
            "Epoch 6514: train loss: 0.584500789642334\n",
            "Epoch 6515: train loss: 0.5844627618789673\n",
            "Epoch 6516: train loss: 0.5844246745109558\n",
            "Epoch 6517: train loss: 0.5843866467475891\n",
            "Epoch 6518: train loss: 0.5843486785888672\n",
            "Epoch 6519: train loss: 0.5843107104301453\n",
            "Epoch 6520: train loss: 0.5842727422714233\n",
            "Epoch 6521: train loss: 0.5842347741127014\n",
            "Epoch 6522: train loss: 0.5841968059539795\n",
            "Epoch 6523: train loss: 0.5841589570045471\n",
            "Epoch 6524: train loss: 0.58412104845047\n",
            "Epoch 6525: train loss: 0.5840830206871033\n",
            "Epoch 6526: train loss: 0.5840451717376709\n",
            "Epoch 6527: train loss: 0.5840072631835938\n",
            "Epoch 6528: train loss: 0.5839694738388062\n",
            "Epoch 6529: train loss: 0.583931565284729\n",
            "Epoch 6530: train loss: 0.5838936567306519\n",
            "Epoch 6531: train loss: 0.5838558673858643\n",
            "Epoch 6532: train loss: 0.5838180184364319\n",
            "Epoch 6533: train loss: 0.5837802290916443\n",
            "Epoch 6534: train loss: 0.5837423205375671\n",
            "Epoch 6535: train loss: 0.5837045907974243\n",
            "Epoch 6536: train loss: 0.5836668610572815\n",
            "Epoch 6537: train loss: 0.5836290717124939\n",
            "Epoch 6538: train loss: 0.5835912823677063\n",
            "Epoch 6539: train loss: 0.5835536122322083\n",
            "Epoch 6540: train loss: 0.5835158228874207\n",
            "Epoch 6541: train loss: 0.5834781527519226\n",
            "Epoch 6542: train loss: 0.5834404230117798\n",
            "Epoch 6543: train loss: 0.583402693271637\n",
            "Epoch 6544: train loss: 0.5833650231361389\n",
            "Epoch 6545: train loss: 0.5833273530006409\n",
            "Epoch 6546: train loss: 0.5832897424697876\n",
            "Epoch 6547: train loss: 0.5832520723342896\n",
            "Epoch 6548: train loss: 0.5832144021987915\n",
            "Epoch 6549: train loss: 0.583176851272583\n",
            "Epoch 6550: train loss: 0.5831393003463745\n",
            "Epoch 6551: train loss: 0.5831016302108765\n",
            "Epoch 6552: train loss: 0.5830640196800232\n",
            "Epoch 6553: train loss: 0.5830264687538147\n",
            "Epoch 6554: train loss: 0.582988977432251\n",
            "Epoch 6555: train loss: 0.5829513669013977\n",
            "Epoch 6556: train loss: 0.5829138159751892\n",
            "Epoch 6557: train loss: 0.5828762650489807\n",
            "Epoch 6558: train loss: 0.5828388333320618\n",
            "Epoch 6559: train loss: 0.582801342010498\n",
            "Epoch 6560: train loss: 0.5827638506889343\n",
            "Epoch 6561: train loss: 0.5827263593673706\n",
            "Epoch 6562: train loss: 0.5826889276504517\n",
            "Epoch 6563: train loss: 0.5826514959335327\n",
            "Epoch 6564: train loss: 0.5826140642166138\n",
            "Epoch 6565: train loss: 0.5825766324996948\n",
            "Epoch 6566: train loss: 0.5825392603874207\n",
            "Epoch 6567: train loss: 0.5825018882751465\n",
            "Epoch 6568: train loss: 0.5824643969535828\n",
            "Epoch 6569: train loss: 0.5824270844459534\n",
            "Epoch 6570: train loss: 0.582389771938324\n",
            "Epoch 6571: train loss: 0.582352340221405\n",
            "Epoch 6572: train loss: 0.5823150873184204\n",
            "Epoch 6573: train loss: 0.582277774810791\n",
            "Epoch 6574: train loss: 0.5822404026985168\n",
            "Epoch 6575: train loss: 0.5822031497955322\n",
            "Epoch 6576: train loss: 0.5821658372879028\n",
            "Epoch 6577: train loss: 0.5821285247802734\n",
            "Epoch 6578: train loss: 0.5820913314819336\n",
            "Epoch 6579: train loss: 0.582054078578949\n",
            "Epoch 6580: train loss: 0.5820168256759644\n",
            "Epoch 6581: train loss: 0.5819796323776245\n",
            "Epoch 6582: train loss: 0.5819424390792847\n",
            "Epoch 6583: train loss: 0.5819051861763\n",
            "Epoch 6584: train loss: 0.5818679928779602\n",
            "Epoch 6585: train loss: 0.5818308591842651\n",
            "Epoch 6586: train loss: 0.5817937254905701\n",
            "Epoch 6587: train loss: 0.5817565321922302\n",
            "Epoch 6588: train loss: 0.5817193388938904\n",
            "Epoch 6589: train loss: 0.5816822648048401\n",
            "Epoch 6590: train loss: 0.5816451907157898\n",
            "Epoch 6591: train loss: 0.5816081166267395\n",
            "Epoch 6592: train loss: 0.5815709233283997\n",
            "Epoch 6593: train loss: 0.5815339088439941\n",
            "Epoch 6594: train loss: 0.5814967751502991\n",
            "Epoch 6595: train loss: 0.5814597606658936\n",
            "Epoch 6596: train loss: 0.581422746181488\n",
            "Epoch 6597: train loss: 0.5813857913017273\n",
            "Epoch 6598: train loss: 0.5813486576080322\n",
            "Epoch 6599: train loss: 0.5813117027282715\n",
            "Epoch 6600: train loss: 0.581274688243866\n",
            "Epoch 6601: train loss: 0.5812376737594604\n",
            "Epoch 6602: train loss: 0.5812007188796997\n",
            "Epoch 6603: train loss: 0.581163763999939\n",
            "Epoch 6604: train loss: 0.581126868724823\n",
            "Epoch 6605: train loss: 0.581089973449707\n",
            "Epoch 6606: train loss: 0.5810530781745911\n",
            "Epoch 6607: train loss: 0.5810161232948303\n",
            "Epoch 6608: train loss: 0.5809792280197144\n",
            "Epoch 6609: train loss: 0.5809423923492432\n",
            "Epoch 6610: train loss: 0.5809054374694824\n",
            "Epoch 6611: train loss: 0.5808686017990112\n",
            "Epoch 6612: train loss: 0.5808318257331848\n",
            "Epoch 6613: train loss: 0.5807949900627136\n",
            "Epoch 6614: train loss: 0.5807581543922424\n",
            "Epoch 6615: train loss: 0.5807213187217712\n",
            "Epoch 6616: train loss: 0.5806845426559448\n",
            "Epoch 6617: train loss: 0.5806477665901184\n",
            "Epoch 6618: train loss: 0.5806110501289368\n",
            "Epoch 6619: train loss: 0.5805742740631104\n",
            "Epoch 6620: train loss: 0.5805374979972839\n",
            "Epoch 6621: train loss: 0.5805007815361023\n",
            "Epoch 6622: train loss: 0.5804640650749207\n",
            "Epoch 6623: train loss: 0.580427348613739\n",
            "Epoch 6624: train loss: 0.5803906321525574\n",
            "Epoch 6625: train loss: 0.5803539752960205\n",
            "Epoch 6626: train loss: 0.5803173184394836\n",
            "Epoch 6627: train loss: 0.5802806615829468\n",
            "Epoch 6628: train loss: 0.5802440047264099\n",
            "Epoch 6629: train loss: 0.580207347869873\n",
            "Epoch 6630: train loss: 0.5801706910133362\n",
            "Epoch 6631: train loss: 0.5801342129707336\n",
            "Epoch 6632: train loss: 0.5800976157188416\n",
            "Epoch 6633: train loss: 0.5800609588623047\n",
            "Epoch 6634: train loss: 0.5800243616104126\n",
            "Epoch 6635: train loss: 0.5799878239631653\n",
            "Epoch 6636: train loss: 0.579951286315918\n",
            "Epoch 6637: train loss: 0.5799147486686707\n",
            "Epoch 6638: train loss: 0.5798782706260681\n",
            "Epoch 6639: train loss: 0.5798417329788208\n",
            "Epoch 6640: train loss: 0.5798051953315735\n",
            "Epoch 6641: train loss: 0.579768717288971\n",
            "Epoch 6642: train loss: 0.5797322988510132\n",
            "Epoch 6643: train loss: 0.5796957612037659\n",
            "Epoch 6644: train loss: 0.5796593427658081\n",
            "Epoch 6645: train loss: 0.5796229243278503\n",
            "Epoch 6646: train loss: 0.5795865654945374\n",
            "Epoch 6647: train loss: 0.5795500874519348\n",
            "Epoch 6648: train loss: 0.579513669013977\n",
            "Epoch 6649: train loss: 0.5794773101806641\n",
            "Epoch 6650: train loss: 0.5794408917427063\n",
            "Epoch 6651: train loss: 0.5794046521186829\n",
            "Epoch 6652: train loss: 0.5793681740760803\n",
            "Epoch 6653: train loss: 0.5793318748474121\n",
            "Epoch 6654: train loss: 0.5792954564094543\n",
            "Epoch 6655: train loss: 0.5792592167854309\n",
            "Epoch 6656: train loss: 0.5792229771614075\n",
            "Epoch 6657: train loss: 0.5791866183280945\n",
            "Epoch 6658: train loss: 0.579150378704071\n",
            "Epoch 6659: train loss: 0.5791140794754028\n",
            "Epoch 6660: train loss: 0.5790778994560242\n",
            "Epoch 6661: train loss: 0.5790415406227112\n",
            "Epoch 6662: train loss: 0.5790053606033325\n",
            "Epoch 6663: train loss: 0.5789691805839539\n",
            "Epoch 6664: train loss: 0.5789329409599304\n",
            "Epoch 6665: train loss: 0.5788967609405518\n",
            "Epoch 6666: train loss: 0.5788605809211731\n",
            "Epoch 6667: train loss: 0.5788244009017944\n",
            "Epoch 6668: train loss: 0.5787882804870605\n",
            "Epoch 6669: train loss: 0.5787521004676819\n",
            "Epoch 6670: train loss: 0.5787159204483032\n",
            "Epoch 6671: train loss: 0.5786798596382141\n",
            "Epoch 6672: train loss: 0.5786437392234802\n",
            "Epoch 6673: train loss: 0.5786076188087463\n",
            "Epoch 6674: train loss: 0.578571617603302\n",
            "Epoch 6675: train loss: 0.5785354375839233\n",
            "Epoch 6676: train loss: 0.578499436378479\n",
            "Epoch 6677: train loss: 0.5784633755683899\n",
            "Epoch 6678: train loss: 0.5784273147583008\n",
            "Epoch 6679: train loss: 0.5783913731575012\n",
            "Epoch 6680: train loss: 0.5783553123474121\n",
            "Epoch 6681: train loss: 0.578319251537323\n",
            "Epoch 6682: train loss: 0.5782833099365234\n",
            "Epoch 6683: train loss: 0.5782473087310791\n",
            "Epoch 6684: train loss: 0.5782113671302795\n",
            "Epoch 6685: train loss: 0.57817542552948\n",
            "Epoch 6686: train loss: 0.5781395435333252\n",
            "Epoch 6687: train loss: 0.5781036019325256\n",
            "Epoch 6688: train loss: 0.5780676007270813\n",
            "Epoch 6689: train loss: 0.5780317783355713\n",
            "Epoch 6690: train loss: 0.5779958963394165\n",
            "Epoch 6691: train loss: 0.5779600739479065\n",
            "Epoch 6692: train loss: 0.5779241323471069\n",
            "Epoch 6693: train loss: 0.5778882503509521\n",
            "Epoch 6694: train loss: 0.5778524279594421\n",
            "Epoch 6695: train loss: 0.5778166651725769\n",
            "Epoch 6696: train loss: 0.5777808427810669\n",
            "Epoch 6697: train loss: 0.5777449607849121\n",
            "Epoch 6698: train loss: 0.5777092576026917\n",
            "Epoch 6699: train loss: 0.5776734352111816\n",
            "Epoch 6700: train loss: 0.5776376724243164\n",
            "Epoch 6701: train loss: 0.5776018500328064\n",
            "Epoch 6702: train loss: 0.5775661468505859\n",
            "Epoch 6703: train loss: 0.5775304436683655\n",
            "Epoch 6704: train loss: 0.577494740486145\n",
            "Epoch 6705: train loss: 0.5774589776992798\n",
            "Epoch 6706: train loss: 0.5774233341217041\n",
            "Epoch 6707: train loss: 0.5773876309394836\n",
            "Epoch 6708: train loss: 0.5773519277572632\n",
            "Epoch 6709: train loss: 0.5773162841796875\n",
            "Epoch 6710: train loss: 0.577280580997467\n",
            "Epoch 6711: train loss: 0.5772449970245361\n",
            "Epoch 6712: train loss: 0.5772093534469604\n",
            "Epoch 6713: train loss: 0.5771737694740295\n",
            "Epoch 6714: train loss: 0.5771380662918091\n",
            "Epoch 6715: train loss: 0.577102541923523\n",
            "Epoch 6716: train loss: 0.5770670175552368\n",
            "Epoch 6717: train loss: 0.5770314335823059\n",
            "Epoch 6718: train loss: 0.5769959092140198\n",
            "Epoch 6719: train loss: 0.5769603252410889\n",
            "Epoch 6720: train loss: 0.5769248008728027\n",
            "Epoch 6721: train loss: 0.5768893361091614\n",
            "Epoch 6722: train loss: 0.5768538117408752\n",
            "Epoch 6723: train loss: 0.5768182873725891\n",
            "Epoch 6724: train loss: 0.5767828822135925\n",
            "Epoch 6725: train loss: 0.5767473578453064\n",
            "Epoch 6726: train loss: 0.576711893081665\n",
            "Epoch 6727: train loss: 0.5766764283180237\n",
            "Epoch 6728: train loss: 0.5766409635543823\n",
            "Epoch 6729: train loss: 0.5766056180000305\n",
            "Epoch 6730: train loss: 0.5765702128410339\n",
            "Epoch 6731: train loss: 0.5765348672866821\n",
            "Epoch 6732: train loss: 0.5764994025230408\n",
            "Epoch 6733: train loss: 0.576464056968689\n",
            "Epoch 6734: train loss: 0.5764286518096924\n",
            "Epoch 6735: train loss: 0.5763933062553406\n",
            "Epoch 6736: train loss: 0.5763580203056335\n",
            "Epoch 6737: train loss: 0.5763225555419922\n",
            "Epoch 6738: train loss: 0.5762873291969299\n",
            "Epoch 6739: train loss: 0.5762521028518677\n",
            "Epoch 6740: train loss: 0.5762167572975159\n",
            "Epoch 6741: train loss: 0.5761814713478088\n",
            "Epoch 6742: train loss: 0.5761462450027466\n",
            "Epoch 6743: train loss: 0.5761109590530396\n",
            "Epoch 6744: train loss: 0.5760757923126221\n",
            "Epoch 6745: train loss: 0.5760404467582703\n",
            "Epoch 6746: train loss: 0.5760052800178528\n",
            "Epoch 6747: train loss: 0.5759701132774353\n",
            "Epoch 6748: train loss: 0.575934886932373\n",
            "Epoch 6749: train loss: 0.5758997201919556\n",
            "Epoch 6750: train loss: 0.5758645534515381\n",
            "Epoch 6751: train loss: 0.5758293271064758\n",
            "Epoch 6752: train loss: 0.5757942795753479\n",
            "Epoch 6753: train loss: 0.5757591724395752\n",
            "Epoch 6754: train loss: 0.5757240056991577\n",
            "Epoch 6755: train loss: 0.575688898563385\n",
            "Epoch 6756: train loss: 0.5756537318229675\n",
            "Epoch 6757: train loss: 0.5756186842918396\n",
            "Epoch 6758: train loss: 0.5755836367607117\n",
            "Epoch 6759: train loss: 0.575548529624939\n",
            "Epoch 6760: train loss: 0.575513482093811\n",
            "Epoch 6761: train loss: 0.5754784345626831\n",
            "Epoch 6762: train loss: 0.5754434466362\n",
            "Epoch 6763: train loss: 0.575408399105072\n",
            "Epoch 6764: train loss: 0.5753734111785889\n",
            "Epoch 6765: train loss: 0.5753384232521057\n",
            "Epoch 6766: train loss: 0.5753034353256226\n",
            "Epoch 6767: train loss: 0.5752684473991394\n",
            "Epoch 6768: train loss: 0.575233519077301\n",
            "Epoch 6769: train loss: 0.5751985907554626\n",
            "Epoch 6770: train loss: 0.5751636028289795\n",
            "Epoch 6771: train loss: 0.5751287341117859\n",
            "Epoch 6772: train loss: 0.5750938057899475\n",
            "Epoch 6773: train loss: 0.5750588774681091\n",
            "Epoch 6774: train loss: 0.5750240087509155\n",
            "Epoch 6775: train loss: 0.5749891996383667\n",
            "Epoch 6776: train loss: 0.5749543309211731\n",
            "Epoch 6777: train loss: 0.5749194622039795\n",
            "Epoch 6778: train loss: 0.5748845934867859\n",
            "Epoch 6779: train loss: 0.5748498439788818\n",
            "Epoch 6780: train loss: 0.5748149156570435\n",
            "Epoch 6781: train loss: 0.5747801661491394\n",
            "Epoch 6782: train loss: 0.5747454166412354\n",
            "Epoch 6783: train loss: 0.5747105479240417\n",
            "Epoch 6784: train loss: 0.5746758580207825\n",
            "Epoch 6785: train loss: 0.5746410489082336\n",
            "Epoch 6786: train loss: 0.5746062994003296\n",
            "Epoch 6787: train loss: 0.5745715498924255\n",
            "Epoch 6788: train loss: 0.5745368599891663\n",
            "Epoch 6789: train loss: 0.5745021104812622\n",
            "Epoch 6790: train loss: 0.5744674205780029\n",
            "Epoch 6791: train loss: 0.5744327902793884\n",
            "Epoch 6792: train loss: 0.5743981003761292\n",
            "Epoch 6793: train loss: 0.5743634700775146\n",
            "Epoch 6794: train loss: 0.5743287205696106\n",
            "Epoch 6795: train loss: 0.5742941498756409\n",
            "Epoch 6796: train loss: 0.5742595195770264\n",
            "Epoch 6797: train loss: 0.5742248892784119\n",
            "Epoch 6798: train loss: 0.5741902589797974\n",
            "Epoch 6799: train loss: 0.5741557478904724\n",
            "Epoch 6800: train loss: 0.5741211175918579\n",
            "Epoch 6801: train loss: 0.5740865468978882\n",
            "Epoch 6802: train loss: 0.5740520358085632\n",
            "Epoch 6803: train loss: 0.5740174055099487\n",
            "Epoch 6804: train loss: 0.5739828944206238\n",
            "Epoch 6805: train loss: 0.5739483833312988\n",
            "Epoch 6806: train loss: 0.5739138722419739\n",
            "Epoch 6807: train loss: 0.5738793611526489\n",
            "Epoch 6808: train loss: 0.573844850063324\n",
            "Epoch 6809: train loss: 0.5738103985786438\n",
            "Epoch 6810: train loss: 0.5737758874893188\n",
            "Epoch 6811: train loss: 0.5737414956092834\n",
            "Epoch 6812: train loss: 0.5737070441246033\n",
            "Epoch 6813: train loss: 0.5736725926399231\n",
            "Epoch 6814: train loss: 0.5736381411552429\n",
            "Epoch 6815: train loss: 0.5736038684844971\n",
            "Epoch 6816: train loss: 0.5735693573951721\n",
            "Epoch 6817: train loss: 0.5735349655151367\n",
            "Epoch 6818: train loss: 0.5735006332397461\n",
            "Epoch 6819: train loss: 0.5734662413597107\n",
            "Epoch 6820: train loss: 0.5734318494796753\n",
            "Epoch 6821: train loss: 0.5733976364135742\n",
            "Epoch 6822: train loss: 0.5733632445335388\n",
            "Epoch 6823: train loss: 0.573328971862793\n",
            "Epoch 6824: train loss: 0.5732946395874023\n",
            "Epoch 6825: train loss: 0.5732603073120117\n",
            "Epoch 6826: train loss: 0.5732260942459106\n",
            "Epoch 6827: train loss: 0.57319176197052\n",
            "Epoch 6828: train loss: 0.573157548904419\n",
            "Epoch 6829: train loss: 0.5731232762336731\n",
            "Epoch 6830: train loss: 0.5730890035629272\n",
            "Epoch 6831: train loss: 0.5730547308921814\n",
            "Epoch 6832: train loss: 0.5730205774307251\n",
            "Epoch 6833: train loss: 0.572986364364624\n",
            "Epoch 6834: train loss: 0.5729522109031677\n",
            "Epoch 6835: train loss: 0.5729179978370667\n",
            "Epoch 6836: train loss: 0.5728839039802551\n",
            "Epoch 6837: train loss: 0.5728497505187988\n",
            "Epoch 6838: train loss: 0.5728155374526978\n",
            "Epoch 6839: train loss: 0.5727813839912415\n",
            "Epoch 6840: train loss: 0.5727472901344299\n",
            "Epoch 6841: train loss: 0.5727131366729736\n",
            "Epoch 6842: train loss: 0.5726791024208069\n",
            "Epoch 6843: train loss: 0.5726450085639954\n",
            "Epoch 6844: train loss: 0.5726109147071838\n",
            "Epoch 6845: train loss: 0.5725768804550171\n",
            "Epoch 6846: train loss: 0.5725427865982056\n",
            "Epoch 6847: train loss: 0.5725087523460388\n",
            "Epoch 6848: train loss: 0.5724747776985168\n",
            "Epoch 6849: train loss: 0.5724406838417053\n",
            "Epoch 6850: train loss: 0.5724067091941833\n",
            "Epoch 6851: train loss: 0.5723727345466614\n",
            "Epoch 6852: train loss: 0.5723387002944946\n",
            "Epoch 6853: train loss: 0.5723047256469727\n",
            "Epoch 6854: train loss: 0.5722708106040955\n",
            "Epoch 6855: train loss: 0.5722368955612183\n",
            "Epoch 6856: train loss: 0.5722029209136963\n",
            "Epoch 6857: train loss: 0.5721689462661743\n",
            "Epoch 6858: train loss: 0.5721350908279419\n",
            "Epoch 6859: train loss: 0.5721011161804199\n",
            "Epoch 6860: train loss: 0.5720672607421875\n",
            "Epoch 6861: train loss: 0.5720334053039551\n",
            "Epoch 6862: train loss: 0.5719994902610779\n",
            "Epoch 6863: train loss: 0.5719656348228455\n",
            "Epoch 6864: train loss: 0.5719318389892578\n",
            "Epoch 6865: train loss: 0.5718979239463806\n",
            "Epoch 6866: train loss: 0.571864128112793\n",
            "Epoch 6867: train loss: 0.5718302726745605\n",
            "Epoch 6868: train loss: 0.5717964768409729\n",
            "Epoch 6869: train loss: 0.57176274061203\n",
            "Epoch 6870: train loss: 0.5717289447784424\n",
            "Epoch 6871: train loss: 0.5716952085494995\n",
            "Epoch 6872: train loss: 0.5716613531112671\n",
            "Epoch 6873: train loss: 0.5716276168823242\n",
            "Epoch 6874: train loss: 0.5715938806533813\n",
            "Epoch 6875: train loss: 0.5715602040290833\n",
            "Epoch 6876: train loss: 0.5715264081954956\n",
            "Epoch 6877: train loss: 0.5714927911758423\n",
            "Epoch 6878: train loss: 0.5714590549468994\n",
            "Epoch 6879: train loss: 0.5714254379272461\n",
            "Epoch 6880: train loss: 0.5713917016983032\n",
            "Epoch 6881: train loss: 0.5713580846786499\n",
            "Epoch 6882: train loss: 0.5713244080543518\n",
            "Epoch 6883: train loss: 0.5712907910346985\n",
            "Epoch 6884: train loss: 0.5712571144104004\n",
            "Epoch 6885: train loss: 0.5712235569953918\n",
            "Epoch 6886: train loss: 0.5711899399757385\n",
            "Epoch 6887: train loss: 0.5711563229560852\n",
            "Epoch 6888: train loss: 0.5711228251457214\n",
            "Epoch 6889: train loss: 0.5710891485214233\n",
            "Epoch 6890: train loss: 0.5710556507110596\n",
            "Epoch 6891: train loss: 0.571022093296051\n",
            "Epoch 6892: train loss: 0.5709885358810425\n",
            "Epoch 6893: train loss: 0.5709550380706787\n",
            "Epoch 6894: train loss: 0.5709214806556702\n",
            "Epoch 6895: train loss: 0.5708879232406616\n",
            "Epoch 6896: train loss: 0.5708545446395874\n",
            "Epoch 6897: train loss: 0.5708210468292236\n",
            "Epoch 6898: train loss: 0.5707874894142151\n",
            "Epoch 6899: train loss: 0.5707541108131409\n",
            "Epoch 6900: train loss: 0.5707206130027771\n",
            "Epoch 6901: train loss: 0.5706871747970581\n",
            "Epoch 6902: train loss: 0.5706538558006287\n",
            "Epoch 6903: train loss: 0.5706203579902649\n",
            "Epoch 6904: train loss: 0.5705869197845459\n",
            "Epoch 6905: train loss: 0.5705535411834717\n",
            "Epoch 6906: train loss: 0.5705202221870422\n",
            "Epoch 6907: train loss: 0.5704867839813232\n",
            "Epoch 6908: train loss: 0.570453405380249\n",
            "Epoch 6909: train loss: 0.5704200863838196\n",
            "Epoch 6910: train loss: 0.5703868269920349\n",
            "Epoch 6911: train loss: 0.5703533887863159\n",
            "Epoch 6912: train loss: 0.5703200697898865\n",
            "Epoch 6913: train loss: 0.5702868103981018\n",
            "Epoch 6914: train loss: 0.5702534317970276\n",
            "Epoch 6915: train loss: 0.5702202320098877\n",
            "Epoch 6916: train loss: 0.570186972618103\n",
            "Epoch 6917: train loss: 0.5701536536216736\n",
            "Epoch 6918: train loss: 0.5701204538345337\n",
            "Epoch 6919: train loss: 0.570087194442749\n",
            "Epoch 6920: train loss: 0.5700539350509644\n",
            "Epoch 6921: train loss: 0.5700207352638245\n",
            "Epoch 6922: train loss: 0.5699875950813293\n",
            "Epoch 6923: train loss: 0.5699543356895447\n",
            "Epoch 6924: train loss: 0.5699211955070496\n",
            "Epoch 6925: train loss: 0.5698879957199097\n",
            "Epoch 6926: train loss: 0.5698547959327698\n",
            "Epoch 6927: train loss: 0.5698216557502747\n",
            "Epoch 6928: train loss: 0.5697885155677795\n",
            "Epoch 6929: train loss: 0.5697553753852844\n",
            "Epoch 6930: train loss: 0.5697222352027893\n",
            "Epoch 6931: train loss: 0.5696890950202942\n",
            "Epoch 6932: train loss: 0.5696560144424438\n",
            "Epoch 6933: train loss: 0.5696229338645935\n",
            "Epoch 6934: train loss: 0.5695898532867432\n",
            "Epoch 6935: train loss: 0.5695567727088928\n",
            "Epoch 6936: train loss: 0.5695237517356873\n",
            "Epoch 6937: train loss: 0.5694906711578369\n",
            "Epoch 6938: train loss: 0.5694576501846313\n",
            "Epoch 6939: train loss: 0.5694246292114258\n",
            "Epoch 6940: train loss: 0.5693915486335754\n",
            "Epoch 6941: train loss: 0.5693585872650146\n",
            "Epoch 6942: train loss: 0.5693256258964539\n",
            "Epoch 6943: train loss: 0.5692926645278931\n",
            "Epoch 6944: train loss: 0.5692596435546875\n",
            "Epoch 6945: train loss: 0.5692266821861267\n",
            "Epoch 6946: train loss: 0.5691937208175659\n",
            "Epoch 6947: train loss: 0.5691608786582947\n",
            "Epoch 6948: train loss: 0.5691279172897339\n",
            "Epoch 6949: train loss: 0.5690949559211731\n",
            "Epoch 6950: train loss: 0.5690621137619019\n",
            "Epoch 6951: train loss: 0.5690291523933411\n",
            "Epoch 6952: train loss: 0.5689963102340698\n",
            "Epoch 6953: train loss: 0.5689634084701538\n",
            "Epoch 6954: train loss: 0.5689305663108826\n",
            "Epoch 6955: train loss: 0.5688976645469666\n",
            "Epoch 6956: train loss: 0.5688648223876953\n",
            "Epoch 6957: train loss: 0.5688319802284241\n",
            "Epoch 6958: train loss: 0.5687991976737976\n",
            "Epoch 6959: train loss: 0.5687664747238159\n",
            "Epoch 6960: train loss: 0.5687336325645447\n",
            "Epoch 6961: train loss: 0.5687007904052734\n",
            "Epoch 6962: train loss: 0.568668007850647\n",
            "Epoch 6963: train loss: 0.5686352252960205\n",
            "Epoch 6964: train loss: 0.5686025023460388\n",
            "Epoch 6965: train loss: 0.5685697197914124\n",
            "Epoch 6966: train loss: 0.5685369968414307\n",
            "Epoch 6967: train loss: 0.5685042142868042\n",
            "Epoch 6968: train loss: 0.5684714913368225\n",
            "Epoch 6969: train loss: 0.5684388279914856\n",
            "Epoch 6970: train loss: 0.5684061050415039\n",
            "Epoch 6971: train loss: 0.5683735013008118\n",
            "Epoch 6972: train loss: 0.5683407783508301\n",
            "Epoch 6973: train loss: 0.5683081150054932\n",
            "Epoch 6974: train loss: 0.568275511264801\n",
            "Epoch 6975: train loss: 0.5682428479194641\n",
            "Epoch 6976: train loss: 0.5682101845741272\n",
            "Epoch 6977: train loss: 0.5681775808334351\n",
            "Epoch 6978: train loss: 0.5681449174880981\n",
            "Epoch 6979: train loss: 0.5681123733520508\n",
            "Epoch 6980: train loss: 0.5680797696113586\n",
            "Epoch 6981: train loss: 0.5680472254753113\n",
            "Epoch 6982: train loss: 0.5680146217346191\n",
            "Epoch 6983: train loss: 0.5679820775985718\n",
            "Epoch 6984: train loss: 0.5679494142532349\n",
            "Epoch 6985: train loss: 0.567916989326477\n",
            "Epoch 6986: train loss: 0.5678844451904297\n",
            "Epoch 6987: train loss: 0.5678519606590271\n",
            "Epoch 6988: train loss: 0.5678194165229797\n",
            "Epoch 6989: train loss: 0.5677869319915771\n",
            "Epoch 6990: train loss: 0.5677544474601746\n",
            "Epoch 6991: train loss: 0.567721962928772\n",
            "Epoch 6992: train loss: 0.5676895380020142\n",
            "Epoch 6993: train loss: 0.5676569938659668\n",
            "Epoch 6994: train loss: 0.5676246285438538\n",
            "Epoch 6995: train loss: 0.5675921440124512\n",
            "Epoch 6996: train loss: 0.5675597190856934\n",
            "Epoch 6997: train loss: 0.5675272345542908\n",
            "Epoch 6998: train loss: 0.5674949884414673\n",
            "Epoch 6999: train loss: 0.5674625039100647\n",
            "Epoch 7000: train loss: 0.5674301981925964\n",
            "Epoch 7001: train loss: 0.5673977136611938\n",
            "Epoch 7002: train loss: 0.5673653483390808\n",
            "Epoch 7003: train loss: 0.5673329830169678\n",
            "Epoch 7004: train loss: 0.5673007369041443\n",
            "Epoch 7005: train loss: 0.5672683715820312\n",
            "Epoch 7006: train loss: 0.5672359466552734\n",
            "Epoch 7007: train loss: 0.56720370054245\n",
            "Epoch 7008: train loss: 0.5671713948249817\n",
            "Epoch 7009: train loss: 0.5671391487121582\n",
            "Epoch 7010: train loss: 0.5671067833900452\n",
            "Epoch 7011: train loss: 0.5670745372772217\n",
            "Epoch 7012: train loss: 0.5670422911643982\n",
            "Epoch 7013: train loss: 0.5670099854469299\n",
            "Epoch 7014: train loss: 0.5669777989387512\n",
            "Epoch 7015: train loss: 0.5669455528259277\n",
            "Epoch 7016: train loss: 0.566913366317749\n",
            "Epoch 7017: train loss: 0.5668811202049255\n",
            "Epoch 7018: train loss: 0.566848874092102\n",
            "Epoch 7019: train loss: 0.5668166875839233\n",
            "Epoch 7020: train loss: 0.5667845606803894\n",
            "Epoch 7021: train loss: 0.5667523145675659\n",
            "Epoch 7022: train loss: 0.566720187664032\n",
            "Epoch 7023: train loss: 0.566688060760498\n",
            "Epoch 7024: train loss: 0.5666559934616089\n",
            "Epoch 7025: train loss: 0.5666238069534302\n",
            "Epoch 7026: train loss: 0.5665916800498962\n",
            "Epoch 7027: train loss: 0.5665595531463623\n",
            "Epoch 7028: train loss: 0.5665274858474731\n",
            "Epoch 7029: train loss: 0.566495418548584\n",
            "Epoch 7030: train loss: 0.5664632320404053\n",
            "Epoch 7031: train loss: 0.5664311647415161\n",
            "Epoch 7032: train loss: 0.5663991570472717\n",
            "Epoch 7033: train loss: 0.5663671493530273\n",
            "Epoch 7034: train loss: 0.5663350820541382\n",
            "Epoch 7035: train loss: 0.566303014755249\n",
            "Epoch 7036: train loss: 0.5662709474563599\n",
            "Epoch 7037: train loss: 0.566239058971405\n",
            "Epoch 7038: train loss: 0.5662069916725159\n",
            "Epoch 7039: train loss: 0.5661750435829163\n",
            "Epoch 7040: train loss: 0.5661430358886719\n",
            "Epoch 7041: train loss: 0.5661110281944275\n",
            "Epoch 7042: train loss: 0.5660791397094727\n",
            "Epoch 7043: train loss: 0.5660470724105835\n",
            "Epoch 7044: train loss: 0.5660151839256287\n",
            "Epoch 7045: train loss: 0.5659832954406738\n",
            "Epoch 7046: train loss: 0.5659513473510742\n",
            "Epoch 7047: train loss: 0.5659194588661194\n",
            "Epoch 7048: train loss: 0.5658875703811646\n",
            "Epoch 7049: train loss: 0.5658555626869202\n",
            "Epoch 7050: train loss: 0.5658237934112549\n",
            "Epoch 7051: train loss: 0.5657919049263\n",
            "Epoch 7052: train loss: 0.5657599568367004\n",
            "Epoch 7053: train loss: 0.5657281279563904\n",
            "Epoch 7054: train loss: 0.5656962990760803\n",
            "Epoch 7055: train loss: 0.5656644105911255\n",
            "Epoch 7056: train loss: 0.5656326413154602\n",
            "Epoch 7057: train loss: 0.5656008124351501\n",
            "Epoch 7058: train loss: 0.5655689835548401\n",
            "Epoch 7059: train loss: 0.56553715467453\n",
            "Epoch 7060: train loss: 0.5655054450035095\n",
            "Epoch 7061: train loss: 0.565473735332489\n",
            "Epoch 7062: train loss: 0.5654419660568237\n",
            "Epoch 7063: train loss: 0.5654101967811584\n",
            "Epoch 7064: train loss: 0.5653784275054932\n",
            "Epoch 7065: train loss: 0.5653466582298279\n",
            "Epoch 7066: train loss: 0.5653149485588074\n",
            "Epoch 7067: train loss: 0.5652832388877869\n",
            "Epoch 7068: train loss: 0.5652515292167664\n",
            "Epoch 7069: train loss: 0.5652198195457458\n",
            "Epoch 7070: train loss: 0.5651881694793701\n",
            "Epoch 7071: train loss: 0.5651564598083496\n",
            "Epoch 7072: train loss: 0.5651248097419739\n",
            "Epoch 7073: train loss: 0.5650931596755981\n",
            "Epoch 7074: train loss: 0.5650615692138672\n",
            "Epoch 7075: train loss: 0.5650298595428467\n",
            "Epoch 7076: train loss: 0.564998209476471\n",
            "Epoch 7077: train loss: 0.5649665594100952\n",
            "Epoch 7078: train loss: 0.564935028553009\n",
            "Epoch 7079: train loss: 0.5649034380912781\n",
            "Epoch 7080: train loss: 0.5648717880249023\n",
            "Epoch 7081: train loss: 0.5648403167724609\n",
            "Epoch 7082: train loss: 0.5648086071014404\n",
            "Epoch 7083: train loss: 0.5647770166397095\n",
            "Epoch 7084: train loss: 0.5647455453872681\n",
            "Epoch 7085: train loss: 0.5647140741348267\n",
            "Epoch 7086: train loss: 0.5646824836730957\n",
            "Epoch 7087: train loss: 0.5646508932113647\n",
            "Epoch 7088: train loss: 0.5646193623542786\n",
            "Epoch 7089: train loss: 0.5645878911018372\n",
            "Epoch 7090: train loss: 0.5645564198493958\n",
            "Epoch 7091: train loss: 0.5645249485969543\n",
            "Epoch 7092: train loss: 0.5644934177398682\n",
            "Epoch 7093: train loss: 0.5644620060920715\n",
            "Epoch 7094: train loss: 0.5644305348396301\n",
            "Epoch 7095: train loss: 0.5643990635871887\n",
            "Epoch 7096: train loss: 0.5643676519393921\n",
            "Epoch 7097: train loss: 0.5643362402915955\n",
            "Epoch 7098: train loss: 0.5643048286437988\n",
            "Epoch 7099: train loss: 0.5642733573913574\n",
            "Epoch 7100: train loss: 0.5642419457435608\n",
            "Epoch 7101: train loss: 0.5642105937004089\n",
            "Epoch 7102: train loss: 0.5641791820526123\n",
            "Epoch 7103: train loss: 0.5641478300094604\n",
            "Epoch 7104: train loss: 0.5641164779663086\n",
            "Epoch 7105: train loss: 0.564085066318512\n",
            "Epoch 7106: train loss: 0.5640537738800049\n",
            "Epoch 7107: train loss: 0.564022421836853\n",
            "Epoch 7108: train loss: 0.5639910697937012\n",
            "Epoch 7109: train loss: 0.5639598369598389\n",
            "Epoch 7110: train loss: 0.5639284253120422\n",
            "Epoch 7111: train loss: 0.5638971924781799\n",
            "Epoch 7112: train loss: 0.5638659000396729\n",
            "Epoch 7113: train loss: 0.563834547996521\n",
            "Epoch 7114: train loss: 0.5638032555580139\n",
            "Epoch 7115: train loss: 0.5637720823287964\n",
            "Epoch 7116: train loss: 0.5637408494949341\n",
            "Epoch 7117: train loss: 0.5637096166610718\n",
            "Epoch 7118: train loss: 0.5636783242225647\n",
            "Epoch 7119: train loss: 0.5636470913887024\n",
            "Epoch 7120: train loss: 0.5636158585548401\n",
            "Epoch 7121: train loss: 0.5635846853256226\n",
            "Epoch 7122: train loss: 0.563553512096405\n",
            "Epoch 7123: train loss: 0.5635222792625427\n",
            "Epoch 7124: train loss: 0.56349116563797\n",
            "Epoch 7125: train loss: 0.5634599924087524\n",
            "Epoch 7126: train loss: 0.5634288191795349\n",
            "Epoch 7127: train loss: 0.5633976459503174\n",
            "Epoch 7128: train loss: 0.5633665919303894\n",
            "Epoch 7129: train loss: 0.5633353590965271\n",
            "Epoch 7130: train loss: 0.5633043050765991\n",
            "Epoch 7131: train loss: 0.5632731318473816\n",
            "Epoch 7132: train loss: 0.5632420182228088\n",
            "Epoch 7133: train loss: 0.5632109642028809\n",
            "Epoch 7134: train loss: 0.5631798505783081\n",
            "Epoch 7135: train loss: 0.5631487965583801\n",
            "Epoch 7136: train loss: 0.5631176829338074\n",
            "Epoch 7137: train loss: 0.5630866885185242\n",
            "Epoch 7138: train loss: 0.5630555748939514\n",
            "Epoch 7139: train loss: 0.5630245208740234\n",
            "Epoch 7140: train loss: 0.5629934668540955\n",
            "Epoch 7141: train loss: 0.5629624128341675\n",
            "Epoch 7142: train loss: 0.562931478023529\n",
            "Epoch 7143: train loss: 0.5629004240036011\n",
            "Epoch 7144: train loss: 0.5628694891929626\n",
            "Epoch 7145: train loss: 0.5628384947776794\n",
            "Epoch 7146: train loss: 0.5628074407577515\n",
            "Epoch 7147: train loss: 0.5627765655517578\n",
            "Epoch 7148: train loss: 0.5627455711364746\n",
            "Epoch 7149: train loss: 0.5627146363258362\n",
            "Epoch 7150: train loss: 0.562683641910553\n",
            "Epoch 7151: train loss: 0.5626527070999146\n",
            "Epoch 7152: train loss: 0.5626218318939209\n",
            "Epoch 7153: train loss: 0.5625908970832825\n",
            "Epoch 7154: train loss: 0.5625600218772888\n",
            "Epoch 7155: train loss: 0.5625290274620056\n",
            "Epoch 7156: train loss: 0.562498152256012\n",
            "Epoch 7157: train loss: 0.5624673366546631\n",
            "Epoch 7158: train loss: 0.5624364614486694\n",
            "Epoch 7159: train loss: 0.562405526638031\n",
            "Epoch 7160: train loss: 0.5623747110366821\n",
            "Epoch 7161: train loss: 0.5623438954353333\n",
            "Epoch 7162: train loss: 0.5623129606246948\n",
            "Epoch 7163: train loss: 0.562282145023346\n",
            "Epoch 7164: train loss: 0.5622513890266418\n",
            "Epoch 7165: train loss: 0.562220573425293\n",
            "Epoch 7166: train loss: 0.5621897578239441\n",
            "Epoch 7167: train loss: 0.5621589422225952\n",
            "Epoch 7168: train loss: 0.5621281862258911\n",
            "Epoch 7169: train loss: 0.562097430229187\n",
            "Epoch 7170: train loss: 0.5620666742324829\n",
            "Epoch 7171: train loss: 0.562035858631134\n",
            "Epoch 7172: train loss: 0.5620051622390747\n",
            "Epoch 7173: train loss: 0.5619744062423706\n",
            "Epoch 7174: train loss: 0.5619437098503113\n",
            "Epoch 7175: train loss: 0.5619128942489624\n",
            "Epoch 7176: train loss: 0.5618822574615479\n",
            "Epoch 7177: train loss: 0.561851441860199\n",
            "Epoch 7178: train loss: 0.5618207454681396\n",
            "Epoch 7179: train loss: 0.5617901086807251\n",
            "Epoch 7180: train loss: 0.5617594122886658\n",
            "Epoch 7181: train loss: 0.5617287755012512\n",
            "Epoch 7182: train loss: 0.5616981387138367\n",
            "Epoch 7183: train loss: 0.5616674423217773\n",
            "Epoch 7184: train loss: 0.5616368055343628\n",
            "Epoch 7185: train loss: 0.5616061091423035\n",
            "Epoch 7186: train loss: 0.5615755319595337\n",
            "Epoch 7187: train loss: 0.5615448951721191\n",
            "Epoch 7188: train loss: 0.5615143179893494\n",
            "Epoch 7189: train loss: 0.5614836812019348\n",
            "Epoch 7190: train loss: 0.5614530444145203\n",
            "Epoch 7191: train loss: 0.5614224672317505\n",
            "Epoch 7192: train loss: 0.5613919496536255\n",
            "Epoch 7193: train loss: 0.5613613128662109\n",
            "Epoch 7194: train loss: 0.5613307952880859\n",
            "Epoch 7195: train loss: 0.5613002777099609\n",
            "Epoch 7196: train loss: 0.5612697005271912\n",
            "Epoch 7197: train loss: 0.5612392425537109\n",
            "Epoch 7198: train loss: 0.5612087249755859\n",
            "Epoch 7199: train loss: 0.5611780881881714\n",
            "Epoch 7200: train loss: 0.5611476302146912\n",
            "Epoch 7201: train loss: 0.5611171126365662\n",
            "Epoch 7202: train loss: 0.5610865950584412\n",
            "Epoch 7203: train loss: 0.5610561370849609\n",
            "Epoch 7204: train loss: 0.5610256791114807\n",
            "Epoch 7205: train loss: 0.5609952211380005\n",
            "Epoch 7206: train loss: 0.5609647631645203\n",
            "Epoch 7207: train loss: 0.5609342455863953\n",
            "Epoch 7208: train loss: 0.5609038472175598\n",
            "Epoch 7209: train loss: 0.5608733296394348\n",
            "Epoch 7210: train loss: 0.5608429312705994\n",
            "Epoch 7211: train loss: 0.5608125329017639\n",
            "Epoch 7212: train loss: 0.5607821345329285\n",
            "Epoch 7213: train loss: 0.560751736164093\n",
            "Epoch 7214: train loss: 0.5607213973999023\n",
            "Epoch 7215: train loss: 0.5606909394264221\n",
            "Epoch 7216: train loss: 0.5606606602668762\n",
            "Epoch 7217: train loss: 0.560630202293396\n",
            "Epoch 7218: train loss: 0.5605998039245605\n",
            "Epoch 7219: train loss: 0.5605695247650146\n",
            "Epoch 7220: train loss: 0.560539186000824\n",
            "Epoch 7221: train loss: 0.5605088472366333\n",
            "Epoch 7222: train loss: 0.5604785084724426\n",
            "Epoch 7223: train loss: 0.5604482293128967\n",
            "Epoch 7224: train loss: 0.5604178309440613\n",
            "Epoch 7225: train loss: 0.5603875517845154\n",
            "Epoch 7226: train loss: 0.5603572726249695\n",
            "Epoch 7227: train loss: 0.5603269934654236\n",
            "Epoch 7228: train loss: 0.5602967739105225\n",
            "Epoch 7229: train loss: 0.5602664947509766\n",
            "Epoch 7230: train loss: 0.5602361559867859\n",
            "Epoch 7231: train loss: 0.5602059364318848\n",
            "Epoch 7232: train loss: 0.5601757168769836\n",
            "Epoch 7233: train loss: 0.5601454973220825\n",
            "Epoch 7234: train loss: 0.5601152181625366\n",
            "Epoch 7235: train loss: 0.5600849986076355\n",
            "Epoch 7236: train loss: 0.5600548386573792\n",
            "Epoch 7237: train loss: 0.5600245594978333\n",
            "Epoch 7238: train loss: 0.5599943995475769\n",
            "Epoch 7239: train loss: 0.5599641799926758\n",
            "Epoch 7240: train loss: 0.5599340200424194\n",
            "Epoch 7241: train loss: 0.5599038600921631\n",
            "Epoch 7242: train loss: 0.5598737001419067\n",
            "Epoch 7243: train loss: 0.5598434805870056\n",
            "Epoch 7244: train loss: 0.559813380241394\n",
            "Epoch 7245: train loss: 0.5597832798957825\n",
            "Epoch 7246: train loss: 0.5597531199455261\n",
            "Epoch 7247: train loss: 0.5597230195999146\n",
            "Epoch 7248: train loss: 0.559692919254303\n",
            "Epoch 7249: train loss: 0.5596626996994019\n",
            "Epoch 7250: train loss: 0.5596327185630798\n",
            "Epoch 7251: train loss: 0.5596026182174683\n",
            "Epoch 7252: train loss: 0.5595724582672119\n",
            "Epoch 7253: train loss: 0.5595423579216003\n",
            "Epoch 7254: train loss: 0.5595123767852783\n",
            "Epoch 7255: train loss: 0.5594822764396667\n",
            "Epoch 7256: train loss: 0.5594522356987\n",
            "Epoch 7257: train loss: 0.5594221949577332\n",
            "Epoch 7258: train loss: 0.5593920946121216\n",
            "Epoch 7259: train loss: 0.5593621134757996\n",
            "Epoch 7260: train loss: 0.5593320727348328\n",
            "Epoch 7261: train loss: 0.5593020915985107\n",
            "Epoch 7262: train loss: 0.5592721104621887\n",
            "Epoch 7263: train loss: 0.5592420101165771\n",
            "Epoch 7264: train loss: 0.5592120885848999\n",
            "Epoch 7265: train loss: 0.5591820478439331\n",
            "Epoch 7266: train loss: 0.5591521263122559\n",
            "Epoch 7267: train loss: 0.5591221451759338\n",
            "Epoch 7268: train loss: 0.5590921640396118\n",
            "Epoch 7269: train loss: 0.5590622425079346\n",
            "Epoch 7270: train loss: 0.5590322613716125\n",
            "Epoch 7271: train loss: 0.5590023398399353\n",
            "Epoch 7272: train loss: 0.5589724183082581\n",
            "Epoch 7273: train loss: 0.5589425563812256\n",
            "Epoch 7274: train loss: 0.5589125156402588\n",
            "Epoch 7275: train loss: 0.5588827133178711\n",
            "Epoch 7276: train loss: 0.5588528513908386\n",
            "Epoch 7277: train loss: 0.5588228702545166\n",
            "Epoch 7278: train loss: 0.5587930083274841\n",
            "Epoch 7279: train loss: 0.5587631464004517\n",
            "Epoch 7280: train loss: 0.5587332248687744\n",
            "Epoch 7281: train loss: 0.5587033629417419\n",
            "Epoch 7282: train loss: 0.5586735606193542\n",
            "Epoch 7283: train loss: 0.5586437582969666\n",
            "Epoch 7284: train loss: 0.5586138963699341\n",
            "Epoch 7285: train loss: 0.5585840344429016\n",
            "Epoch 7286: train loss: 0.5585542321205139\n",
            "Epoch 7287: train loss: 0.5585244297981262\n",
            "Epoch 7288: train loss: 0.5584946274757385\n",
            "Epoch 7289: train loss: 0.5584648251533508\n",
            "Epoch 7290: train loss: 0.5584350824356079\n",
            "Epoch 7291: train loss: 0.5584052801132202\n",
            "Epoch 7292: train loss: 0.5583754777908325\n",
            "Epoch 7293: train loss: 0.5583456754684448\n",
            "Epoch 7294: train loss: 0.5583159327507019\n",
            "Epoch 7295: train loss: 0.558286190032959\n",
            "Epoch 7296: train loss: 0.5582563877105713\n",
            "Epoch 7297: train loss: 0.5582267642021179\n",
            "Epoch 7298: train loss: 0.5581969618797302\n",
            "Epoch 7299: train loss: 0.5581672191619873\n",
            "Epoch 7300: train loss: 0.5581375360488892\n",
            "Epoch 7301: train loss: 0.558107852935791\n",
            "Epoch 7302: train loss: 0.5580781102180481\n",
            "Epoch 7303: train loss: 0.55804842710495\n",
            "Epoch 7304: train loss: 0.5580187439918518\n",
            "Epoch 7305: train loss: 0.5579891204833984\n",
            "Epoch 7306: train loss: 0.5579593777656555\n",
            "Epoch 7307: train loss: 0.5579296946525574\n",
            "Epoch 7308: train loss: 0.557900071144104\n",
            "Epoch 7309: train loss: 0.5578703880310059\n",
            "Epoch 7310: train loss: 0.5578407645225525\n",
            "Epoch 7311: train loss: 0.5578110814094543\n",
            "Epoch 7312: train loss: 0.5577815175056458\n",
            "Epoch 7313: train loss: 0.5577518343925476\n",
            "Epoch 7314: train loss: 0.5577222108840942\n",
            "Epoch 7315: train loss: 0.5576926469802856\n",
            "Epoch 7316: train loss: 0.557663083076477\n",
            "Epoch 7317: train loss: 0.5576334595680237\n",
            "Epoch 7318: train loss: 0.5576038956642151\n",
            "Epoch 7319: train loss: 0.5575743317604065\n",
            "Epoch 7320: train loss: 0.5575447082519531\n",
            "Epoch 7321: train loss: 0.5575151443481445\n",
            "Epoch 7322: train loss: 0.5574855804443359\n",
            "Epoch 7323: train loss: 0.5574560761451721\n",
            "Epoch 7324: train loss: 0.5574264526367188\n",
            "Epoch 7325: train loss: 0.5573969483375549\n",
            "Epoch 7326: train loss: 0.5573674440383911\n",
            "Epoch 7327: train loss: 0.5573379397392273\n",
            "Epoch 7328: train loss: 0.5573083758354187\n",
            "Epoch 7329: train loss: 0.5572789311408997\n",
            "Epoch 7330: train loss: 0.5572494268417358\n",
            "Epoch 7331: train loss: 0.5572198629379272\n",
            "Epoch 7332: train loss: 0.5571904182434082\n",
            "Epoch 7333: train loss: 0.5571609735488892\n",
            "Epoch 7334: train loss: 0.5571314692497253\n",
            "Epoch 7335: train loss: 0.5571020245552063\n",
            "Epoch 7336: train loss: 0.5570725798606873\n",
            "Epoch 7337: train loss: 0.5570430755615234\n",
            "Epoch 7338: train loss: 0.5570136904716492\n",
            "Epoch 7339: train loss: 0.5569842457771301\n",
            "Epoch 7340: train loss: 0.5569548010826111\n",
            "Epoch 7341: train loss: 0.556925356388092\n",
            "Epoch 7342: train loss: 0.5568959712982178\n",
            "Epoch 7343: train loss: 0.5568665266036987\n",
            "Epoch 7344: train loss: 0.5568371415138245\n",
            "Epoch 7345: train loss: 0.556807816028595\n",
            "Epoch 7346: train loss: 0.5567783713340759\n",
            "Epoch 7347: train loss: 0.5567490458488464\n",
            "Epoch 7348: train loss: 0.5567196607589722\n",
            "Epoch 7349: train loss: 0.5566902756690979\n",
            "Epoch 7350: train loss: 0.5566608905792236\n",
            "Epoch 7351: train loss: 0.5566315650939941\n",
            "Epoch 7352: train loss: 0.5566022396087646\n",
            "Epoch 7353: train loss: 0.5565728545188904\n",
            "Epoch 7354: train loss: 0.5565434694290161\n",
            "Epoch 7355: train loss: 0.5565141439437866\n",
            "Epoch 7356: train loss: 0.5564849376678467\n",
            "Epoch 7357: train loss: 0.5564555525779724\n",
            "Epoch 7358: train loss: 0.5564262866973877\n",
            "Epoch 7359: train loss: 0.556397020816803\n",
            "Epoch 7360: train loss: 0.5563676953315735\n",
            "Epoch 7361: train loss: 0.5563384294509888\n",
            "Epoch 7362: train loss: 0.556309163570404\n",
            "Epoch 7363: train loss: 0.5562797784805298\n",
            "Epoch 7364: train loss: 0.5562506318092346\n",
            "Epoch 7365: train loss: 0.5562213659286499\n",
            "Epoch 7366: train loss: 0.5561921000480652\n",
            "Epoch 7367: train loss: 0.5561628341674805\n",
            "Epoch 7368: train loss: 0.5561335682868958\n",
            "Epoch 7369: train loss: 0.5561043620109558\n",
            "Epoch 7370: train loss: 0.5560751557350159\n",
            "Epoch 7371: train loss: 0.5560458898544312\n",
            "Epoch 7372: train loss: 0.556016743183136\n",
            "Epoch 7373: train loss: 0.5559874773025513\n",
            "Epoch 7374: train loss: 0.5559583306312561\n",
            "Epoch 7375: train loss: 0.5559291243553162\n",
            "Epoch 7376: train loss: 0.5558999180793762\n",
            "Epoch 7377: train loss: 0.5558707118034363\n",
            "Epoch 7378: train loss: 0.5558415651321411\n",
            "Epoch 7379: train loss: 0.555812418460846\n",
            "Epoch 7380: train loss: 0.5557832717895508\n",
            "Epoch 7381: train loss: 0.5557540655136108\n",
            "Epoch 7382: train loss: 0.5557250380516052\n",
            "Epoch 7383: train loss: 0.5556957721710205\n",
            "Epoch 7384: train loss: 0.5556666851043701\n",
            "Epoch 7385: train loss: 0.5556375980377197\n",
            "Epoch 7386: train loss: 0.5556085109710693\n",
            "Epoch 7387: train loss: 0.5555793642997742\n",
            "Epoch 7388: train loss: 0.555550217628479\n",
            "Epoch 7389: train loss: 0.5555210709571838\n",
            "Epoch 7390: train loss: 0.5554920434951782\n",
            "Epoch 7391: train loss: 0.5554629564285278\n",
            "Epoch 7392: train loss: 0.5554338693618774\n",
            "Epoch 7393: train loss: 0.5554048418998718\n",
            "Epoch 7394: train loss: 0.5553757548332214\n",
            "Epoch 7395: train loss: 0.5553467273712158\n",
            "Epoch 7396: train loss: 0.5553176403045654\n",
            "Epoch 7397: train loss: 0.5552884936332703\n",
            "Epoch 7398: train loss: 0.5552594661712646\n",
            "Epoch 7399: train loss: 0.5552304983139038\n",
            "Epoch 7400: train loss: 0.555201530456543\n",
            "Epoch 7401: train loss: 0.5551725029945374\n",
            "Epoch 7402: train loss: 0.555143415927887\n",
            "Epoch 7403: train loss: 0.5551143884658813\n",
            "Epoch 7404: train loss: 0.5550854802131653\n",
            "Epoch 7405: train loss: 0.5550564527511597\n",
            "Epoch 7406: train loss: 0.555027425289154\n",
            "Epoch 7407: train loss: 0.5549983978271484\n",
            "Epoch 7408: train loss: 0.5549694299697876\n",
            "Epoch 7409: train loss: 0.5549404621124268\n",
            "Epoch 7410: train loss: 0.5549114942550659\n",
            "Epoch 7411: train loss: 0.5548825860023499\n",
            "Epoch 7412: train loss: 0.5548535585403442\n",
            "Epoch 7413: train loss: 0.5548246502876282\n",
            "Epoch 7414: train loss: 0.5547956824302673\n",
            "Epoch 7415: train loss: 0.554766833782196\n",
            "Epoch 7416: train loss: 0.5547378063201904\n",
            "Epoch 7417: train loss: 0.5547088980674744\n",
            "Epoch 7418: train loss: 0.5546799898147583\n",
            "Epoch 7419: train loss: 0.5546510815620422\n",
            "Epoch 7420: train loss: 0.5546221733093262\n",
            "Epoch 7421: train loss: 0.5545932650566101\n",
            "Epoch 7422: train loss: 0.5545644164085388\n",
            "Epoch 7423: train loss: 0.5545355677604675\n",
            "Epoch 7424: train loss: 0.5545065999031067\n",
            "Epoch 7425: train loss: 0.5544778108596802\n",
            "Epoch 7426: train loss: 0.5544489622116089\n",
            "Epoch 7427: train loss: 0.554419994354248\n",
            "Epoch 7428: train loss: 0.5543912649154663\n",
            "Epoch 7429: train loss: 0.5543623566627502\n",
            "Epoch 7430: train loss: 0.554333508014679\n",
            "Epoch 7431: train loss: 0.5543046593666077\n",
            "Epoch 7432: train loss: 0.5542758107185364\n",
            "Epoch 7433: train loss: 0.5542469024658203\n",
            "Epoch 7434: train loss: 0.5542181730270386\n",
            "Epoch 7435: train loss: 0.5541894435882568\n",
            "Epoch 7436: train loss: 0.5541605949401855\n",
            "Epoch 7437: train loss: 0.5541317462921143\n",
            "Epoch 7438: train loss: 0.5541029572486877\n",
            "Epoch 7439: train loss: 0.5540741086006165\n",
            "Epoch 7440: train loss: 0.5540453791618347\n",
            "Epoch 7441: train loss: 0.5540165901184082\n",
            "Epoch 7442: train loss: 0.5539878606796265\n",
            "Epoch 7443: train loss: 0.5539591312408447\n",
            "Epoch 7444: train loss: 0.5539302825927734\n",
            "Epoch 7445: train loss: 0.5539015531539917\n",
            "Epoch 7446: train loss: 0.5538727641105652\n",
            "Epoch 7447: train loss: 0.5538440346717834\n",
            "Epoch 7448: train loss: 0.5538153052330017\n",
            "Epoch 7449: train loss: 0.55378657579422\n",
            "Epoch 7450: train loss: 0.5537578463554382\n",
            "Epoch 7451: train loss: 0.5537291765213013\n",
            "Epoch 7452: train loss: 0.5537003874778748\n",
            "Epoch 7453: train loss: 0.5536717176437378\n",
            "Epoch 7454: train loss: 0.5536430478096008\n",
            "Epoch 7455: train loss: 0.5536143183708191\n",
            "Epoch 7456: train loss: 0.5535856485366821\n",
            "Epoch 7457: train loss: 0.5535568594932556\n",
            "Epoch 7458: train loss: 0.5535283088684082\n",
            "Epoch 7459: train loss: 0.5534995794296265\n",
            "Epoch 7460: train loss: 0.5534709095954895\n",
            "Epoch 7461: train loss: 0.5534422993659973\n",
            "Epoch 7462: train loss: 0.5534136295318604\n",
            "Epoch 7463: train loss: 0.5533849596977234\n",
            "Epoch 7464: train loss: 0.5533562898635864\n",
            "Epoch 7465: train loss: 0.5533276796340942\n",
            "Epoch 7466: train loss: 0.553299069404602\n",
            "Epoch 7467: train loss: 0.5532703995704651\n",
            "Epoch 7468: train loss: 0.5532417893409729\n",
            "Epoch 7469: train loss: 0.5532131791114807\n",
            "Epoch 7470: train loss: 0.5531845688819885\n",
            "Epoch 7471: train loss: 0.5531558990478516\n",
            "Epoch 7472: train loss: 0.5531273484230042\n",
            "Epoch 7473: train loss: 0.553098738193512\n",
            "Epoch 7474: train loss: 0.5530701875686646\n",
            "Epoch 7475: train loss: 0.5530415773391724\n",
            "Epoch 7476: train loss: 0.553013026714325\n",
            "Epoch 7477: train loss: 0.5529844164848328\n",
            "Epoch 7478: train loss: 0.5529558658599854\n",
            "Epoch 7479: train loss: 0.5529272556304932\n",
            "Epoch 7480: train loss: 0.5528988242149353\n",
            "Epoch 7481: train loss: 0.5528702139854431\n",
            "Epoch 7482: train loss: 0.5528416633605957\n",
            "Epoch 7483: train loss: 0.5528131127357483\n",
            "Epoch 7484: train loss: 0.5527846217155457\n",
            "Epoch 7485: train loss: 0.5527560114860535\n",
            "Epoch 7486: train loss: 0.5527275204658508\n",
            "Epoch 7487: train loss: 0.5526989698410034\n",
            "Epoch 7488: train loss: 0.5526704788208008\n",
            "Epoch 7489: train loss: 0.5526419281959534\n",
            "Epoch 7490: train loss: 0.5526134371757507\n",
            "Epoch 7491: train loss: 0.5525849461555481\n",
            "Epoch 7492: train loss: 0.5525565147399902\n",
            "Epoch 7493: train loss: 0.5525279641151428\n",
            "Epoch 7494: train loss: 0.552499532699585\n",
            "Epoch 7495: train loss: 0.5524709820747375\n",
            "Epoch 7496: train loss: 0.5524425506591797\n",
            "Epoch 7497: train loss: 0.552414059638977\n",
            "Epoch 7498: train loss: 0.5523856282234192\n",
            "Epoch 7499: train loss: 0.5523572564125061\n",
            "Epoch 7500: train loss: 0.5523287057876587\n",
            "Epoch 7501: train loss: 0.5523002743721008\n",
            "Epoch 7502: train loss: 0.552271842956543\n",
            "Epoch 7503: train loss: 0.5522434115409851\n",
            "Epoch 7504: train loss: 0.5522149801254272\n",
            "Epoch 7505: train loss: 0.5521864891052246\n",
            "Epoch 7506: train loss: 0.5521581172943115\n",
            "Epoch 7507: train loss: 0.5521297454833984\n",
            "Epoch 7508: train loss: 0.5521013140678406\n",
            "Epoch 7509: train loss: 0.5520728826522827\n",
            "Epoch 7510: train loss: 0.5520445108413696\n",
            "Epoch 7511: train loss: 0.5520161390304565\n",
            "Epoch 7512: train loss: 0.5519877076148987\n",
            "Epoch 7513: train loss: 0.5519593358039856\n",
            "Epoch 7514: train loss: 0.5519309639930725\n",
            "Epoch 7515: train loss: 0.5519025921821594\n",
            "Epoch 7516: train loss: 0.5518741607666016\n",
            "Epoch 7517: train loss: 0.5518458485603333\n",
            "Epoch 7518: train loss: 0.5518174767494202\n",
            "Epoch 7519: train loss: 0.5517891049385071\n",
            "Epoch 7520: train loss: 0.5517607927322388\n",
            "Epoch 7521: train loss: 0.5517324209213257\n",
            "Epoch 7522: train loss: 0.5517041087150574\n",
            "Epoch 7523: train loss: 0.5516757965087891\n",
            "Epoch 7524: train loss: 0.551647424697876\n",
            "Epoch 7525: train loss: 0.5516190528869629\n",
            "Epoch 7526: train loss: 0.5515908002853394\n",
            "Epoch 7527: train loss: 0.5515624284744263\n",
            "Epoch 7528: train loss: 0.5515341758728027\n",
            "Epoch 7529: train loss: 0.5515058636665344\n",
            "Epoch 7530: train loss: 0.5514776110649109\n",
            "Epoch 7531: train loss: 0.5514493584632874\n",
            "Epoch 7532: train loss: 0.5514209866523743\n",
            "Epoch 7533: train loss: 0.551392674446106\n",
            "Epoch 7534: train loss: 0.5513643622398376\n",
            "Epoch 7535: train loss: 0.5513361692428589\n",
            "Epoch 7536: train loss: 0.5513079166412354\n",
            "Epoch 7537: train loss: 0.551279604434967\n",
            "Epoch 7538: train loss: 0.5512513518333435\n",
            "Epoch 7539: train loss: 0.55122309923172\n",
            "Epoch 7540: train loss: 0.5511949062347412\n",
            "Epoch 7541: train loss: 0.5511665940284729\n",
            "Epoch 7542: train loss: 0.5511383414268494\n",
            "Epoch 7543: train loss: 0.5511100888252258\n",
            "Epoch 7544: train loss: 0.5510818958282471\n",
            "Epoch 7545: train loss: 0.5510536432266235\n",
            "Epoch 7546: train loss: 0.5510254502296448\n",
            "Epoch 7547: train loss: 0.5509971380233765\n",
            "Epoch 7548: train loss: 0.5509689450263977\n",
            "Epoch 7549: train loss: 0.5509408116340637\n",
            "Epoch 7550: train loss: 0.550912618637085\n",
            "Epoch 7551: train loss: 0.5508843660354614\n",
            "Epoch 7552: train loss: 0.5508561730384827\n",
            "Epoch 7553: train loss: 0.5508279800415039\n",
            "Epoch 7554: train loss: 0.5507998466491699\n",
            "Epoch 7555: train loss: 0.5507715940475464\n",
            "Epoch 7556: train loss: 0.5507434606552124\n",
            "Epoch 7557: train loss: 0.5507153272628784\n",
            "Epoch 7558: train loss: 0.5506870746612549\n",
            "Epoch 7559: train loss: 0.5506589412689209\n",
            "Epoch 7560: train loss: 0.5506307482719421\n",
            "Epoch 7561: train loss: 0.5506026148796082\n",
            "Epoch 7562: train loss: 0.5505744814872742\n",
            "Epoch 7563: train loss: 0.5505463480949402\n",
            "Epoch 7564: train loss: 0.550518274307251\n",
            "Epoch 7565: train loss: 0.5504900813102722\n",
            "Epoch 7566: train loss: 0.5504619479179382\n",
            "Epoch 7567: train loss: 0.5504338145256042\n",
            "Epoch 7568: train loss: 0.5504056811332703\n",
            "Epoch 7569: train loss: 0.5503775477409363\n",
            "Epoch 7570: train loss: 0.5503494739532471\n",
            "Epoch 7571: train loss: 0.5503214001655579\n",
            "Epoch 7572: train loss: 0.5502932667732239\n",
            "Epoch 7573: train loss: 0.5502651333808899\n",
            "Epoch 7574: train loss: 0.5502370595932007\n",
            "Epoch 7575: train loss: 0.5502089858055115\n",
            "Epoch 7576: train loss: 0.5501808524131775\n",
            "Epoch 7577: train loss: 0.5501528382301331\n",
            "Epoch 7578: train loss: 0.5501247048377991\n",
            "Epoch 7579: train loss: 0.5500966310501099\n",
            "Epoch 7580: train loss: 0.5500685572624207\n",
            "Epoch 7581: train loss: 0.5500404834747314\n",
            "Epoch 7582: train loss: 0.5500125288963318\n",
            "Epoch 7583: train loss: 0.5499843955039978\n",
            "Epoch 7584: train loss: 0.5499563217163086\n",
            "Epoch 7585: train loss: 0.5499283075332642\n",
            "Epoch 7586: train loss: 0.549900233745575\n",
            "Epoch 7587: train loss: 0.5498722195625305\n",
            "Epoch 7588: train loss: 0.5498441457748413\n",
            "Epoch 7589: train loss: 0.5498161315917969\n",
            "Epoch 7590: train loss: 0.5497881174087524\n",
            "Epoch 7591: train loss: 0.5497600436210632\n",
            "Epoch 7592: train loss: 0.5497320294380188\n",
            "Epoch 7593: train loss: 0.5497040152549744\n",
            "Epoch 7594: train loss: 0.5496760010719299\n",
            "Epoch 7595: train loss: 0.5496480464935303\n",
            "Epoch 7596: train loss: 0.5496200323104858\n",
            "Epoch 7597: train loss: 0.5495920181274414\n",
            "Epoch 7598: train loss: 0.549564003944397\n",
            "Epoch 7599: train loss: 0.5495360493659973\n",
            "Epoch 7600: train loss: 0.5495080351829529\n",
            "Epoch 7601: train loss: 0.5494800806045532\n",
            "Epoch 7602: train loss: 0.5494520664215088\n",
            "Epoch 7603: train loss: 0.5494241118431091\n",
            "Epoch 7604: train loss: 0.5493960976600647\n",
            "Epoch 7605: train loss: 0.5493682026863098\n",
            "Epoch 7606: train loss: 0.5493401885032654\n",
            "Epoch 7607: train loss: 0.5493122339248657\n",
            "Epoch 7608: train loss: 0.5492842793464661\n",
            "Epoch 7609: train loss: 0.5492563247680664\n",
            "Epoch 7610: train loss: 0.5492283701896667\n",
            "Epoch 7611: train loss: 0.5492004752159119\n",
            "Epoch 7612: train loss: 0.549172580242157\n",
            "Epoch 7613: train loss: 0.5491445660591125\n",
            "Epoch 7614: train loss: 0.5491166114807129\n",
            "Epoch 7615: train loss: 0.549088716506958\n",
            "Epoch 7616: train loss: 0.5490608215332031\n",
            "Epoch 7617: train loss: 0.5490328669548035\n",
            "Epoch 7618: train loss: 0.5490049719810486\n",
            "Epoch 7619: train loss: 0.5489770174026489\n",
            "Epoch 7620: train loss: 0.5489491820335388\n",
            "Epoch 7621: train loss: 0.5489212274551392\n",
            "Epoch 7622: train loss: 0.5488933324813843\n",
            "Epoch 7623: train loss: 0.5488654375076294\n",
            "Epoch 7624: train loss: 0.5488376021385193\n",
            "Epoch 7625: train loss: 0.5488097071647644\n",
            "Epoch 7626: train loss: 0.5487817525863647\n",
            "Epoch 7627: train loss: 0.5487538576126099\n",
            "Epoch 7628: train loss: 0.5487260222434998\n",
            "Epoch 7629: train loss: 0.5486981272697449\n",
            "Epoch 7630: train loss: 0.54867023229599\n",
            "Epoch 7631: train loss: 0.5486423969268799\n",
            "Epoch 7632: train loss: 0.548614501953125\n",
            "Epoch 7633: train loss: 0.5485866665840149\n",
            "Epoch 7634: train loss: 0.5485588312149048\n",
            "Epoch 7635: train loss: 0.5485309362411499\n",
            "Epoch 7636: train loss: 0.5485031604766846\n",
            "Epoch 7637: train loss: 0.5484752655029297\n",
            "Epoch 7638: train loss: 0.5484474301338196\n",
            "Epoch 7639: train loss: 0.5484195351600647\n",
            "Epoch 7640: train loss: 0.5483916997909546\n",
            "Epoch 7641: train loss: 0.5483639240264893\n",
            "Epoch 7642: train loss: 0.5483360886573792\n",
            "Epoch 7643: train loss: 0.548308253288269\n",
            "Epoch 7644: train loss: 0.5482804179191589\n",
            "Epoch 7645: train loss: 0.5482527017593384\n",
            "Epoch 7646: train loss: 0.5482248067855835\n",
            "Epoch 7647: train loss: 0.5481969714164734\n",
            "Epoch 7648: train loss: 0.5481692552566528\n",
            "Epoch 7649: train loss: 0.5481414198875427\n",
            "Epoch 7650: train loss: 0.5481136441230774\n",
            "Epoch 7651: train loss: 0.5480858087539673\n",
            "Epoch 7652: train loss: 0.548058032989502\n",
            "Epoch 7653: train loss: 0.5480301976203918\n",
            "Epoch 7654: train loss: 0.5480024218559265\n",
            "Epoch 7655: train loss: 0.5479746460914612\n",
            "Epoch 7656: train loss: 0.5479468703269958\n",
            "Epoch 7657: train loss: 0.5479190945625305\n",
            "Epoch 7658: train loss: 0.5478913187980652\n",
            "Epoch 7659: train loss: 0.5478636026382446\n",
            "Epoch 7660: train loss: 0.5478357672691345\n",
            "Epoch 7661: train loss: 0.5478079915046692\n",
            "Epoch 7662: train loss: 0.5477802753448486\n",
            "Epoch 7663: train loss: 0.5477524995803833\n",
            "Epoch 7664: train loss: 0.5477247834205627\n",
            "Epoch 7665: train loss: 0.5476970672607422\n",
            "Epoch 7666: train loss: 0.5476692318916321\n",
            "Epoch 7667: train loss: 0.5476414561271667\n",
            "Epoch 7668: train loss: 0.547613799571991\n",
            "Epoch 7669: train loss: 0.5475860238075256\n",
            "Epoch 7670: train loss: 0.5475583076477051\n",
            "Epoch 7671: train loss: 0.5475305914878845\n",
            "Epoch 7672: train loss: 0.5475028157234192\n",
            "Epoch 7673: train loss: 0.5474751591682434\n",
            "Epoch 7674: train loss: 0.5474473834037781\n",
            "Epoch 7675: train loss: 0.5474197268486023\n",
            "Epoch 7676: train loss: 0.547391951084137\n",
            "Epoch 7677: train loss: 0.5473642349243164\n",
            "Epoch 7678: train loss: 0.5473365187644958\n",
            "Epoch 7679: train loss: 0.5473088622093201\n",
            "Epoch 7680: train loss: 0.5472812056541443\n",
            "Epoch 7681: train loss: 0.5472533702850342\n",
            "Epoch 7682: train loss: 0.5472257137298584\n",
            "Epoch 7683: train loss: 0.5471980571746826\n",
            "Epoch 7684: train loss: 0.5471704006195068\n",
            "Epoch 7685: train loss: 0.5471426844596863\n",
            "Epoch 7686: train loss: 0.5471149682998657\n",
            "Epoch 7687: train loss: 0.5470873117446899\n",
            "Epoch 7688: train loss: 0.5470597147941589\n",
            "Epoch 7689: train loss: 0.5470319986343384\n",
            "Epoch 7690: train loss: 0.5470043420791626\n",
            "Epoch 7691: train loss: 0.546976625919342\n",
            "Epoch 7692: train loss: 0.5469489693641663\n",
            "Epoch 7693: train loss: 0.5469213128089905\n",
            "Epoch 7694: train loss: 0.5468935966491699\n",
            "Epoch 7695: train loss: 0.5468659996986389\n",
            "Epoch 7696: train loss: 0.5468383431434631\n",
            "Epoch 7697: train loss: 0.5468106865882874\n",
            "Epoch 7698: train loss: 0.5467829704284668\n",
            "Epoch 7699: train loss: 0.5467554330825806\n",
            "Epoch 7700: train loss: 0.5467277765274048\n",
            "Epoch 7701: train loss: 0.5467001795768738\n",
            "Epoch 7702: train loss: 0.5466724038124084\n",
            "Epoch 7703: train loss: 0.5466448664665222\n",
            "Epoch 7704: train loss: 0.5466172099113464\n",
            "Epoch 7705: train loss: 0.5465895533561707\n",
            "Epoch 7706: train loss: 0.5465619564056396\n",
            "Epoch 7707: train loss: 0.5465342998504639\n",
            "Epoch 7708: train loss: 0.5465067028999329\n",
            "Epoch 7709: train loss: 0.5464790463447571\n",
            "Epoch 7710: train loss: 0.5464515089988708\n",
            "Epoch 7711: train loss: 0.5464238524436951\n",
            "Epoch 7712: train loss: 0.5463962554931641\n",
            "Epoch 7713: train loss: 0.5463686585426331\n",
            "Epoch 7714: train loss: 0.546341061592102\n",
            "Epoch 7715: train loss: 0.5463135242462158\n",
            "Epoch 7716: train loss: 0.5462858080863953\n",
            "Epoch 7717: train loss: 0.546258270740509\n",
            "Epoch 7718: train loss: 0.546230673789978\n",
            "Epoch 7719: train loss: 0.5462030172348022\n",
            "Epoch 7720: train loss: 0.546175479888916\n",
            "Epoch 7721: train loss: 0.546147882938385\n",
            "Epoch 7722: train loss: 0.5461203455924988\n",
            "Epoch 7723: train loss: 0.5460926294326782\n",
            "Epoch 7724: train loss: 0.5460651516914368\n",
            "Epoch 7725: train loss: 0.5460376143455505\n",
            "Epoch 7726: train loss: 0.54600989818573\n",
            "Epoch 7727: train loss: 0.5459824204444885\n",
            "Epoch 7728: train loss: 0.5459548830986023\n",
            "Epoch 7729: train loss: 0.5459273457527161\n",
            "Epoch 7730: train loss: 0.5458996891975403\n",
            "Epoch 7731: train loss: 0.545872151851654\n",
            "Epoch 7732: train loss: 0.545844554901123\n",
            "Epoch 7733: train loss: 0.545816957950592\n",
            "Epoch 7734: train loss: 0.5457895398139954\n",
            "Epoch 7735: train loss: 0.5457618832588196\n",
            "Epoch 7736: train loss: 0.5457344055175781\n",
            "Epoch 7737: train loss: 0.5457068681716919\n",
            "Epoch 7738: train loss: 0.5456792712211609\n",
            "Epoch 7739: train loss: 0.5456517338752747\n",
            "Epoch 7740: train loss: 0.5456242561340332\n",
            "Epoch 7741: train loss: 0.5455966591835022\n",
            "Epoch 7742: train loss: 0.545569121837616\n",
            "Epoch 7743: train loss: 0.5455416440963745\n",
            "Epoch 7744: train loss: 0.5455139875411987\n",
            "Epoch 7745: train loss: 0.5454865097999573\n",
            "Epoch 7746: train loss: 0.5454590320587158\n",
            "Epoch 7747: train loss: 0.5454314351081848\n",
            "Epoch 7748: train loss: 0.5454039573669434\n",
            "Epoch 7749: train loss: 0.5453764796257019\n",
            "Epoch 7750: train loss: 0.5453489422798157\n",
            "Epoch 7751: train loss: 0.5453214645385742\n",
            "Epoch 7752: train loss: 0.5452938675880432\n",
            "Epoch 7753: train loss: 0.545266330242157\n",
            "Epoch 7754: train loss: 0.5452389121055603\n",
            "Epoch 7755: train loss: 0.5452113151550293\n",
            "Epoch 7756: train loss: 0.5451838374137878\n",
            "Epoch 7757: train loss: 0.5451563596725464\n",
            "Epoch 7758: train loss: 0.5451288819313049\n",
            "Epoch 7759: train loss: 0.5451013445854187\n",
            "Epoch 7760: train loss: 0.5450738668441772\n",
            "Epoch 7761: train loss: 0.5450463891029358\n",
            "Epoch 7762: train loss: 0.5450189709663391\n",
            "Epoch 7763: train loss: 0.5449913144111633\n",
            "Epoch 7764: train loss: 0.5449638962745667\n",
            "Epoch 7765: train loss: 0.54493647813797\n",
            "Epoch 7766: train loss: 0.544908881187439\n",
            "Epoch 7767: train loss: 0.5448814630508423\n",
            "Epoch 7768: train loss: 0.5448539853096008\n",
            "Epoch 7769: train loss: 0.5448265075683594\n",
            "Epoch 7770: train loss: 0.5447990298271179\n",
            "Epoch 7771: train loss: 0.5447715520858765\n",
            "Epoch 7772: train loss: 0.544744074344635\n",
            "Epoch 7773: train loss: 0.5447165966033936\n",
            "Epoch 7774: train loss: 0.5446891188621521\n",
            "Epoch 7775: train loss: 0.5446617007255554\n",
            "Epoch 7776: train loss: 0.544634222984314\n",
            "Epoch 7777: train loss: 0.5446067452430725\n",
            "Epoch 7778: train loss: 0.544579267501831\n",
            "Epoch 7779: train loss: 0.5445517897605896\n",
            "Epoch 7780: train loss: 0.5445244312286377\n",
            "Epoch 7781: train loss: 0.5444968938827515\n",
            "Epoch 7782: train loss: 0.5444694757461548\n",
            "Epoch 7783: train loss: 0.5444419980049133\n",
            "Epoch 7784: train loss: 0.5444145202636719\n",
            "Epoch 7785: train loss: 0.54438716173172\n",
            "Epoch 7786: train loss: 0.5443596839904785\n",
            "Epoch 7787: train loss: 0.5443322658538818\n",
            "Epoch 7788: train loss: 0.5443047881126404\n",
            "Epoch 7789: train loss: 0.5442773699760437\n",
            "Epoch 7790: train loss: 0.5442498922348022\n",
            "Epoch 7791: train loss: 0.5442224740982056\n",
            "Epoch 7792: train loss: 0.5441950559616089\n",
            "Epoch 7793: train loss: 0.5441675782203674\n",
            "Epoch 7794: train loss: 0.5441401600837708\n",
            "Epoch 7795: train loss: 0.5441126823425293\n",
            "Epoch 7796: train loss: 0.5440852642059326\n",
            "Epoch 7797: train loss: 0.5440578460693359\n",
            "Epoch 7798: train loss: 0.5440304279327393\n",
            "Epoch 7799: train loss: 0.5440030694007874\n",
            "Epoch 7800: train loss: 0.5439755916595459\n",
            "Epoch 7801: train loss: 0.5439481735229492\n",
            "Epoch 7802: train loss: 0.5439207553863525\n",
            "Epoch 7803: train loss: 0.5438933372497559\n",
            "Epoch 7804: train loss: 0.5438659191131592\n",
            "Epoch 7805: train loss: 0.5438385009765625\n",
            "Epoch 7806: train loss: 0.5438111424446106\n",
            "Epoch 7807: train loss: 0.5437837243080139\n",
            "Epoch 7808: train loss: 0.5437563061714172\n",
            "Epoch 7809: train loss: 0.5437288284301758\n",
            "Epoch 7810: train loss: 0.5437014102935791\n",
            "Epoch 7811: train loss: 0.5436739921569824\n",
            "Epoch 7812: train loss: 0.5436466336250305\n",
            "Epoch 7813: train loss: 0.5436191558837891\n",
            "Epoch 7814: train loss: 0.5435918569564819\n",
            "Epoch 7815: train loss: 0.5435644388198853\n",
            "Epoch 7816: train loss: 0.5435369610786438\n",
            "Epoch 7817: train loss: 0.5435096025466919\n",
            "Epoch 7818: train loss: 0.5434821844100952\n",
            "Epoch 7819: train loss: 0.5434548258781433\n",
            "Epoch 7820: train loss: 0.5434274077415466\n",
            "Epoch 7821: train loss: 0.5434000492095947\n",
            "Epoch 7822: train loss: 0.5433725714683533\n",
            "Epoch 7823: train loss: 0.5433452129364014\n",
            "Epoch 7824: train loss: 0.5433178544044495\n",
            "Epoch 7825: train loss: 0.5432904362678528\n",
            "Epoch 7826: train loss: 0.5432631373405457\n",
            "Epoch 7827: train loss: 0.543235719203949\n",
            "Epoch 7828: train loss: 0.5432083010673523\n",
            "Epoch 7829: train loss: 0.5431808829307556\n",
            "Epoch 7830: train loss: 0.5431535840034485\n",
            "Epoch 7831: train loss: 0.543126106262207\n",
            "Epoch 7832: train loss: 0.5430987477302551\n",
            "Epoch 7833: train loss: 0.5430713891983032\n",
            "Epoch 7834: train loss: 0.5430439710617065\n",
            "Epoch 7835: train loss: 0.5430165529251099\n",
            "Epoch 7836: train loss: 0.5429892539978027\n",
            "Epoch 7837: train loss: 0.542961835861206\n",
            "Epoch 7838: train loss: 0.5429344773292542\n",
            "Epoch 7839: train loss: 0.5429070591926575\n",
            "Epoch 7840: train loss: 0.5428797602653503\n",
            "Epoch 7841: train loss: 0.5428524017333984\n",
            "Epoch 7842: train loss: 0.5428250432014465\n",
            "Epoch 7843: train loss: 0.5427976846694946\n",
            "Epoch 7844: train loss: 0.542770266532898\n",
            "Epoch 7845: train loss: 0.5427429676055908\n",
            "Epoch 7846: train loss: 0.5427156090736389\n",
            "Epoch 7847: train loss: 0.5426881909370422\n",
            "Epoch 7848: train loss: 0.5426607728004456\n",
            "Epoch 7849: train loss: 0.5426334738731384\n",
            "Epoch 7850: train loss: 0.5426060557365417\n",
            "Epoch 7851: train loss: 0.5425787568092346\n",
            "Epoch 7852: train loss: 0.5425513386726379\n",
            "Epoch 7853: train loss: 0.542523980140686\n",
            "Epoch 7854: train loss: 0.5424966216087341\n",
            "Epoch 7855: train loss: 0.542469322681427\n",
            "Epoch 7856: train loss: 0.5424419045448303\n",
            "Epoch 7857: train loss: 0.5424145460128784\n",
            "Epoch 7858: train loss: 0.5423871874809265\n",
            "Epoch 7859: train loss: 0.5423598885536194\n",
            "Epoch 7860: train loss: 0.5423324108123779\n",
            "Epoch 7861: train loss: 0.5423051118850708\n",
            "Epoch 7862: train loss: 0.5422777533531189\n",
            "Epoch 7863: train loss: 0.542250394821167\n",
            "Epoch 7864: train loss: 0.5422230362892151\n",
            "Epoch 7865: train loss: 0.542195737361908\n",
            "Epoch 7866: train loss: 0.5421683192253113\n",
            "Epoch 7867: train loss: 0.5421410202980042\n",
            "Epoch 7868: train loss: 0.5421136021614075\n",
            "Epoch 7869: train loss: 0.5420863032341003\n",
            "Epoch 7870: train loss: 0.5420589447021484\n",
            "Epoch 7871: train loss: 0.5420316457748413\n",
            "Epoch 7872: train loss: 0.5420042872428894\n",
            "Epoch 7873: train loss: 0.5419769287109375\n",
            "Epoch 7874: train loss: 0.5419495701789856\n",
            "Epoch 7875: train loss: 0.5419222712516785\n",
            "Epoch 7876: train loss: 0.5418949127197266\n",
            "Epoch 7877: train loss: 0.5418674945831299\n",
            "Epoch 7878: train loss: 0.5418401956558228\n",
            "Epoch 7879: train loss: 0.5418128371238708\n",
            "Epoch 7880: train loss: 0.5417855381965637\n",
            "Epoch 7881: train loss: 0.5417581796646118\n",
            "Epoch 7882: train loss: 0.5417308807373047\n",
            "Epoch 7883: train loss: 0.541703462600708\n",
            "Epoch 7884: train loss: 0.5416761040687561\n",
            "Epoch 7885: train loss: 0.541648805141449\n",
            "Epoch 7886: train loss: 0.5416214466094971\n",
            "Epoch 7887: train loss: 0.5415940880775452\n",
            "Epoch 7888: train loss: 0.541566789150238\n",
            "Epoch 7889: train loss: 0.5415394306182861\n",
            "Epoch 7890: train loss: 0.541512131690979\n",
            "Epoch 7891: train loss: 0.5414847135543823\n",
            "Epoch 7892: train loss: 0.5414574146270752\n",
            "Epoch 7893: train loss: 0.5414300560951233\n",
            "Epoch 7894: train loss: 0.5414027571678162\n",
            "Epoch 7895: train loss: 0.5413753390312195\n",
            "Epoch 7896: train loss: 0.5413480997085571\n",
            "Epoch 7897: train loss: 0.5413206815719604\n",
            "Epoch 7898: train loss: 0.5412933230400085\n",
            "Epoch 7899: train loss: 0.5412660241127014\n",
            "Epoch 7900: train loss: 0.5412387251853943\n",
            "Epoch 7901: train loss: 0.5412113666534424\n",
            "Epoch 7902: train loss: 0.5411840081214905\n",
            "Epoch 7903: train loss: 0.5411567091941833\n",
            "Epoch 7904: train loss: 0.5411293506622314\n",
            "Epoch 7905: train loss: 0.5411020517349243\n",
            "Epoch 7906: train loss: 0.5410746932029724\n",
            "Epoch 7907: train loss: 0.5410473346710205\n",
            "Epoch 7908: train loss: 0.5410200357437134\n",
            "Epoch 7909: train loss: 0.5409926772117615\n",
            "Epoch 7910: train loss: 0.5409653186798096\n",
            "Epoch 7911: train loss: 0.5409380197525024\n",
            "Epoch 7912: train loss: 0.5409106612205505\n",
            "Epoch 7913: train loss: 0.5408833622932434\n",
            "Epoch 7914: train loss: 0.5408560037612915\n",
            "Epoch 7915: train loss: 0.5408287048339844\n",
            "Epoch 7916: train loss: 0.5408013463020325\n",
            "Epoch 7917: train loss: 0.5407739877700806\n",
            "Epoch 7918: train loss: 0.5407466888427734\n",
            "Epoch 7919: train loss: 0.5407193303108215\n",
            "Epoch 7920: train loss: 0.5406920313835144\n",
            "Epoch 7921: train loss: 0.5406646132469177\n",
            "Epoch 7922: train loss: 0.5406373143196106\n",
            "Epoch 7923: train loss: 0.5406100153923035\n",
            "Epoch 7924: train loss: 0.5405826568603516\n",
            "Epoch 7925: train loss: 0.5405552387237549\n",
            "Epoch 7926: train loss: 0.5405279994010925\n",
            "Epoch 7927: train loss: 0.5405006408691406\n",
            "Epoch 7928: train loss: 0.5404732823371887\n",
            "Epoch 7929: train loss: 0.5404459238052368\n",
            "Epoch 7930: train loss: 0.5404186248779297\n",
            "Epoch 7931: train loss: 0.540391206741333\n",
            "Epoch 7932: train loss: 0.5403639674186707\n",
            "Epoch 7933: train loss: 0.540336549282074\n",
            "Epoch 7934: train loss: 0.5403092503547668\n",
            "Epoch 7935: train loss: 0.5402818918228149\n",
            "Epoch 7936: train loss: 0.5402545928955078\n",
            "Epoch 7937: train loss: 0.5402271747589111\n",
            "Epoch 7938: train loss: 0.5401999354362488\n",
            "Epoch 7939: train loss: 0.5401725172996521\n",
            "Epoch 7940: train loss: 0.540145218372345\n",
            "Epoch 7941: train loss: 0.5401178598403931\n",
            "Epoch 7942: train loss: 0.5400905609130859\n",
            "Epoch 7943: train loss: 0.540063202381134\n",
            "Epoch 7944: train loss: 0.5400358438491821\n",
            "Epoch 7945: train loss: 0.5400084853172302\n",
            "Epoch 7946: train loss: 0.5399811863899231\n",
            "Epoch 7947: train loss: 0.5399538278579712\n",
            "Epoch 7948: train loss: 0.5399264693260193\n",
            "Epoch 7949: train loss: 0.5398991703987122\n",
            "Epoch 7950: train loss: 0.5398718118667603\n",
            "Epoch 7951: train loss: 0.5398444533348083\n",
            "Epoch 7952: train loss: 0.5398170948028564\n",
            "Epoch 7953: train loss: 0.5397897362709045\n",
            "Epoch 7954: train loss: 0.5397624373435974\n",
            "Epoch 7955: train loss: 0.5397350192070007\n",
            "Epoch 7956: train loss: 0.5397077202796936\n",
            "Epoch 7957: train loss: 0.5396803021430969\n",
            "Epoch 7958: train loss: 0.5396530032157898\n",
            "Epoch 7959: train loss: 0.5396255850791931\n",
            "Epoch 7960: train loss: 0.5395982265472412\n",
            "Epoch 7961: train loss: 0.5395709276199341\n",
            "Epoch 7962: train loss: 0.5395435690879822\n",
            "Epoch 7963: train loss: 0.5395162105560303\n",
            "Epoch 7964: train loss: 0.5394888520240784\n",
            "Epoch 7965: train loss: 0.5394614934921265\n",
            "Epoch 7966: train loss: 0.5394341349601746\n",
            "Epoch 7967: train loss: 0.5394067764282227\n",
            "Epoch 7968: train loss: 0.5393794178962708\n",
            "Epoch 7969: train loss: 0.5393520593643188\n",
            "Epoch 7970: train loss: 0.5393247604370117\n",
            "Epoch 7971: train loss: 0.5392972826957703\n",
            "Epoch 7972: train loss: 0.5392699837684631\n",
            "Epoch 7973: train loss: 0.5392425656318665\n",
            "Epoch 7974: train loss: 0.5392152667045593\n",
            "Epoch 7975: train loss: 0.5391877889633179\n",
            "Epoch 7976: train loss: 0.5391604900360107\n",
            "Epoch 7977: train loss: 0.5391330718994141\n",
            "Epoch 7978: train loss: 0.5391057729721069\n",
            "Epoch 7979: train loss: 0.539078414440155\n",
            "Epoch 7980: train loss: 0.5390510559082031\n",
            "Epoch 7981: train loss: 0.5390236973762512\n",
            "Epoch 7982: train loss: 0.5389962792396545\n",
            "Epoch 7983: train loss: 0.5389689207077026\n",
            "Epoch 7984: train loss: 0.5389415621757507\n",
            "Epoch 7985: train loss: 0.538914144039154\n",
            "Epoch 7986: train loss: 0.5388867855072021\n",
            "Epoch 7987: train loss: 0.5388594269752502\n",
            "Epoch 7988: train loss: 0.5388320088386536\n",
            "Epoch 7989: train loss: 0.5388046503067017\n",
            "Epoch 7990: train loss: 0.538777232170105\n",
            "Epoch 7991: train loss: 0.5387498736381531\n",
            "Epoch 7992: train loss: 0.5387224555015564\n",
            "Epoch 7993: train loss: 0.5386951565742493\n",
            "Epoch 7994: train loss: 0.5386677384376526\n",
            "Epoch 7995: train loss: 0.5386403203010559\n",
            "Epoch 7996: train loss: 0.5386130213737488\n",
            "Epoch 7997: train loss: 0.5385855436325073\n",
            "Epoch 7998: train loss: 0.5385582447052002\n",
            "Epoch 7999: train loss: 0.5385308265686035\n",
            "Epoch 8000: train loss: 0.5385034084320068\n",
            "Epoch 8001: train loss: 0.5384760499000549\n",
            "Epoch 8002: train loss: 0.5384486317634583\n",
            "Epoch 8003: train loss: 0.5384211540222168\n",
            "Epoch 8004: train loss: 0.5383937954902649\n",
            "Epoch 8005: train loss: 0.5383663773536682\n",
            "Epoch 8006: train loss: 0.5383390188217163\n",
            "Epoch 8007: train loss: 0.5383116602897644\n",
            "Epoch 8008: train loss: 0.538284182548523\n",
            "Epoch 8009: train loss: 0.538256824016571\n",
            "Epoch 8010: train loss: 0.5382294654846191\n",
            "Epoch 8011: train loss: 0.5382019877433777\n",
            "Epoch 8012: train loss: 0.538174569606781\n",
            "Epoch 8013: train loss: 0.5381472110748291\n",
            "Epoch 8014: train loss: 0.5381197333335876\n",
            "Epoch 8015: train loss: 0.5380924344062805\n",
            "Epoch 8016: train loss: 0.5380649566650391\n",
            "Epoch 8017: train loss: 0.5380375385284424\n",
            "Epoch 8018: train loss: 0.5380101203918457\n",
            "Epoch 8019: train loss: 0.537982702255249\n",
            "Epoch 8020: train loss: 0.5379552841186523\n",
            "Epoch 8021: train loss: 0.5379278063774109\n",
            "Epoch 8022: train loss: 0.537900447845459\n",
            "Epoch 8023: train loss: 0.5378729701042175\n",
            "Epoch 8024: train loss: 0.5378456115722656\n",
            "Epoch 8025: train loss: 0.5378181338310242\n",
            "Epoch 8026: train loss: 0.5377906560897827\n",
            "Epoch 8027: train loss: 0.5377632975578308\n",
            "Epoch 8028: train loss: 0.5377358198165894\n",
            "Epoch 8029: train loss: 0.5377084016799927\n",
            "Epoch 8030: train loss: 0.5376809239387512\n",
            "Epoch 8031: train loss: 0.5376535058021545\n",
            "Epoch 8032: train loss: 0.5376261472702026\n",
            "Epoch 8033: train loss: 0.5375986099243164\n",
            "Epoch 8034: train loss: 0.5375711917877197\n",
            "Epoch 8035: train loss: 0.537543773651123\n",
            "Epoch 8036: train loss: 0.5375162959098816\n",
            "Epoch 8037: train loss: 0.5374888777732849\n",
            "Epoch 8038: train loss: 0.5374614596366882\n",
            "Epoch 8039: train loss: 0.5374339818954468\n",
            "Epoch 8040: train loss: 0.5374065041542053\n",
            "Epoch 8041: train loss: 0.5373790264129639\n",
            "Epoch 8042: train loss: 0.5373516082763672\n",
            "Epoch 8043: train loss: 0.537324070930481\n",
            "Epoch 8044: train loss: 0.5372966527938843\n",
            "Epoch 8045: train loss: 0.537269115447998\n",
            "Epoch 8046: train loss: 0.5372416973114014\n",
            "Epoch 8047: train loss: 0.5372142195701599\n",
            "Epoch 8048: train loss: 0.5371867418289185\n",
            "Epoch 8049: train loss: 0.5371593236923218\n",
            "Epoch 8050: train loss: 0.5371317863464355\n",
            "Epoch 8051: train loss: 0.5371043086051941\n",
            "Epoch 8052: train loss: 0.5370768904685974\n",
            "Epoch 8053: train loss: 0.5370492935180664\n",
            "Epoch 8054: train loss: 0.5370218753814697\n",
            "Epoch 8055: train loss: 0.5369943380355835\n",
            "Epoch 8056: train loss: 0.5369669198989868\n",
            "Epoch 8057: train loss: 0.5369394421577454\n",
            "Epoch 8058: train loss: 0.5369119048118591\n",
            "Epoch 8059: train loss: 0.5368844270706177\n",
            "Epoch 8060: train loss: 0.5368569493293762\n",
            "Epoch 8061: train loss: 0.53682941198349\n",
            "Epoch 8062: train loss: 0.5368019342422485\n",
            "Epoch 8063: train loss: 0.5367743968963623\n",
            "Epoch 8064: train loss: 0.5367469191551208\n",
            "Epoch 8065: train loss: 0.5367193818092346\n",
            "Epoch 8066: train loss: 0.5366918444633484\n",
            "Epoch 8067: train loss: 0.5366643667221069\n",
            "Epoch 8068: train loss: 0.5366368293762207\n",
            "Epoch 8069: train loss: 0.5366092920303345\n",
            "Epoch 8070: train loss: 0.536581814289093\n",
            "Epoch 8071: train loss: 0.5365542769432068\n",
            "Epoch 8072: train loss: 0.5365267395973206\n",
            "Epoch 8073: train loss: 0.5364992022514343\n",
            "Epoch 8074: train loss: 0.5364716649055481\n",
            "Epoch 8075: train loss: 0.5364441275596619\n",
            "Epoch 8076: train loss: 0.5364165902137756\n",
            "Epoch 8077: train loss: 0.5363890528678894\n",
            "Epoch 8078: train loss: 0.5363615155220032\n",
            "Epoch 8079: train loss: 0.5363340377807617\n",
            "Epoch 8080: train loss: 0.5363064408302307\n",
            "Epoch 8081: train loss: 0.5362788438796997\n",
            "Epoch 8082: train loss: 0.5362513661384583\n",
            "Epoch 8083: train loss: 0.5362237691879272\n",
            "Epoch 8084: train loss: 0.5361961722373962\n",
            "Epoch 8085: train loss: 0.5361686944961548\n",
            "Epoch 8086: train loss: 0.5361410975456238\n",
            "Epoch 8087: train loss: 0.5361135601997375\n",
            "Epoch 8088: train loss: 0.5360860228538513\n",
            "Epoch 8089: train loss: 0.5360584259033203\n",
            "Epoch 8090: train loss: 0.5360308289527893\n",
            "Epoch 8091: train loss: 0.5360032916069031\n",
            "Epoch 8092: train loss: 0.5359756946563721\n",
            "Epoch 8093: train loss: 0.5359480977058411\n",
            "Epoch 8094: train loss: 0.5359205007553101\n",
            "Epoch 8095: train loss: 0.5358929634094238\n",
            "Epoch 8096: train loss: 0.535865306854248\n",
            "Epoch 8097: train loss: 0.5358377695083618\n",
            "Epoch 8098: train loss: 0.5358101725578308\n",
            "Epoch 8099: train loss: 0.535782516002655\n",
            "Epoch 8100: train loss: 0.535754919052124\n",
            "Epoch 8101: train loss: 0.535727322101593\n",
            "Epoch 8102: train loss: 0.5356997847557068\n",
            "Epoch 8103: train loss: 0.5356720685958862\n",
            "Epoch 8104: train loss: 0.53564453125\n",
            "Epoch 8105: train loss: 0.5356168746948242\n",
            "Epoch 8106: train loss: 0.5355892777442932\n",
            "Epoch 8107: train loss: 0.5355616807937622\n",
            "Epoch 8108: train loss: 0.5355340838432312\n",
            "Epoch 8109: train loss: 0.5355064272880554\n",
            "Epoch 8110: train loss: 0.5354787707328796\n",
            "Epoch 8111: train loss: 0.5354511737823486\n",
            "Epoch 8112: train loss: 0.5354235172271729\n",
            "Epoch 8113: train loss: 0.5353958606719971\n",
            "Epoch 8114: train loss: 0.5353681445121765\n",
            "Epoch 8115: train loss: 0.5353406071662903\n",
            "Epoch 8116: train loss: 0.5353129506111145\n",
            "Epoch 8117: train loss: 0.5352852940559387\n",
            "Epoch 8118: train loss: 0.5352575778961182\n",
            "Epoch 8119: train loss: 0.5352299213409424\n",
            "Epoch 8120: train loss: 0.5352022647857666\n",
            "Epoch 8121: train loss: 0.5351746678352356\n",
            "Epoch 8122: train loss: 0.535146951675415\n",
            "Epoch 8123: train loss: 0.535119354724884\n",
            "Epoch 8124: train loss: 0.5350916385650635\n",
            "Epoch 8125: train loss: 0.5350639820098877\n",
            "Epoch 8126: train loss: 0.5350362062454224\n",
            "Epoch 8127: train loss: 0.5350085496902466\n",
            "Epoch 8128: train loss: 0.5349808931350708\n",
            "Epoch 8129: train loss: 0.534953236579895\n",
            "Epoch 8130: train loss: 0.5349254608154297\n",
            "Epoch 8131: train loss: 0.5348977446556091\n",
            "Epoch 8132: train loss: 0.5348700881004333\n",
            "Epoch 8133: train loss: 0.5348424315452576\n",
            "Epoch 8134: train loss: 0.5348147749900818\n",
            "Epoch 8135: train loss: 0.5347869396209717\n",
            "Epoch 8136: train loss: 0.5347592234611511\n",
            "Epoch 8137: train loss: 0.5347315073013306\n",
            "Epoch 8138: train loss: 0.5347038507461548\n",
            "Epoch 8139: train loss: 0.5346760749816895\n",
            "Epoch 8140: train loss: 0.5346482992172241\n",
            "Epoch 8141: train loss: 0.5346206426620483\n",
            "Epoch 8142: train loss: 0.534592866897583\n",
            "Epoch 8143: train loss: 0.5345650911331177\n",
            "Epoch 8144: train loss: 0.5345373749732971\n",
            "Epoch 8145: train loss: 0.5345096588134766\n",
            "Epoch 8146: train loss: 0.5344818234443665\n",
            "Epoch 8147: train loss: 0.5344541072845459\n",
            "Epoch 8148: train loss: 0.5344263315200806\n",
            "Epoch 8149: train loss: 0.53439861536026\n",
            "Epoch 8150: train loss: 0.5343708395957947\n",
            "Epoch 8151: train loss: 0.5343430638313293\n",
            "Epoch 8152: train loss: 0.5343152284622192\n",
            "Epoch 8153: train loss: 0.5342874526977539\n",
            "Epoch 8154: train loss: 0.5342597365379333\n",
            "Epoch 8155: train loss: 0.534231960773468\n",
            "Epoch 8156: train loss: 0.5342041850090027\n",
            "Epoch 8157: train loss: 0.5341763496398926\n",
            "Epoch 8158: train loss: 0.5341485142707825\n",
            "Epoch 8159: train loss: 0.5341207385063171\n",
            "Epoch 8160: train loss: 0.534092903137207\n",
            "Epoch 8161: train loss: 0.5340651273727417\n",
            "Epoch 8162: train loss: 0.5340373516082764\n",
            "Epoch 8163: train loss: 0.5340094566345215\n",
            "Epoch 8164: train loss: 0.5339816808700562\n",
            "Epoch 8165: train loss: 0.533953845500946\n",
            "Epoch 8166: train loss: 0.5339260101318359\n",
            "Epoch 8167: train loss: 0.5338981747627258\n",
            "Epoch 8168: train loss: 0.5338703393936157\n",
            "Epoch 8169: train loss: 0.5338425040245056\n",
            "Epoch 8170: train loss: 0.5338146686553955\n",
            "Epoch 8171: train loss: 0.5337867736816406\n",
            "Epoch 8172: train loss: 0.5337589383125305\n",
            "Epoch 8173: train loss: 0.5337311029434204\n",
            "Epoch 8174: train loss: 0.5337032675743103\n",
            "Epoch 8175: train loss: 0.5336753726005554\n",
            "Epoch 8176: train loss: 0.5336474776268005\n",
            "Epoch 8177: train loss: 0.5336195826530457\n",
            "Epoch 8178: train loss: 0.5335917472839355\n",
            "Epoch 8179: train loss: 0.5335638523101807\n",
            "Epoch 8180: train loss: 0.5335359573364258\n",
            "Epoch 8181: train loss: 0.5335080623626709\n",
            "Epoch 8182: train loss: 0.5334801077842712\n",
            "Epoch 8183: train loss: 0.5334522724151611\n",
            "Epoch 8184: train loss: 0.5334243774414062\n",
            "Epoch 8185: train loss: 0.5333964228630066\n",
            "Epoch 8186: train loss: 0.5333685278892517\n",
            "Epoch 8187: train loss: 0.5333406925201416\n",
            "Epoch 8188: train loss: 0.5333126783370972\n",
            "Epoch 8189: train loss: 0.5332847833633423\n",
            "Epoch 8190: train loss: 0.5332567691802979\n",
            "Epoch 8191: train loss: 0.533228874206543\n",
            "Epoch 8192: train loss: 0.5332009792327881\n",
            "Epoch 8193: train loss: 0.5331729650497437\n",
            "Epoch 8194: train loss: 0.5331450700759888\n",
            "Epoch 8195: train loss: 0.5331171154975891\n",
            "Epoch 8196: train loss: 0.5330891609191895\n",
            "Epoch 8197: train loss: 0.533061146736145\n",
            "Epoch 8198: train loss: 0.5330332517623901\n",
            "Epoch 8199: train loss: 0.5330052375793457\n",
            "Epoch 8200: train loss: 0.5329772233963013\n",
            "Epoch 8201: train loss: 0.5329492688179016\n",
            "Epoch 8202: train loss: 0.532921314239502\n",
            "Epoch 8203: train loss: 0.5328933000564575\n",
            "Epoch 8204: train loss: 0.5328652858734131\n",
            "Epoch 8205: train loss: 0.5328372716903687\n",
            "Epoch 8206: train loss: 0.5328092575073242\n",
            "Epoch 8207: train loss: 0.5327812433242798\n",
            "Epoch 8208: train loss: 0.5327532291412354\n",
            "Epoch 8209: train loss: 0.5327252149581909\n",
            "Epoch 8210: train loss: 0.5326972007751465\n",
            "Epoch 8211: train loss: 0.532669186592102\n",
            "Epoch 8212: train loss: 0.5326411128044128\n",
            "Epoch 8213: train loss: 0.5326130390167236\n",
            "Epoch 8214: train loss: 0.5325850248336792\n",
            "Epoch 8215: train loss: 0.53255695104599\n",
            "Epoch 8216: train loss: 0.5325289368629456\n",
            "Epoch 8217: train loss: 0.5325008630752563\n",
            "Epoch 8218: train loss: 0.5324727296829224\n",
            "Epoch 8219: train loss: 0.5324447154998779\n",
            "Epoch 8220: train loss: 0.5324166417121887\n",
            "Epoch 8221: train loss: 0.5323885679244995\n",
            "Epoch 8222: train loss: 0.5323604941368103\n",
            "Epoch 8223: train loss: 0.5323324203491211\n",
            "Epoch 8224: train loss: 0.5323042869567871\n",
            "Epoch 8225: train loss: 0.5322761535644531\n",
            "Epoch 8226: train loss: 0.5322480201721191\n",
            "Epoch 8227: train loss: 0.5322199463844299\n",
            "Epoch 8228: train loss: 0.532191812992096\n",
            "Epoch 8229: train loss: 0.532163679599762\n",
            "Epoch 8230: train loss: 0.5321356058120728\n",
            "Epoch 8231: train loss: 0.5321074724197388\n",
            "Epoch 8232: train loss: 0.5320793390274048\n",
            "Epoch 8233: train loss: 0.532051146030426\n",
            "Epoch 8234: train loss: 0.5320229530334473\n",
            "Epoch 8235: train loss: 0.5319948196411133\n",
            "Epoch 8236: train loss: 0.5319666862487793\n",
            "Epoch 8237: train loss: 0.5319385528564453\n",
            "Epoch 8238: train loss: 0.5319104194641113\n",
            "Epoch 8239: train loss: 0.5318821668624878\n",
            "Epoch 8240: train loss: 0.531853973865509\n",
            "Epoch 8241: train loss: 0.531825840473175\n",
            "Epoch 8242: train loss: 0.5317975878715515\n",
            "Epoch 8243: train loss: 0.5317694544792175\n",
            "Epoch 8244: train loss: 0.531741201877594\n",
            "Epoch 8245: train loss: 0.5317130088806152\n",
            "Epoch 8246: train loss: 0.5316847562789917\n",
            "Epoch 8247: train loss: 0.5316565632820129\n",
            "Epoch 8248: train loss: 0.5316283106803894\n",
            "Epoch 8249: train loss: 0.5316001176834106\n",
            "Epoch 8250: train loss: 0.5315718650817871\n",
            "Epoch 8251: train loss: 0.5315436720848083\n",
            "Epoch 8252: train loss: 0.53151535987854\n",
            "Epoch 8253: train loss: 0.5314871668815613\n",
            "Epoch 8254: train loss: 0.5314589142799377\n",
            "Epoch 8255: train loss: 0.5314306020736694\n",
            "Epoch 8256: train loss: 0.5314023494720459\n",
            "Epoch 8257: train loss: 0.5313740372657776\n",
            "Epoch 8258: train loss: 0.531345784664154\n",
            "Epoch 8259: train loss: 0.5313174724578857\n",
            "Epoch 8260: train loss: 0.5312891602516174\n",
            "Epoch 8261: train loss: 0.5312607884407043\n",
            "Epoch 8262: train loss: 0.5312325954437256\n",
            "Epoch 8263: train loss: 0.5312042236328125\n",
            "Epoch 8264: train loss: 0.531175971031189\n",
            "Epoch 8265: train loss: 0.5311476588249207\n",
            "Epoch 8266: train loss: 0.5311192870140076\n",
            "Epoch 8267: train loss: 0.5310909748077393\n",
            "Epoch 8268: train loss: 0.5310626029968262\n",
            "Epoch 8269: train loss: 0.5310342907905579\n",
            "Epoch 8270: train loss: 0.5310059189796448\n",
            "Epoch 8271: train loss: 0.5309775471687317\n",
            "Epoch 8272: train loss: 0.5309492349624634\n",
            "Epoch 8273: train loss: 0.5309208035469055\n",
            "Epoch 8274: train loss: 0.5308923721313477\n",
            "Epoch 8275: train loss: 0.5308640599250793\n",
            "Epoch 8276: train loss: 0.5308356285095215\n",
            "Epoch 8277: train loss: 0.5308072566986084\n",
            "Epoch 8278: train loss: 0.5307788848876953\n",
            "Epoch 8279: train loss: 0.5307504534721375\n",
            "Epoch 8280: train loss: 0.5307220220565796\n",
            "Epoch 8281: train loss: 0.5306935906410217\n",
            "Epoch 8282: train loss: 0.5306652188301086\n",
            "Epoch 8283: train loss: 0.530636727809906\n",
            "Epoch 8284: train loss: 0.5306083559989929\n",
            "Epoch 8285: train loss: 0.5305798649787903\n",
            "Epoch 8286: train loss: 0.5305513739585876\n",
            "Epoch 8287: train loss: 0.5305229425430298\n",
            "Epoch 8288: train loss: 0.5304944515228271\n",
            "Epoch 8289: train loss: 0.5304660201072693\n",
            "Epoch 8290: train loss: 0.5304375290870667\n",
            "Epoch 8291: train loss: 0.530409038066864\n",
            "Epoch 8292: train loss: 0.5303805470466614\n",
            "Epoch 8293: train loss: 0.530351996421814\n",
            "Epoch 8294: train loss: 0.5303235650062561\n",
            "Epoch 8295: train loss: 0.5302950143814087\n",
            "Epoch 8296: train loss: 0.5302664637565613\n",
            "Epoch 8297: train loss: 0.5302379727363586\n",
            "Epoch 8298: train loss: 0.5302094221115112\n",
            "Epoch 8299: train loss: 0.5301809310913086\n",
            "Epoch 8300: train loss: 0.5301523804664612\n",
            "Epoch 8301: train loss: 0.5301238298416138\n",
            "Epoch 8302: train loss: 0.5300952196121216\n",
            "Epoch 8303: train loss: 0.5300666689872742\n",
            "Epoch 8304: train loss: 0.530038058757782\n",
            "Epoch 8305: train loss: 0.5300095081329346\n",
            "Epoch 8306: train loss: 0.5299808979034424\n",
            "Epoch 8307: train loss: 0.529952347278595\n",
            "Epoch 8308: train loss: 0.5299237370491028\n",
            "Epoch 8309: train loss: 0.5298951268196106\n",
            "Epoch 8310: train loss: 0.5298664569854736\n",
            "Epoch 8311: train loss: 0.5298379063606262\n",
            "Epoch 8312: train loss: 0.529809296131134\n",
            "Epoch 8313: train loss: 0.5297806859016418\n",
            "Epoch 8314: train loss: 0.5297519564628601\n",
            "Epoch 8315: train loss: 0.5297234058380127\n",
            "Epoch 8316: train loss: 0.529694676399231\n",
            "Epoch 8317: train loss: 0.529666006565094\n",
            "Epoch 8318: train loss: 0.529637336730957\n",
            "Epoch 8319: train loss: 0.5296086668968201\n",
            "Epoch 8320: train loss: 0.5295799970626831\n",
            "Epoch 8321: train loss: 0.5295512676239014\n",
            "Epoch 8322: train loss: 0.5295225977897644\n",
            "Epoch 8323: train loss: 0.5294938683509827\n",
            "Epoch 8324: train loss: 0.5294651389122009\n",
            "Epoch 8325: train loss: 0.529436469078064\n",
            "Epoch 8326: train loss: 0.529407799243927\n",
            "Epoch 8327: train loss: 0.5293789505958557\n",
            "Epoch 8328: train loss: 0.5293502807617188\n",
            "Epoch 8329: train loss: 0.529321551322937\n",
            "Epoch 8330: train loss: 0.5292927026748657\n",
            "Epoch 8331: train loss: 0.529263973236084\n",
            "Epoch 8332: train loss: 0.5292351841926575\n",
            "Epoch 8333: train loss: 0.5292064547538757\n",
            "Epoch 8334: train loss: 0.5291776657104492\n",
            "Epoch 8335: train loss: 0.5291488170623779\n",
            "Epoch 8336: train loss: 0.5291200280189514\n",
            "Epoch 8337: train loss: 0.5290912389755249\n",
            "Epoch 8338: train loss: 0.5290624499320984\n",
            "Epoch 8339: train loss: 0.5290336012840271\n",
            "Epoch 8340: train loss: 0.5290048122406006\n",
            "Epoch 8341: train loss: 0.5289759039878845\n",
            "Epoch 8342: train loss: 0.528947114944458\n",
            "Epoch 8343: train loss: 0.5289182662963867\n",
            "Epoch 8344: train loss: 0.5288893580436707\n",
            "Epoch 8345: train loss: 0.5288605093955994\n",
            "Epoch 8346: train loss: 0.5288316607475281\n",
            "Epoch 8347: train loss: 0.528802752494812\n",
            "Epoch 8348: train loss: 0.528773844242096\n",
            "Epoch 8349: train loss: 0.5287449955940247\n",
            "Epoch 8350: train loss: 0.5287160873413086\n",
            "Epoch 8351: train loss: 0.5286871790885925\n",
            "Epoch 8352: train loss: 0.5286582112312317\n",
            "Epoch 8353: train loss: 0.5286293029785156\n",
            "Epoch 8354: train loss: 0.5286003351211548\n",
            "Epoch 8355: train loss: 0.5285714268684387\n",
            "Epoch 8356: train loss: 0.5285423994064331\n",
            "Epoch 8357: train loss: 0.5285134315490723\n",
            "Epoch 8358: train loss: 0.528484582901001\n",
            "Epoch 8359: train loss: 0.5284555554389954\n",
            "Epoch 8360: train loss: 0.5284265279769897\n",
            "Epoch 8361: train loss: 0.5283975005149841\n",
            "Epoch 8362: train loss: 0.5283685326576233\n",
            "Epoch 8363: train loss: 0.5283395051956177\n",
            "Epoch 8364: train loss: 0.5283105373382568\n",
            "Epoch 8365: train loss: 0.5282815098762512\n",
            "Epoch 8366: train loss: 0.5282524228096008\n",
            "Epoch 8367: train loss: 0.5282233953475952\n",
            "Epoch 8368: train loss: 0.5281943082809448\n",
            "Epoch 8369: train loss: 0.528165340423584\n",
            "Epoch 8370: train loss: 0.5281361937522888\n",
            "Epoch 8371: train loss: 0.5281071662902832\n",
            "Epoch 8372: train loss: 0.5280780792236328\n",
            "Epoch 8373: train loss: 0.5280489921569824\n",
            "Epoch 8374: train loss: 0.528019905090332\n",
            "Epoch 8375: train loss: 0.5279907584190369\n",
            "Epoch 8376: train loss: 0.5279616117477417\n",
            "Epoch 8377: train loss: 0.5279325246810913\n",
            "Epoch 8378: train loss: 0.5279033780097961\n",
            "Epoch 8379: train loss: 0.5278742909431458\n",
            "Epoch 8380: train loss: 0.5278450846672058\n",
            "Epoch 8381: train loss: 0.5278159379959106\n",
            "Epoch 8382: train loss: 0.5277867913246155\n",
            "Epoch 8383: train loss: 0.5277576446533203\n",
            "Epoch 8384: train loss: 0.5277283787727356\n",
            "Epoch 8385: train loss: 0.5276991724967957\n",
            "Epoch 8386: train loss: 0.5276699662208557\n",
            "Epoch 8387: train loss: 0.5276407599449158\n",
            "Epoch 8388: train loss: 0.527611494064331\n",
            "Epoch 8389: train loss: 0.5275822877883911\n",
            "Epoch 8390: train loss: 0.5275530815124512\n",
            "Epoch 8391: train loss: 0.5275238156318665\n",
            "Epoch 8392: train loss: 0.5274945497512817\n",
            "Epoch 8393: train loss: 0.527465283870697\n",
            "Epoch 8394: train loss: 0.5274360179901123\n",
            "Epoch 8395: train loss: 0.5274067521095276\n",
            "Epoch 8396: train loss: 0.5273774266242981\n",
            "Epoch 8397: train loss: 0.5273482203483582\n",
            "Epoch 8398: train loss: 0.5273188948631287\n",
            "Epoch 8399: train loss: 0.5272895693778992\n",
            "Epoch 8400: train loss: 0.5272602438926697\n",
            "Epoch 8401: train loss: 0.5272309184074402\n",
            "Epoch 8402: train loss: 0.5272016525268555\n",
            "Epoch 8403: train loss: 0.5271722078323364\n",
            "Epoch 8404: train loss: 0.5271428227424622\n",
            "Epoch 8405: train loss: 0.5271134376525879\n",
            "Epoch 8406: train loss: 0.5270841121673584\n",
            "Epoch 8407: train loss: 0.5270546674728394\n",
            "Epoch 8408: train loss: 0.5270252823829651\n",
            "Epoch 8409: train loss: 0.5269958972930908\n",
            "Epoch 8410: train loss: 0.5269664525985718\n",
            "Epoch 8411: train loss: 0.5269370675086975\n",
            "Epoch 8412: train loss: 0.5269076228141785\n",
            "Epoch 8413: train loss: 0.5268781781196594\n",
            "Epoch 8414: train loss: 0.5268487334251404\n",
            "Epoch 8415: train loss: 0.5268192291259766\n",
            "Epoch 8416: train loss: 0.5267897844314575\n",
            "Epoch 8417: train loss: 0.5267602801322937\n",
            "Epoch 8418: train loss: 0.5267308354377747\n",
            "Epoch 8419: train loss: 0.5267012715339661\n",
            "Epoch 8420: train loss: 0.5266717672348022\n",
            "Epoch 8421: train loss: 0.5266423225402832\n",
            "Epoch 8422: train loss: 0.5266127586364746\n",
            "Epoch 8423: train loss: 0.526583194732666\n",
            "Epoch 8424: train loss: 0.5265536308288574\n",
            "Epoch 8425: train loss: 0.5265241861343384\n",
            "Epoch 8426: train loss: 0.526494562625885\n",
            "Epoch 8427: train loss: 0.5264649391174316\n",
            "Epoch 8428: train loss: 0.526435375213623\n",
            "Epoch 8429: train loss: 0.5264058113098145\n",
            "Epoch 8430: train loss: 0.5263761878013611\n",
            "Epoch 8431: train loss: 0.5263465642929077\n",
            "Epoch 8432: train loss: 0.5263169407844543\n",
            "Epoch 8433: train loss: 0.5262872576713562\n",
            "Epoch 8434: train loss: 0.5262576341629028\n",
            "Epoch 8435: train loss: 0.5262280106544495\n",
            "Epoch 8436: train loss: 0.5261983275413513\n",
            "Epoch 8437: train loss: 0.5261686444282532\n",
            "Epoch 8438: train loss: 0.526138961315155\n",
            "Epoch 8439: train loss: 0.5261092782020569\n",
            "Epoch 8440: train loss: 0.5260795950889587\n",
            "Epoch 8441: train loss: 0.5260499119758606\n",
            "Epoch 8442: train loss: 0.5260201692581177\n",
            "Epoch 8443: train loss: 0.52599036693573\n",
            "Epoch 8444: train loss: 0.5259606838226318\n",
            "Epoch 8445: train loss: 0.5259309411048889\n",
            "Epoch 8446: train loss: 0.5259011387825012\n",
            "Epoch 8447: train loss: 0.5258713364601135\n",
            "Epoch 8448: train loss: 0.5258415341377258\n",
            "Epoch 8449: train loss: 0.5258118510246277\n",
            "Epoch 8450: train loss: 0.5257819890975952\n",
            "Epoch 8451: train loss: 0.5257521867752075\n",
            "Epoch 8452: train loss: 0.525722324848175\n",
            "Epoch 8453: train loss: 0.5256925225257874\n",
            "Epoch 8454: train loss: 0.5256626605987549\n",
            "Epoch 8455: train loss: 0.5256327986717224\n",
            "Epoch 8456: train loss: 0.5256029367446899\n",
            "Epoch 8457: train loss: 0.5255730748176575\n",
            "Epoch 8458: train loss: 0.525543212890625\n",
            "Epoch 8459: train loss: 0.5255132913589478\n",
            "Epoch 8460: train loss: 0.5254833698272705\n",
            "Epoch 8461: train loss: 0.525453507900238\n",
            "Epoch 8462: train loss: 0.525423526763916\n",
            "Epoch 8463: train loss: 0.5253936052322388\n",
            "Epoch 8464: train loss: 0.5253636240959167\n",
            "Epoch 8465: train loss: 0.5253337025642395\n",
            "Epoch 8466: train loss: 0.5253036618232727\n",
            "Epoch 8467: train loss: 0.5252737402915955\n",
            "Epoch 8468: train loss: 0.5252437591552734\n",
            "Epoch 8469: train loss: 0.5252137184143066\n",
            "Epoch 8470: train loss: 0.5251837372779846\n",
            "Epoch 8471: train loss: 0.5251536965370178\n",
            "Epoch 8472: train loss: 0.525123655796051\n",
            "Epoch 8473: train loss: 0.5250936150550842\n",
            "Epoch 8474: train loss: 0.5250635743141174\n",
            "Epoch 8475: train loss: 0.5250334739685059\n",
            "Epoch 8476: train loss: 0.5250034332275391\n",
            "Epoch 8477: train loss: 0.5249733328819275\n",
            "Epoch 8478: train loss: 0.5249432325363159\n",
            "Epoch 8479: train loss: 0.5249131321907043\n",
            "Epoch 8480: train loss: 0.524882972240448\n",
            "Epoch 8481: train loss: 0.5248528718948364\n",
            "Epoch 8482: train loss: 0.5248227119445801\n",
            "Epoch 8483: train loss: 0.5247925519943237\n",
            "Epoch 8484: train loss: 0.5247623920440674\n",
            "Epoch 8485: train loss: 0.5247321724891663\n",
            "Epoch 8486: train loss: 0.5247020125389099\n",
            "Epoch 8487: train loss: 0.5246717929840088\n",
            "Epoch 8488: train loss: 0.5246416330337524\n",
            "Epoch 8489: train loss: 0.5246114134788513\n",
            "Epoch 8490: train loss: 0.5245811343193054\n",
            "Epoch 8491: train loss: 0.5245509147644043\n",
            "Epoch 8492: train loss: 0.5245206356048584\n",
            "Epoch 8493: train loss: 0.5244903564453125\n",
            "Epoch 8494: train loss: 0.5244600772857666\n",
            "Epoch 8495: train loss: 0.5244298577308655\n",
            "Epoch 8496: train loss: 0.52439945936203\n",
            "Epoch 8497: train loss: 0.5243691802024841\n",
            "Epoch 8498: train loss: 0.5243387818336487\n",
            "Epoch 8499: train loss: 0.5243085026741028\n",
            "Epoch 8500: train loss: 0.5242781639099121\n",
            "Epoch 8501: train loss: 0.5242478251457214\n",
            "Epoch 8502: train loss: 0.524217426776886\n",
            "Epoch 8503: train loss: 0.5241870880126953\n",
            "Epoch 8504: train loss: 0.5241566300392151\n",
            "Epoch 8505: train loss: 0.5241261720657349\n",
            "Epoch 8506: train loss: 0.5240957736968994\n",
            "Epoch 8507: train loss: 0.524065375328064\n",
            "Epoch 8508: train loss: 0.5240349769592285\n",
            "Epoch 8509: train loss: 0.5240045189857483\n",
            "Epoch 8510: train loss: 0.5239740610122681\n",
            "Epoch 8511: train loss: 0.5239436030387878\n",
            "Epoch 8512: train loss: 0.5239130854606628\n",
            "Epoch 8513: train loss: 0.5238825678825378\n",
            "Epoch 8514: train loss: 0.5238521099090576\n",
            "Epoch 8515: train loss: 0.5238215327262878\n",
            "Epoch 8516: train loss: 0.5237910151481628\n",
            "Epoch 8517: train loss: 0.5237604379653931\n",
            "Epoch 8518: train loss: 0.5237299203872681\n",
            "Epoch 8519: train loss: 0.5236992835998535\n",
            "Epoch 8520: train loss: 0.5236687064170837\n",
            "Epoch 8521: train loss: 0.523638129234314\n",
            "Epoch 8522: train loss: 0.5236074924468994\n",
            "Epoch 8523: train loss: 0.5235768556594849\n",
            "Epoch 8524: train loss: 0.5235462188720703\n",
            "Epoch 8525: train loss: 0.5235156416893005\n",
            "Epoch 8526: train loss: 0.5234849452972412\n",
            "Epoch 8527: train loss: 0.5234543085098267\n",
            "Epoch 8528: train loss: 0.5234236121177673\n",
            "Epoch 8529: train loss: 0.523392915725708\n",
            "Epoch 8530: train loss: 0.5233622193336487\n",
            "Epoch 8531: train loss: 0.5233314633369446\n",
            "Epoch 8532: train loss: 0.5233007669448853\n",
            "Epoch 8533: train loss: 0.5232700109481812\n",
            "Epoch 8534: train loss: 0.523239254951477\n",
            "Epoch 8535: train loss: 0.5232084393501282\n",
            "Epoch 8536: train loss: 0.5231776833534241\n",
            "Epoch 8537: train loss: 0.52314692735672\n",
            "Epoch 8538: train loss: 0.5231161117553711\n",
            "Epoch 8539: train loss: 0.5230852961540222\n",
            "Epoch 8540: train loss: 0.5230544209480286\n",
            "Epoch 8541: train loss: 0.5230236053466797\n",
            "Epoch 8542: train loss: 0.5229927897453308\n",
            "Epoch 8543: train loss: 0.5229619145393372\n",
            "Epoch 8544: train loss: 0.5229309797286987\n",
            "Epoch 8545: train loss: 0.5229001045227051\n",
            "Epoch 8546: train loss: 0.5228692293167114\n",
            "Epoch 8547: train loss: 0.5228382349014282\n",
            "Epoch 8548: train loss: 0.5228073596954346\n",
            "Epoch 8549: train loss: 0.5227763652801514\n",
            "Epoch 8550: train loss: 0.5227454304695129\n",
            "Epoch 8551: train loss: 0.5227144360542297\n",
            "Epoch 8552: train loss: 0.5226834416389465\n",
            "Epoch 8553: train loss: 0.5226524472236633\n",
            "Epoch 8554: train loss: 0.5226214528083801\n",
            "Epoch 8555: train loss: 0.5225904583930969\n",
            "Epoch 8556: train loss: 0.522559404373169\n",
            "Epoch 8557: train loss: 0.522528350353241\n",
            "Epoch 8558: train loss: 0.5224972367286682\n",
            "Epoch 8559: train loss: 0.5224661827087402\n",
            "Epoch 8560: train loss: 0.5224350690841675\n",
            "Epoch 8561: train loss: 0.5224039554595947\n",
            "Epoch 8562: train loss: 0.522372841835022\n",
            "Epoch 8563: train loss: 0.522341787815094\n",
            "Epoch 8564: train loss: 0.5223105549812317\n",
            "Epoch 8565: train loss: 0.5222794413566589\n",
            "Epoch 8566: train loss: 0.5222482085227966\n",
            "Epoch 8567: train loss: 0.5222170352935791\n",
            "Epoch 8568: train loss: 0.5221858024597168\n",
            "Epoch 8569: train loss: 0.522154688835144\n",
            "Epoch 8570: train loss: 0.522123396396637\n",
            "Epoch 8571: train loss: 0.5220921635627747\n",
            "Epoch 8572: train loss: 0.5220609903335571\n",
            "Epoch 8573: train loss: 0.52202969789505\n",
            "Epoch 8574: train loss: 0.521998405456543\n",
            "Epoch 8575: train loss: 0.5219670534133911\n",
            "Epoch 8576: train loss: 0.521935760974884\n",
            "Epoch 8577: train loss: 0.521904468536377\n",
            "Epoch 8578: train loss: 0.5218731164932251\n",
            "Epoch 8579: train loss: 0.5218417644500732\n",
            "Epoch 8580: train loss: 0.5218104124069214\n",
            "Epoch 8581: train loss: 0.5217790007591248\n",
            "Epoch 8582: train loss: 0.5217476487159729\n",
            "Epoch 8583: train loss: 0.5217162370681763\n",
            "Epoch 8584: train loss: 0.5216847658157349\n",
            "Epoch 8585: train loss: 0.5216533541679382\n",
            "Epoch 8586: train loss: 0.5216219425201416\n",
            "Epoch 8587: train loss: 0.5215904712677002\n",
            "Epoch 8588: train loss: 0.521558940410614\n",
            "Epoch 8589: train loss: 0.5215274691581726\n",
            "Epoch 8590: train loss: 0.5214959979057312\n",
            "Epoch 8591: train loss: 0.521464467048645\n",
            "Epoch 8592: train loss: 0.5214328765869141\n",
            "Epoch 8593: train loss: 0.5214013457298279\n",
            "Epoch 8594: train loss: 0.5213698148727417\n",
            "Epoch 8595: train loss: 0.5213382840156555\n",
            "Epoch 8596: train loss: 0.5213066935539246\n",
            "Epoch 8597: train loss: 0.5212750434875488\n",
            "Epoch 8598: train loss: 0.5212433934211731\n",
            "Epoch 8599: train loss: 0.5212117433547974\n",
            "Epoch 8600: train loss: 0.5211800932884216\n",
            "Epoch 8601: train loss: 0.5211485028266907\n",
            "Epoch 8602: train loss: 0.5211167335510254\n",
            "Epoch 8603: train loss: 0.5210851430892944\n",
            "Epoch 8604: train loss: 0.5210533738136292\n",
            "Epoch 8605: train loss: 0.5210217237472534\n",
            "Epoch 8606: train loss: 0.5209899544715881\n",
            "Epoch 8607: train loss: 0.5209582448005676\n",
            "Epoch 8608: train loss: 0.5209264159202576\n",
            "Epoch 8609: train loss: 0.5208946466445923\n",
            "Epoch 8610: train loss: 0.520862877368927\n",
            "Epoch 8611: train loss: 0.5208310484886169\n",
            "Epoch 8612: train loss: 0.5207992196083069\n",
            "Epoch 8613: train loss: 0.520767331123352\n",
            "Epoch 8614: train loss: 0.520735502243042\n",
            "Epoch 8615: train loss: 0.5207036733627319\n",
            "Epoch 8616: train loss: 0.5206717848777771\n",
            "Epoch 8617: train loss: 0.5206398367881775\n",
            "Epoch 8618: train loss: 0.5206079483032227\n",
            "Epoch 8619: train loss: 0.520576000213623\n",
            "Epoch 8620: train loss: 0.5205440521240234\n",
            "Epoch 8621: train loss: 0.5205121040344238\n",
            "Epoch 8622: train loss: 0.5204801559448242\n",
            "Epoch 8623: train loss: 0.5204481482505798\n",
            "Epoch 8624: train loss: 0.5204161405563354\n",
            "Epoch 8625: train loss: 0.5203840732574463\n",
            "Epoch 8626: train loss: 0.5203520655632019\n",
            "Epoch 8627: train loss: 0.5203200578689575\n",
            "Epoch 8628: train loss: 0.5202879309654236\n",
            "Epoch 8629: train loss: 0.5202558636665344\n",
            "Epoch 8630: train loss: 0.5202237367630005\n",
            "Epoch 8631: train loss: 0.5201916694641113\n",
            "Epoch 8632: train loss: 0.5201595425605774\n",
            "Epoch 8633: train loss: 0.5201273560523987\n",
            "Epoch 8634: train loss: 0.52009516954422\n",
            "Epoch 8635: train loss: 0.520063042640686\n",
            "Epoch 8636: train loss: 0.5200308561325073\n",
            "Epoch 8637: train loss: 0.5199986100196838\n",
            "Epoch 8638: train loss: 0.5199664235115051\n",
            "Epoch 8639: train loss: 0.5199341177940369\n",
            "Epoch 8640: train loss: 0.5199019312858582\n",
            "Epoch 8641: train loss: 0.5198696255683899\n",
            "Epoch 8642: train loss: 0.5198373198509216\n",
            "Epoch 8643: train loss: 0.5198050737380981\n",
            "Epoch 8644: train loss: 0.5197726488113403\n",
            "Epoch 8645: train loss: 0.5197404026985168\n",
            "Epoch 8646: train loss: 0.519707977771759\n",
            "Epoch 8647: train loss: 0.519675612449646\n",
            "Epoch 8648: train loss: 0.5196433067321777\n",
            "Epoch 8649: train loss: 0.5196108222007751\n",
            "Epoch 8650: train loss: 0.5195784568786621\n",
            "Epoch 8651: train loss: 0.5195460319519043\n",
            "Epoch 8652: train loss: 0.5195136070251465\n",
            "Epoch 8653: train loss: 0.5194811224937439\n",
            "Epoch 8654: train loss: 0.5194486379623413\n",
            "Epoch 8655: train loss: 0.5194161534309387\n",
            "Epoch 8656: train loss: 0.5193836092948914\n",
            "Epoch 8657: train loss: 0.5193511247634888\n",
            "Epoch 8658: train loss: 0.5193185210227966\n",
            "Epoch 8659: train loss: 0.5192859768867493\n",
            "Epoch 8660: train loss: 0.5192534327507019\n",
            "Epoch 8661: train loss: 0.519220769405365\n",
            "Epoch 8662: train loss: 0.5191882252693176\n",
            "Epoch 8663: train loss: 0.5191555619239807\n",
            "Epoch 8664: train loss: 0.5191228985786438\n",
            "Epoch 8665: train loss: 0.5190902352333069\n",
            "Epoch 8666: train loss: 0.51905757188797\n",
            "Epoch 8667: train loss: 0.5190248489379883\n",
            "Epoch 8668: train loss: 0.5189921259880066\n",
            "Epoch 8669: train loss: 0.5189594626426697\n",
            "Epoch 8670: train loss: 0.5189266800880432\n",
            "Epoch 8671: train loss: 0.5188938975334167\n",
            "Epoch 8672: train loss: 0.5188611149787903\n",
            "Epoch 8673: train loss: 0.5188283324241638\n",
            "Epoch 8674: train loss: 0.5187955498695374\n",
            "Epoch 8675: train loss: 0.5187626481056213\n",
            "Epoch 8676: train loss: 0.5187298059463501\n",
            "Epoch 8677: train loss: 0.5186969637870789\n",
            "Epoch 8678: train loss: 0.5186641216278076\n",
            "Epoch 8679: train loss: 0.5186312198638916\n",
            "Epoch 8680: train loss: 0.5185983180999756\n",
            "Epoch 8681: train loss: 0.5185653567314148\n",
            "Epoch 8682: train loss: 0.518532395362854\n",
            "Epoch 8683: train loss: 0.5184993743896484\n",
            "Epoch 8684: train loss: 0.5184663534164429\n",
            "Epoch 8685: train loss: 0.5184333920478821\n",
            "Epoch 8686: train loss: 0.5184003710746765\n",
            "Epoch 8687: train loss: 0.518367350101471\n",
            "Epoch 8688: train loss: 0.5183342695236206\n",
            "Epoch 8689: train loss: 0.5183011889457703\n",
            "Epoch 8690: train loss: 0.5182680487632751\n",
            "Epoch 8691: train loss: 0.5182350277900696\n",
            "Epoch 8692: train loss: 0.5182018876075745\n",
            "Epoch 8693: train loss: 0.5181687474250793\n",
            "Epoch 8694: train loss: 0.5181356072425842\n",
            "Epoch 8695: train loss: 0.5181024074554443\n",
            "Epoch 8696: train loss: 0.5180692672729492\n",
            "Epoch 8697: train loss: 0.5180359482765198\n",
            "Epoch 8698: train loss: 0.5180028080940247\n",
            "Epoch 8699: train loss: 0.5179694890975952\n",
            "Epoch 8700: train loss: 0.5179362297058105\n",
            "Epoch 8701: train loss: 0.5179029703140259\n",
            "Epoch 8702: train loss: 0.5178696513175964\n",
            "Epoch 8703: train loss: 0.517836332321167\n",
            "Epoch 8704: train loss: 0.5178030133247375\n",
            "Epoch 8705: train loss: 0.5177695751190186\n",
            "Epoch 8706: train loss: 0.5177362561225891\n",
            "Epoch 8707: train loss: 0.5177028179168701\n",
            "Epoch 8708: train loss: 0.5176694393157959\n",
            "Epoch 8709: train loss: 0.5176360011100769\n",
            "Epoch 8710: train loss: 0.5176025629043579\n",
            "Epoch 8711: train loss: 0.5175690054893494\n",
            "Epoch 8712: train loss: 0.5175355076789856\n",
            "Epoch 8713: train loss: 0.5175021290779114\n",
            "Epoch 8714: train loss: 0.5174685716629028\n",
            "Epoch 8715: train loss: 0.5174350738525391\n",
            "Epoch 8716: train loss: 0.5174014568328857\n",
            "Epoch 8717: train loss: 0.5173678398132324\n",
            "Epoch 8718: train loss: 0.5173342823982239\n",
            "Epoch 8719: train loss: 0.5173006057739258\n",
            "Epoch 8720: train loss: 0.5172670483589172\n",
            "Epoch 8721: train loss: 0.5172332525253296\n",
            "Epoch 8722: train loss: 0.517199695110321\n",
            "Epoch 8723: train loss: 0.5171659588813782\n",
            "Epoch 8724: train loss: 0.5171322822570801\n",
            "Epoch 8725: train loss: 0.5170985460281372\n",
            "Epoch 8726: train loss: 0.5170648097991943\n",
            "Epoch 8727: train loss: 0.5170310139656067\n",
            "Epoch 8728: train loss: 0.5169972777366638\n",
            "Epoch 8729: train loss: 0.5169633626937866\n",
            "Epoch 8730: train loss: 0.516929566860199\n",
            "Epoch 8731: train loss: 0.5168957710266113\n",
            "Epoch 8732: train loss: 0.5168618559837341\n",
            "Epoch 8733: train loss: 0.5168280005455017\n",
            "Epoch 8734: train loss: 0.5167941451072693\n",
            "Epoch 8735: train loss: 0.5167601704597473\n",
            "Epoch 8736: train loss: 0.5167262554168701\n",
            "Epoch 8737: train loss: 0.5166922807693481\n",
            "Epoch 8738: train loss: 0.5166582465171814\n",
            "Epoch 8739: train loss: 0.5166243314743042\n",
            "Epoch 8740: train loss: 0.5165902376174927\n",
            "Epoch 8741: train loss: 0.5165562629699707\n",
            "Epoch 8742: train loss: 0.5165221691131592\n",
            "Epoch 8743: train loss: 0.5164880752563477\n",
            "Epoch 8744: train loss: 0.5164540410041809\n",
            "Epoch 8745: train loss: 0.5164199471473694\n",
            "Epoch 8746: train loss: 0.5163857936859131\n",
            "Epoch 8747: train loss: 0.5163516402244568\n",
            "Epoch 8748: train loss: 0.5163174271583557\n",
            "Epoch 8749: train loss: 0.5162832140922546\n",
            "Epoch 8750: train loss: 0.5162490010261536\n",
            "Epoch 8751: train loss: 0.5162147879600525\n",
            "Epoch 8752: train loss: 0.5161805152893066\n",
            "Epoch 8753: train loss: 0.5161462426185608\n",
            "Epoch 8754: train loss: 0.5161119103431702\n",
            "Epoch 8755: train loss: 0.5160776376724243\n",
            "Epoch 8756: train loss: 0.5160433053970337\n",
            "Epoch 8757: train loss: 0.5160089731216431\n",
            "Epoch 8758: train loss: 0.5159745812416077\n",
            "Epoch 8759: train loss: 0.5159401893615723\n",
            "Epoch 8760: train loss: 0.5159057378768921\n",
            "Epoch 8761: train loss: 0.5158712863922119\n",
            "Epoch 8762: train loss: 0.5158368349075317\n",
            "Epoch 8763: train loss: 0.5158023834228516\n",
            "Epoch 8764: train loss: 0.5157678723335266\n",
            "Epoch 8765: train loss: 0.5157334208488464\n",
            "Epoch 8766: train loss: 0.5156988501548767\n",
            "Epoch 8767: train loss: 0.515664279460907\n",
            "Epoch 8768: train loss: 0.5156296491622925\n",
            "Epoch 8769: train loss: 0.5155951380729675\n",
            "Epoch 8770: train loss: 0.5155604481697083\n",
            "Epoch 8771: train loss: 0.5155258178710938\n",
            "Epoch 8772: train loss: 0.5154911875724792\n",
            "Epoch 8773: train loss: 0.51545649766922\n",
            "Epoch 8774: train loss: 0.5154217481613159\n",
            "Epoch 8775: train loss: 0.5153871178627014\n",
            "Epoch 8776: train loss: 0.5153522491455078\n",
            "Epoch 8777: train loss: 0.5153174996376038\n",
            "Epoch 8778: train loss: 0.5152827501296997\n",
            "Epoch 8779: train loss: 0.5152479410171509\n",
            "Epoch 8780: train loss: 0.515213131904602\n",
            "Epoch 8781: train loss: 0.5151782631874084\n",
            "Epoch 8782: train loss: 0.5151434540748596\n",
            "Epoch 8783: train loss: 0.5151084661483765\n",
            "Epoch 8784: train loss: 0.5150735974311829\n",
            "Epoch 8785: train loss: 0.5150386691093445\n",
            "Epoch 8786: train loss: 0.5150036811828613\n",
            "Epoch 8787: train loss: 0.514968752861023\n",
            "Epoch 8788: train loss: 0.514933705329895\n",
            "Epoch 8789: train loss: 0.5148986577987671\n",
            "Epoch 8790: train loss: 0.5148636698722839\n",
            "Epoch 8791: train loss: 0.5148285627365112\n",
            "Epoch 8792: train loss: 0.5147934556007385\n",
            "Epoch 8793: train loss: 0.5147584080696106\n",
            "Epoch 8794: train loss: 0.5147232413291931\n",
            "Epoch 8795: train loss: 0.5146880745887756\n",
            "Epoch 8796: train loss: 0.5146529078483582\n",
            "Epoch 8797: train loss: 0.5146177411079407\n",
            "Epoch 8798: train loss: 0.5145824551582336\n",
            "Epoch 8799: train loss: 0.5145472884178162\n",
            "Epoch 8800: train loss: 0.5145120024681091\n",
            "Epoch 8801: train loss: 0.5144767165184021\n",
            "Epoch 8802: train loss: 0.5144414901733398\n",
            "Epoch 8803: train loss: 0.514406144618988\n",
            "Epoch 8804: train loss: 0.5143707394599915\n",
            "Epoch 8805: train loss: 0.5143354535102844\n",
            "Epoch 8806: train loss: 0.5142999887466431\n",
            "Epoch 8807: train loss: 0.5142646431922913\n",
            "Epoch 8808: train loss: 0.5142292380332947\n",
            "Epoch 8809: train loss: 0.5141937732696533\n",
            "Epoch 8810: train loss: 0.5141582489013672\n",
            "Epoch 8811: train loss: 0.514122724533081\n",
            "Epoch 8812: train loss: 0.5140871405601501\n",
            "Epoch 8813: train loss: 0.514051616191864\n",
            "Epoch 8814: train loss: 0.5140160918235779\n",
            "Epoch 8815: train loss: 0.5139804482460022\n",
            "Epoch 8816: train loss: 0.5139448046684265\n",
            "Epoch 8817: train loss: 0.5139092206954956\n",
            "Epoch 8818: train loss: 0.5138735771179199\n",
            "Epoch 8819: train loss: 0.5138378739356995\n",
            "Epoch 8820: train loss: 0.5138022303581238\n",
            "Epoch 8821: train loss: 0.5137664675712585\n",
            "Epoch 8822: train loss: 0.5137306451797485\n",
            "Epoch 8823: train loss: 0.5136949419975281\n",
            "Epoch 8824: train loss: 0.5136591196060181\n",
            "Epoch 8825: train loss: 0.5136232376098633\n",
            "Epoch 8826: train loss: 0.5135874152183533\n",
            "Epoch 8827: train loss: 0.513551652431488\n",
            "Epoch 8828: train loss: 0.5135157108306885\n",
            "Epoch 8829: train loss: 0.5134797692298889\n",
            "Epoch 8830: train loss: 0.5134438276290894\n",
            "Epoch 8831: train loss: 0.5134078860282898\n",
            "Epoch 8832: train loss: 0.5133718848228455\n",
            "Epoch 8833: train loss: 0.5133358836174011\n",
            "Epoch 8834: train loss: 0.5132998824119568\n",
            "Epoch 8835: train loss: 0.5132638216018677\n",
            "Epoch 8836: train loss: 0.5132277011871338\n",
            "Epoch 8837: train loss: 0.5131916999816895\n",
            "Epoch 8838: train loss: 0.5131555199623108\n",
            "Epoch 8839: train loss: 0.5131193995475769\n",
            "Epoch 8840: train loss: 0.5130831599235535\n",
            "Epoch 8841: train loss: 0.5130469799041748\n",
            "Epoch 8842: train loss: 0.5130107998847961\n",
            "Epoch 8843: train loss: 0.5129745006561279\n",
            "Epoch 8844: train loss: 0.5129382014274597\n",
            "Epoch 8845: train loss: 0.5129019618034363\n",
            "Epoch 8846: train loss: 0.5128656625747681\n",
            "Epoch 8847: train loss: 0.5128293633460999\n",
            "Epoch 8848: train loss: 0.5127929449081421\n",
            "Epoch 8849: train loss: 0.5127565860748291\n",
            "Epoch 8850: train loss: 0.5127201676368713\n",
            "Epoch 8851: train loss: 0.5126837491989136\n",
            "Epoch 8852: train loss: 0.512647271156311\n",
            "Epoch 8853: train loss: 0.5126107931137085\n",
            "Epoch 8854: train loss: 0.512574315071106\n",
            "Epoch 8855: train loss: 0.5125377774238586\n",
            "Epoch 8856: train loss: 0.5125012397766113\n",
            "Epoch 8857: train loss: 0.5124646425247192\n",
            "Epoch 8858: train loss: 0.5124280452728271\n",
            "Epoch 8859: train loss: 0.5123913884162903\n",
            "Epoch 8860: train loss: 0.5123547315597534\n",
            "Epoch 8861: train loss: 0.5123180747032166\n",
            "Epoch 8862: train loss: 0.5122814178466797\n",
            "Epoch 8863: train loss: 0.5122446417808533\n",
            "Epoch 8864: train loss: 0.5122079253196716\n",
            "Epoch 8865: train loss: 0.5121710896492004\n",
            "Epoch 8866: train loss: 0.512134313583374\n",
            "Epoch 8867: train loss: 0.5120974779129028\n",
            "Epoch 8868: train loss: 0.5120605826377869\n",
            "Epoch 8869: train loss: 0.5120238065719604\n",
            "Epoch 8870: train loss: 0.5119868516921997\n",
            "Epoch 8871: train loss: 0.5119499564170837\n",
            "Epoch 8872: train loss: 0.5119129419326782\n",
            "Epoch 8873: train loss: 0.5118759870529175\n",
            "Epoch 8874: train loss: 0.511838972568512\n",
            "Epoch 8875: train loss: 0.5118020176887512\n",
            "Epoch 8876: train loss: 0.5117649435997009\n",
            "Epoch 8877: train loss: 0.5117278695106506\n",
            "Epoch 8878: train loss: 0.5116907358169556\n",
            "Epoch 8879: train loss: 0.5116536021232605\n",
            "Epoch 8880: train loss: 0.5116164088249207\n",
            "Epoch 8881: train loss: 0.5115793347358704\n",
            "Epoch 8882: train loss: 0.5115420818328857\n",
            "Epoch 8883: train loss: 0.5115048885345459\n",
            "Epoch 8884: train loss: 0.5114676356315613\n",
            "Epoch 8885: train loss: 0.5114303231239319\n",
            "Epoch 8886: train loss: 0.5113930106163025\n",
            "Epoch 8887: train loss: 0.5113556981086731\n",
            "Epoch 8888: train loss: 0.5113183259963989\n",
            "Epoch 8889: train loss: 0.51128089427948\n",
            "Epoch 8890: train loss: 0.5112435221672058\n",
            "Epoch 8891: train loss: 0.5112060308456421\n",
            "Epoch 8892: train loss: 0.5111685991287231\n",
            "Epoch 8893: train loss: 0.5111311078071594\n",
            "Epoch 8894: train loss: 0.5110936164855957\n",
            "Epoch 8895: train loss: 0.5110560059547424\n",
            "Epoch 8896: train loss: 0.5110185146331787\n",
            "Epoch 8897: train loss: 0.5109809041023254\n",
            "Epoch 8898: train loss: 0.5109433531761169\n",
            "Epoch 8899: train loss: 0.5109056830406189\n",
            "Epoch 8900: train loss: 0.5108679533004761\n",
            "Epoch 8901: train loss: 0.510830283164978\n",
            "Epoch 8902: train loss: 0.5107924938201904\n",
            "Epoch 8903: train loss: 0.5107548236846924\n",
            "Epoch 8904: train loss: 0.5107170343399048\n",
            "Epoch 8905: train loss: 0.5106792449951172\n",
            "Epoch 8906: train loss: 0.51064133644104\n",
            "Epoch 8907: train loss: 0.5106034874916077\n",
            "Epoch 8908: train loss: 0.5105656385421753\n",
            "Epoch 8909: train loss: 0.5105277299880981\n",
            "Epoch 8910: train loss: 0.5104897618293762\n",
            "Epoch 8911: train loss: 0.5104517340660095\n",
            "Epoch 8912: train loss: 0.5104137659072876\n",
            "Epoch 8913: train loss: 0.5103757977485657\n",
            "Epoch 8914: train loss: 0.510337769985199\n",
            "Epoch 8915: train loss: 0.5102996826171875\n",
            "Epoch 8916: train loss: 0.510261595249176\n",
            "Epoch 8917: train loss: 0.510223388671875\n",
            "Epoch 8918: train loss: 0.5101853013038635\n",
            "Epoch 8919: train loss: 0.5101470947265625\n",
            "Epoch 8920: train loss: 0.5101088881492615\n",
            "Epoch 8921: train loss: 0.5100706815719604\n",
            "Epoch 8922: train loss: 0.5100323557853699\n",
            "Epoch 8923: train loss: 0.5099940896034241\n",
            "Epoch 8924: train loss: 0.5099557638168335\n",
            "Epoch 8925: train loss: 0.5099174380302429\n",
            "Epoch 8926: train loss: 0.5098790526390076\n",
            "Epoch 8927: train loss: 0.5098406076431274\n",
            "Epoch 8928: train loss: 0.5098021626472473\n",
            "Epoch 8929: train loss: 0.5097637176513672\n",
            "Epoch 8930: train loss: 0.5097252726554871\n",
            "Epoch 8931: train loss: 0.5096867680549622\n",
            "Epoch 8932: train loss: 0.5096482038497925\n",
            "Epoch 8933: train loss: 0.5096096396446228\n",
            "Epoch 8934: train loss: 0.5095710158348083\n",
            "Epoch 8935: train loss: 0.5095323920249939\n",
            "Epoch 8936: train loss: 0.5094937682151794\n",
            "Epoch 8937: train loss: 0.5094550848007202\n",
            "Epoch 8938: train loss: 0.509416401386261\n",
            "Epoch 8939: train loss: 0.5093775987625122\n",
            "Epoch 8940: train loss: 0.5093388557434082\n",
            "Epoch 8941: train loss: 0.5093000531196594\n",
            "Epoch 8942: train loss: 0.5092612504959106\n",
            "Epoch 8943: train loss: 0.5092223882675171\n",
            "Epoch 8944: train loss: 0.5091835260391235\n",
            "Epoch 8945: train loss: 0.5091445446014404\n",
            "Epoch 8946: train loss: 0.5091056227684021\n",
            "Epoch 8947: train loss: 0.509066641330719\n",
            "Epoch 8948: train loss: 0.5090276002883911\n",
            "Epoch 8949: train loss: 0.508988618850708\n",
            "Epoch 8950: train loss: 0.5089495778083801\n",
            "Epoch 8951: train loss: 0.5089104771614075\n",
            "Epoch 8952: train loss: 0.5088713765144348\n",
            "Epoch 8953: train loss: 0.5088322162628174\n",
            "Epoch 8954: train loss: 0.5087930560112\n",
            "Epoch 8955: train loss: 0.5087538361549377\n",
            "Epoch 8956: train loss: 0.5087146162986755\n",
            "Epoch 8957: train loss: 0.5086753368377686\n",
            "Epoch 8958: train loss: 0.5086359977722168\n",
            "Epoch 8959: train loss: 0.5085967183113098\n",
            "Epoch 8960: train loss: 0.5085573792457581\n",
            "Epoch 8961: train loss: 0.5085180401802063\n",
            "Epoch 8962: train loss: 0.508478581905365\n",
            "Epoch 8963: train loss: 0.5084391832351685\n",
            "Epoch 8964: train loss: 0.5083996653556824\n",
            "Epoch 8965: train loss: 0.5083602070808411\n",
            "Epoch 8966: train loss: 0.5083206295967102\n",
            "Epoch 8967: train loss: 0.5082810521125793\n",
            "Epoch 8968: train loss: 0.5082415342330933\n",
            "Epoch 8969: train loss: 0.5082019567489624\n",
            "Epoch 8970: train loss: 0.508162260055542\n",
            "Epoch 8971: train loss: 0.5081225633621216\n",
            "Epoch 8972: train loss: 0.5080828666687012\n",
            "Epoch 8973: train loss: 0.5080431699752808\n",
            "Epoch 8974: train loss: 0.5080034136772156\n",
            "Epoch 8975: train loss: 0.5079635381698608\n",
            "Epoch 8976: train loss: 0.5079237818717957\n",
            "Epoch 8977: train loss: 0.5078839063644409\n",
            "Epoch 8978: train loss: 0.5078440308570862\n",
            "Epoch 8979: train loss: 0.5078040957450867\n",
            "Epoch 8980: train loss: 0.5077641606330872\n",
            "Epoch 8981: train loss: 0.5077241063117981\n",
            "Epoch 8982: train loss: 0.5076841115951538\n",
            "Epoch 8983: train loss: 0.5076441168785095\n",
            "Epoch 8984: train loss: 0.5076040625572205\n",
            "Epoch 8985: train loss: 0.5075639486312866\n",
            "Epoch 8986: train loss: 0.5075238347053528\n",
            "Epoch 8987: train loss: 0.507483720779419\n",
            "Epoch 8988: train loss: 0.5074434280395508\n",
            "Epoch 8989: train loss: 0.5074032545089722\n",
            "Epoch 8990: train loss: 0.5073630213737488\n",
            "Epoch 8991: train loss: 0.5073226690292358\n",
            "Epoch 8992: train loss: 0.5072823166847229\n",
            "Epoch 8993: train loss: 0.5072420239448547\n",
            "Epoch 8994: train loss: 0.5072015523910522\n",
            "Epoch 8995: train loss: 0.5071612000465393\n",
            "Epoch 8996: train loss: 0.5071207880973816\n",
            "Epoch 8997: train loss: 0.5070803165435791\n",
            "Epoch 8998: train loss: 0.5070398449897766\n",
            "Epoch 8999: train loss: 0.5069992542266846\n",
            "Epoch 9000: train loss: 0.5069586634635925\n",
            "Epoch 9001: train loss: 0.5069180727005005\n",
            "Epoch 9002: train loss: 0.5068774819374084\n",
            "Epoch 9003: train loss: 0.5068367719650269\n",
            "Epoch 9004: train loss: 0.5067960619926453\n",
            "Epoch 9005: train loss: 0.5067553520202637\n",
            "Epoch 9006: train loss: 0.5067145824432373\n",
            "Epoch 9007: train loss: 0.5066738128662109\n",
            "Epoch 9008: train loss: 0.5066329836845398\n",
            "Epoch 9009: train loss: 0.5065921545028687\n",
            "Epoch 9010: train loss: 0.506551206111908\n",
            "Epoch 9011: train loss: 0.506510317325592\n",
            "Epoch 9012: train loss: 0.5064693689346313\n",
            "Epoch 9013: train loss: 0.5064284205436707\n",
            "Epoch 9014: train loss: 0.5063873529434204\n",
            "Epoch 9015: train loss: 0.5063462853431702\n",
            "Epoch 9016: train loss: 0.5063051581382751\n",
            "Epoch 9017: train loss: 0.5062640905380249\n",
            "Epoch 9018: train loss: 0.5062229633331299\n",
            "Epoch 9019: train loss: 0.5061817765235901\n",
            "Epoch 9020: train loss: 0.5061405897140503\n",
            "Epoch 9021: train loss: 0.506099283695221\n",
            "Epoch 9022: train loss: 0.5060580968856812\n",
            "Epoch 9023: train loss: 0.506016731262207\n",
            "Epoch 9024: train loss: 0.5059754252433777\n",
            "Epoch 9025: train loss: 0.5059340000152588\n",
            "Epoch 9026: train loss: 0.5058926343917847\n",
            "Epoch 9027: train loss: 0.505851149559021\n",
            "Epoch 9028: train loss: 0.5058097243309021\n",
            "Epoch 9029: train loss: 0.5057681798934937\n",
            "Epoch 9030: train loss: 0.5057266354560852\n",
            "Epoch 9031: train loss: 0.5056850910186768\n",
            "Epoch 9032: train loss: 0.5056434869766235\n",
            "Epoch 9033: train loss: 0.5056018233299255\n",
            "Epoch 9034: train loss: 0.5055601000785828\n",
            "Epoch 9035: train loss: 0.5055184364318848\n",
            "Epoch 9036: train loss: 0.505476713180542\n",
            "Epoch 9037: train loss: 0.5054349899291992\n",
            "Epoch 9038: train loss: 0.5053931474685669\n",
            "Epoch 9039: train loss: 0.5053513050079346\n",
            "Epoch 9040: train loss: 0.5053094029426575\n",
            "Epoch 9041: train loss: 0.5052674412727356\n",
            "Epoch 9042: train loss: 0.5052254796028137\n",
            "Epoch 9043: train loss: 0.5051835179328918\n",
            "Epoch 9044: train loss: 0.50514155626297\n",
            "Epoch 9045: train loss: 0.5050995349884033\n",
            "Epoch 9046: train loss: 0.5050573945045471\n",
            "Epoch 9047: train loss: 0.5050153136253357\n",
            "Epoch 9048: train loss: 0.5049731731414795\n",
            "Epoch 9049: train loss: 0.5049309730529785\n",
            "Epoch 9050: train loss: 0.5048887133598328\n",
            "Epoch 9051: train loss: 0.5048465132713318\n",
            "Epoch 9052: train loss: 0.5048041939735413\n",
            "Epoch 9053: train loss: 0.5047618746757507\n",
            "Epoch 9054: train loss: 0.5047194957733154\n",
            "Epoch 9055: train loss: 0.5046771764755249\n",
            "Epoch 9056: train loss: 0.5046346783638\n",
            "Epoch 9057: train loss: 0.50459223985672\n",
            "Epoch 9058: train loss: 0.5045496821403503\n",
            "Epoch 9059: train loss: 0.5045071840286255\n",
            "Epoch 9060: train loss: 0.5044646263122559\n",
            "Epoch 9061: train loss: 0.5044219493865967\n",
            "Epoch 9062: train loss: 0.504379391670227\n",
            "Epoch 9063: train loss: 0.5043367147445679\n",
            "Epoch 9064: train loss: 0.5042939782142639\n",
            "Epoch 9065: train loss: 0.5042513012886047\n",
            "Epoch 9066: train loss: 0.5042085647583008\n",
            "Epoch 9067: train loss: 0.5041656494140625\n",
            "Epoch 9068: train loss: 0.5041228532791138\n",
            "Epoch 9069: train loss: 0.5040798783302307\n",
            "Epoch 9070: train loss: 0.504037082195282\n",
            "Epoch 9071: train loss: 0.5039940476417542\n",
            "Epoch 9072: train loss: 0.5039511322975159\n",
            "Epoch 9073: train loss: 0.503908097743988\n",
            "Epoch 9074: train loss: 0.5038650035858154\n",
            "Epoch 9075: train loss: 0.503821849822998\n",
            "Epoch 9076: train loss: 0.5037787556648254\n",
            "Epoch 9077: train loss: 0.5037356019020081\n",
            "Epoch 9078: train loss: 0.5036923885345459\n",
            "Epoch 9079: train loss: 0.503649115562439\n",
            "Epoch 9080: train loss: 0.503605842590332\n",
            "Epoch 9081: train loss: 0.5035625696182251\n",
            "Epoch 9082: train loss: 0.5035191774368286\n",
            "Epoch 9083: train loss: 0.5034758448600769\n",
            "Epoch 9084: train loss: 0.5034324526786804\n",
            "Epoch 9085: train loss: 0.5033890008926392\n",
            "Epoch 9086: train loss: 0.5033454298973083\n",
            "Epoch 9087: train loss: 0.5033019185066223\n",
            "Epoch 9088: train loss: 0.5032584071159363\n",
            "Epoch 9089: train loss: 0.5032147765159607\n",
            "Epoch 9090: train loss: 0.5031710863113403\n",
            "Epoch 9091: train loss: 0.5031274557113647\n",
            "Epoch 9092: train loss: 0.5030837655067444\n",
            "Epoch 9093: train loss: 0.5030398964881897\n",
            "Epoch 9094: train loss: 0.5029962062835693\n",
            "Epoch 9095: train loss: 0.5029523968696594\n",
            "Epoch 9096: train loss: 0.5029085278511047\n",
            "Epoch 9097: train loss: 0.5028645992279053\n",
            "Epoch 9098: train loss: 0.5028206706047058\n",
            "Epoch 9099: train loss: 0.5027766227722168\n",
            "Epoch 9100: train loss: 0.5027326941490173\n",
            "Epoch 9101: train loss: 0.5026886463165283\n",
            "Epoch 9102: train loss: 0.5026445388793945\n",
            "Epoch 9103: train loss: 0.502600371837616\n",
            "Epoch 9104: train loss: 0.5025562644004822\n",
            "Epoch 9105: train loss: 0.5025120377540588\n",
            "Epoch 9106: train loss: 0.5024677515029907\n",
            "Epoch 9107: train loss: 0.5024235248565674\n",
            "Epoch 9108: train loss: 0.5023792386054993\n",
            "Epoch 9109: train loss: 0.5023348331451416\n",
            "Epoch 9110: train loss: 0.5022904872894287\n",
            "Epoch 9111: train loss: 0.502246081829071\n",
            "Epoch 9112: train loss: 0.5022016167640686\n",
            "Epoch 9113: train loss: 0.5021570920944214\n",
            "Epoch 9114: train loss: 0.5021125674247742\n",
            "Epoch 9115: train loss: 0.5020679235458374\n",
            "Epoch 9116: train loss: 0.5020233392715454\n",
            "Epoch 9117: train loss: 0.5019786357879639\n",
            "Epoch 9118: train loss: 0.5019339919090271\n",
            "Epoch 9119: train loss: 0.5018892288208008\n",
            "Epoch 9120: train loss: 0.5018444657325745\n",
            "Epoch 9121: train loss: 0.5017997026443481\n",
            "Epoch 9122: train loss: 0.5017548203468323\n",
            "Epoch 9123: train loss: 0.5017099380493164\n",
            "Epoch 9124: train loss: 0.5016649961471558\n",
            "Epoch 9125: train loss: 0.5016200542449951\n",
            "Epoch 9126: train loss: 0.5015749931335449\n",
            "Epoch 9127: train loss: 0.5015299916267395\n",
            "Epoch 9128: train loss: 0.5014849305152893\n",
            "Epoch 9129: train loss: 0.5014398097991943\n",
            "Epoch 9130: train loss: 0.5013946294784546\n",
            "Epoch 9131: train loss: 0.5013494491577148\n",
            "Epoch 9132: train loss: 0.5013041496276855\n",
            "Epoch 9133: train loss: 0.501258909702301\n",
            "Epoch 9134: train loss: 0.5012136101722717\n",
            "Epoch 9135: train loss: 0.5011681914329529\n",
            "Epoch 9136: train loss: 0.5011228322982788\n",
            "Epoch 9137: train loss: 0.5010773539543152\n",
            "Epoch 9138: train loss: 0.5010318756103516\n",
            "Epoch 9139: train loss: 0.5009863972663879\n",
            "Epoch 9140: train loss: 0.5009407997131348\n",
            "Epoch 9141: train loss: 0.5008952617645264\n",
            "Epoch 9142: train loss: 0.5008496642112732\n",
            "Epoch 9143: train loss: 0.5008039474487305\n",
            "Epoch 9144: train loss: 0.5007582306861877\n",
            "Epoch 9145: train loss: 0.5007124543190002\n",
            "Epoch 9146: train loss: 0.5006666779518127\n",
            "Epoch 9147: train loss: 0.5006208419799805\n",
            "Epoch 9148: train loss: 0.5005749464035034\n",
            "Epoch 9149: train loss: 0.5005290508270264\n",
            "Epoch 9150: train loss: 0.5004830956459045\n",
            "Epoch 9151: train loss: 0.5004370808601379\n",
            "Epoch 9152: train loss: 0.5003910064697266\n",
            "Epoch 9153: train loss: 0.5003449320793152\n",
            "Epoch 9154: train loss: 0.500298798084259\n",
            "Epoch 9155: train loss: 0.5002526640892029\n",
            "Epoch 9156: train loss: 0.500206470489502\n",
            "Epoch 9157: train loss: 0.5001602172851562\n",
            "Epoch 9158: train loss: 0.5001139044761658\n",
            "Epoch 9159: train loss: 0.5000676512718201\n",
            "Epoch 9160: train loss: 0.50002121925354\n",
            "Epoch 9161: train loss: 0.4999748468399048\n",
            "Epoch 9162: train loss: 0.49992838501930237\n",
            "Epoch 9163: train loss: 0.49988192319869995\n",
            "Epoch 9164: train loss: 0.49983540177345276\n",
            "Epoch 9165: train loss: 0.499788761138916\n",
            "Epoch 9166: train loss: 0.49974215030670166\n",
            "Epoch 9167: train loss: 0.4996955096721649\n",
            "Epoch 9168: train loss: 0.4996488094329834\n",
            "Epoch 9169: train loss: 0.4996020793914795\n",
            "Epoch 9170: train loss: 0.49955523014068604\n",
            "Epoch 9171: train loss: 0.49950841069221497\n",
            "Epoch 9172: train loss: 0.4994615614414215\n",
            "Epoch 9173: train loss: 0.4994146525859833\n",
            "Epoch 9174: train loss: 0.49936768412590027\n",
            "Epoch 9175: train loss: 0.49932074546813965\n",
            "Epoch 9176: train loss: 0.4992736279964447\n",
            "Epoch 9177: train loss: 0.4992266297340393\n",
            "Epoch 9178: train loss: 0.49917951226234436\n",
            "Epoch 9179: train loss: 0.49913230538368225\n",
            "Epoch 9180: train loss: 0.49908509850502014\n",
            "Epoch 9181: train loss: 0.49903783202171326\n",
            "Epoch 9182: train loss: 0.498990535736084\n",
            "Epoch 9183: train loss: 0.49894315004348755\n",
            "Epoch 9184: train loss: 0.49889591336250305\n",
            "Epoch 9185: train loss: 0.49884840846061707\n",
            "Epoch 9186: train loss: 0.49880093336105347\n",
            "Epoch 9187: train loss: 0.49875345826148987\n",
            "Epoch 9188: train loss: 0.4987058937549591\n",
            "Epoch 9189: train loss: 0.49865835905075073\n",
            "Epoch 9190: train loss: 0.4986107051372528\n",
            "Epoch 9191: train loss: 0.4985630512237549\n",
            "Epoch 9192: train loss: 0.4985153377056122\n",
            "Epoch 9193: train loss: 0.4984675645828247\n",
            "Epoch 9194: train loss: 0.49841976165771484\n",
            "Epoch 9195: train loss: 0.4983718693256378\n",
            "Epoch 9196: train loss: 0.49832403659820557\n",
            "Epoch 9197: train loss: 0.4982760548591614\n",
            "Epoch 9198: train loss: 0.4982281029224396\n",
            "Epoch 9199: train loss: 0.498180091381073\n",
            "Epoch 9200: train loss: 0.49813205003738403\n",
            "Epoch 9201: train loss: 0.4980838894844055\n",
            "Epoch 9202: train loss: 0.4980357587337494\n",
            "Epoch 9203: train loss: 0.4979875385761261\n",
            "Epoch 9204: train loss: 0.4979393184185028\n",
            "Epoch 9205: train loss: 0.49789097905158997\n",
            "Epoch 9206: train loss: 0.4978426992893219\n",
            "Epoch 9207: train loss: 0.4977943003177643\n",
            "Epoch 9208: train loss: 0.49774590134620667\n",
            "Epoch 9209: train loss: 0.49769747257232666\n",
            "Epoch 9210: train loss: 0.4976489543914795\n",
            "Epoch 9211: train loss: 0.49760037660598755\n",
            "Epoch 9212: train loss: 0.497551828622818\n",
            "Epoch 9213: train loss: 0.4975031316280365\n",
            "Epoch 9214: train loss: 0.4974544644355774\n",
            "Epoch 9215: train loss: 0.4974057078361511\n",
            "Epoch 9216: train loss: 0.49735692143440247\n",
            "Epoch 9217: train loss: 0.4973081350326538\n",
            "Epoch 9218: train loss: 0.4972592890262604\n",
            "Epoch 9219: train loss: 0.49721038341522217\n",
            "Epoch 9220: train loss: 0.4971614181995392\n",
            "Epoch 9221: train loss: 0.4971124529838562\n",
            "Epoch 9222: train loss: 0.4970633089542389\n",
            "Epoch 9223: train loss: 0.49701422452926636\n",
            "Epoch 9224: train loss: 0.4969651401042938\n",
            "Epoch 9225: train loss: 0.4969159662723541\n",
            "Epoch 9226: train loss: 0.49686670303344727\n",
            "Epoch 9227: train loss: 0.496817409992218\n",
            "Epoch 9228: train loss: 0.4967680871486664\n",
            "Epoch 9229: train loss: 0.49671879410743713\n",
            "Epoch 9230: train loss: 0.49666938185691833\n",
            "Epoch 9231: train loss: 0.4966198801994324\n",
            "Epoch 9232: train loss: 0.4965704083442688\n",
            "Epoch 9233: train loss: 0.4965208172798157\n",
            "Epoch 9234: train loss: 0.49647122621536255\n",
            "Epoch 9235: train loss: 0.49642157554626465\n",
            "Epoch 9236: train loss: 0.49637192487716675\n",
            "Epoch 9237: train loss: 0.4963221848011017\n",
            "Epoch 9238: train loss: 0.49627241492271423\n",
            "Epoch 9239: train loss: 0.496222585439682\n",
            "Epoch 9240: train loss: 0.4961727261543274\n",
            "Epoch 9241: train loss: 0.4961227774620056\n",
            "Epoch 9242: train loss: 0.4960728585720062\n",
            "Epoch 9243: train loss: 0.4960228502750397\n",
            "Epoch 9244: train loss: 0.49597281217575073\n",
            "Epoch 9245: train loss: 0.49592265486717224\n",
            "Epoch 9246: train loss: 0.49587249755859375\n",
            "Epoch 9247: train loss: 0.49582234025001526\n",
            "Epoch 9248: train loss: 0.4957720637321472\n",
            "Epoch 9249: train loss: 0.4957217872142792\n",
            "Epoch 9250: train loss: 0.49567145109176636\n",
            "Epoch 9251: train loss: 0.4956210255622864\n",
            "Epoch 9252: train loss: 0.4955706298351288\n",
            "Epoch 9253: train loss: 0.49552011489868164\n",
            "Epoch 9254: train loss: 0.4954696297645569\n",
            "Epoch 9255: train loss: 0.49541905522346497\n",
            "Epoch 9256: train loss: 0.49536845088005066\n",
            "Epoch 9257: train loss: 0.4953177869319916\n",
            "Epoch 9258: train loss: 0.49526703357696533\n",
            "Epoch 9259: train loss: 0.4952162504196167\n",
            "Epoch 9260: train loss: 0.49516546726226807\n",
            "Epoch 9261: train loss: 0.4951145648956299\n",
            "Epoch 9262: train loss: 0.4950636625289917\n",
            "Epoch 9263: train loss: 0.49501270055770874\n",
            "Epoch 9264: train loss: 0.4949616491794586\n",
            "Epoch 9265: train loss: 0.4949106276035309\n",
            "Epoch 9266: train loss: 0.49485960602760315\n",
            "Epoch 9267: train loss: 0.4948084354400635\n",
            "Epoch 9268: train loss: 0.4947572350502014\n",
            "Epoch 9269: train loss: 0.4947059452533722\n",
            "Epoch 9270: train loss: 0.49465468525886536\n",
            "Epoch 9271: train loss: 0.4946032762527466\n",
            "Epoch 9272: train loss: 0.4945519268512726\n",
            "Epoch 9273: train loss: 0.4945005178451538\n",
            "Epoch 9274: train loss: 0.4944489896297455\n",
            "Epoch 9275: train loss: 0.4943974018096924\n",
            "Epoch 9276: train loss: 0.4943458139896393\n",
            "Epoch 9277: train loss: 0.4942942261695862\n",
            "Epoch 9278: train loss: 0.4942425489425659\n",
            "Epoch 9279: train loss: 0.4941907227039337\n",
            "Epoch 9280: train loss: 0.4941389858722687\n",
            "Epoch 9281: train loss: 0.4940871596336365\n",
            "Epoch 9282: train loss: 0.4940353035926819\n",
            "Epoch 9283: train loss: 0.49398329854011536\n",
            "Epoch 9284: train loss: 0.4939313232898712\n",
            "Epoch 9285: train loss: 0.4938793480396271\n",
            "Epoch 9286: train loss: 0.4938272535800934\n",
            "Epoch 9287: train loss: 0.4937750995159149\n",
            "Epoch 9288: train loss: 0.49372294545173645\n",
            "Epoch 9289: train loss: 0.4936707317829132\n",
            "Epoch 9290: train loss: 0.4936184585094452\n",
            "Epoch 9291: train loss: 0.4935661554336548\n",
            "Epoch 9292: train loss: 0.49351370334625244\n",
            "Epoch 9293: train loss: 0.4934612810611725\n",
            "Epoch 9294: train loss: 0.49340876936912537\n",
            "Epoch 9295: train loss: 0.49335628747940063\n",
            "Epoch 9296: train loss: 0.49330371618270874\n",
            "Epoch 9297: train loss: 0.4932510554790497\n",
            "Epoch 9298: train loss: 0.49319833517074585\n",
            "Epoch 9299: train loss: 0.493145614862442\n",
            "Epoch 9300: train loss: 0.4930928349494934\n",
            "Epoch 9301: train loss: 0.4930399954319\n",
            "Epoch 9302: train loss: 0.49298715591430664\n",
            "Epoch 9303: train loss: 0.4929341673851013\n",
            "Epoch 9304: train loss: 0.49288126826286316\n",
            "Epoch 9305: train loss: 0.4928281307220459\n",
            "Epoch 9306: train loss: 0.4927750825881958\n",
            "Epoch 9307: train loss: 0.49272194504737854\n",
            "Epoch 9308: train loss: 0.4926687777042389\n",
            "Epoch 9309: train loss: 0.49261555075645447\n",
            "Epoch 9310: train loss: 0.49256226420402527\n",
            "Epoch 9311: train loss: 0.4925088584423065\n",
            "Epoch 9312: train loss: 0.49245548248291016\n",
            "Epoch 9313: train loss: 0.492402046918869\n",
            "Epoch 9314: train loss: 0.4923485219478607\n",
            "Epoch 9315: train loss: 0.4922949969768524\n",
            "Epoch 9316: train loss: 0.49224135279655457\n",
            "Epoch 9317: train loss: 0.4921877384185791\n",
            "Epoch 9318: train loss: 0.4921339750289917\n",
            "Epoch 9319: train loss: 0.4920802414417267\n",
            "Epoch 9320: train loss: 0.4920264184474945\n",
            "Epoch 9321: train loss: 0.49197256565093994\n",
            "Epoch 9322: train loss: 0.4919187128543854\n",
            "Epoch 9323: train loss: 0.4918646812438965\n",
            "Epoch 9324: train loss: 0.4918106496334076\n",
            "Epoch 9325: train loss: 0.4917566180229187\n",
            "Epoch 9326: train loss: 0.49170246720314026\n",
            "Epoch 9327: train loss: 0.4916483163833618\n",
            "Epoch 9328: train loss: 0.4915941059589386\n",
            "Epoch 9329: train loss: 0.4915398061275482\n",
            "Epoch 9330: train loss: 0.49148547649383545\n",
            "Epoch 9331: train loss: 0.4914310574531555\n",
            "Epoch 9332: train loss: 0.4913766086101532\n",
            "Epoch 9333: train loss: 0.4913220703601837\n",
            "Epoch 9334: train loss: 0.491267591714859\n",
            "Epoch 9335: train loss: 0.49121299386024475\n",
            "Epoch 9336: train loss: 0.4911583364009857\n",
            "Epoch 9337: train loss: 0.4911036193370819\n",
            "Epoch 9338: train loss: 0.49104878306388855\n",
            "Epoch 9339: train loss: 0.49099400639533997\n",
            "Epoch 9340: train loss: 0.4909391403198242\n",
            "Epoch 9341: train loss: 0.4908842444419861\n",
            "Epoch 9342: train loss: 0.4908292889595032\n",
            "Epoch 9343: train loss: 0.4907742440700531\n",
            "Epoch 9344: train loss: 0.49071913957595825\n",
            "Epoch 9345: train loss: 0.490664005279541\n",
            "Epoch 9346: train loss: 0.4906088411808014\n",
            "Epoch 9347: train loss: 0.4905535578727722\n",
            "Epoch 9348: train loss: 0.4904983341693878\n",
            "Epoch 9349: train loss: 0.4904429316520691\n",
            "Epoch 9350: train loss: 0.49038752913475037\n",
            "Epoch 9351: train loss: 0.49033206701278687\n",
            "Epoch 9352: train loss: 0.490276575088501\n",
            "Epoch 9353: train loss: 0.4902209937572479\n",
            "Epoch 9354: train loss: 0.4901653826236725\n",
            "Epoch 9355: train loss: 0.4901096820831299\n",
            "Epoch 9356: train loss: 0.4900539517402649\n",
            "Epoch 9357: train loss: 0.4899981915950775\n",
            "Epoch 9358: train loss: 0.489942342042923\n",
            "Epoch 9359: train loss: 0.4898863732814789\n",
            "Epoch 9360: train loss: 0.48983046412467957\n",
            "Epoch 9361: train loss: 0.4897744953632355\n",
            "Epoch 9362: train loss: 0.4897184371948242\n",
            "Epoch 9363: train loss: 0.4896622896194458\n",
            "Epoch 9364: train loss: 0.4896061420440674\n",
            "Epoch 9365: train loss: 0.4895499646663666\n",
            "Epoch 9366: train loss: 0.48949357867240906\n",
            "Epoch 9367: train loss: 0.4894372820854187\n",
            "Epoch 9368: train loss: 0.4893808960914612\n",
            "Epoch 9369: train loss: 0.4893244206905365\n",
            "Epoch 9370: train loss: 0.4892679452896118\n",
            "Epoch 9371: train loss: 0.48921141028404236\n",
            "Epoch 9372: train loss: 0.48915475606918335\n",
            "Epoch 9373: train loss: 0.48909804224967957\n",
            "Epoch 9374: train loss: 0.4890413284301758\n",
            "Epoch 9375: train loss: 0.48898452520370483\n",
            "Epoch 9376: train loss: 0.4889276921749115\n",
            "Epoch 9377: train loss: 0.4888708293437958\n",
            "Epoch 9378: train loss: 0.4888138771057129\n",
            "Epoch 9379: train loss: 0.48875683546066284\n",
            "Epoch 9380: train loss: 0.4886997938156128\n",
            "Epoch 9381: train loss: 0.48864269256591797\n",
            "Epoch 9382: train loss: 0.488585501909256\n",
            "Epoch 9383: train loss: 0.4885282516479492\n",
            "Epoch 9384: train loss: 0.48847097158432007\n",
            "Epoch 9385: train loss: 0.48841363191604614\n",
            "Epoch 9386: train loss: 0.48835623264312744\n",
            "Epoch 9387: train loss: 0.4882987439632416\n",
            "Epoch 9388: train loss: 0.4882412254810333\n",
            "Epoch 9389: train loss: 0.4881837069988251\n",
            "Epoch 9390: train loss: 0.4881259799003601\n",
            "Epoch 9391: train loss: 0.4880683720111847\n",
            "Epoch 9392: train loss: 0.4880106449127197\n",
            "Epoch 9393: train loss: 0.4879527986049652\n",
            "Epoch 9394: train loss: 0.4878949522972107\n",
            "Epoch 9395: train loss: 0.4878370463848114\n",
            "Epoch 9396: train loss: 0.48777902126312256\n",
            "Epoch 9397: train loss: 0.4877209961414337\n",
            "Epoch 9398: train loss: 0.4876629412174225\n",
            "Epoch 9399: train loss: 0.4876047372817993\n",
            "Epoch 9400: train loss: 0.48754656314849854\n",
            "Epoch 9401: train loss: 0.4874882996082306\n",
            "Epoch 9402: train loss: 0.4874299466609955\n",
            "Epoch 9403: train loss: 0.4873715937137604\n",
            "Epoch 9404: train loss: 0.4873131215572357\n",
            "Epoch 9405: train loss: 0.4872545897960663\n",
            "Epoch 9406: train loss: 0.48719605803489685\n",
            "Epoch 9407: train loss: 0.48713746666908264\n",
            "Epoch 9408: train loss: 0.4870787560939789\n",
            "Epoch 9409: train loss: 0.4870200753211975\n",
            "Epoch 9410: train loss: 0.486961305141449\n",
            "Epoch 9411: train loss: 0.4869023859500885\n",
            "Epoch 9412: train loss: 0.4868434965610504\n",
            "Epoch 9413: train loss: 0.48678451776504517\n",
            "Epoch 9414: train loss: 0.48672547936439514\n",
            "Epoch 9415: train loss: 0.4866664409637451\n",
            "Epoch 9416: train loss: 0.48660728335380554\n",
            "Epoch 9417: train loss: 0.4865480661392212\n",
            "Epoch 9418: train loss: 0.48648878931999207\n",
            "Epoch 9419: train loss: 0.4864295423030853\n",
            "Epoch 9420: train loss: 0.48637014627456665\n",
            "Epoch 9421: train loss: 0.4863106906414032\n",
            "Epoch 9422: train loss: 0.48625120520591736\n",
            "Epoch 9423: train loss: 0.48619166016578674\n",
            "Epoch 9424: train loss: 0.48613202571868896\n",
            "Epoch 9425: train loss: 0.486072301864624\n",
            "Epoch 9426: train loss: 0.48601263761520386\n",
            "Epoch 9427: train loss: 0.48595279455184937\n",
            "Epoch 9428: train loss: 0.4858929514884949\n",
            "Epoch 9429: train loss: 0.4858330190181732\n",
            "Epoch 9430: train loss: 0.4857730567455292\n",
            "Epoch 9431: train loss: 0.48571303486824036\n",
            "Epoch 9432: train loss: 0.48565298318862915\n",
            "Epoch 9433: train loss: 0.4855928122997284\n",
            "Epoch 9434: train loss: 0.4855325520038605\n",
            "Epoch 9435: train loss: 0.48547226190567017\n",
            "Epoch 9436: train loss: 0.4854119122028351\n",
            "Epoch 9437: train loss: 0.4853515625\n",
            "Epoch 9438: train loss: 0.48529109358787537\n",
            "Epoch 9439: train loss: 0.48523056507110596\n",
            "Epoch 9440: train loss: 0.48517000675201416\n",
            "Epoch 9441: train loss: 0.4851093590259552\n",
            "Epoch 9442: train loss: 0.48504865169525146\n",
            "Epoch 9443: train loss: 0.48498785495758057\n",
            "Epoch 9444: train loss: 0.48492705821990967\n",
            "Epoch 9445: train loss: 0.4848661720752716\n",
            "Epoch 9446: train loss: 0.48480525612831116\n",
            "Epoch 9447: train loss: 0.48474422097206116\n",
            "Epoch 9448: train loss: 0.4846831262111664\n",
            "Epoch 9449: train loss: 0.4846220016479492\n",
            "Epoch 9450: train loss: 0.48456084728240967\n",
            "Epoch 9451: train loss: 0.48449957370758057\n",
            "Epoch 9452: train loss: 0.4844382703304291\n",
            "Epoch 9453: train loss: 0.4843769371509552\n",
            "Epoch 9454: train loss: 0.48431551456451416\n",
            "Epoch 9455: train loss: 0.48425400257110596\n",
            "Epoch 9456: train loss: 0.4841924011707306\n",
            "Epoch 9457: train loss: 0.4841307997703552\n",
            "Epoch 9458: train loss: 0.4840691387653351\n",
            "Epoch 9459: train loss: 0.4840073585510254\n",
            "Epoch 9460: train loss: 0.48394548892974854\n",
            "Epoch 9461: train loss: 0.48388370871543884\n",
            "Epoch 9462: train loss: 0.4838217496871948\n",
            "Epoch 9463: train loss: 0.4837597608566284\n",
            "Epoch 9464: train loss: 0.48369768261909485\n",
            "Epoch 9465: train loss: 0.4836355745792389\n",
            "Epoch 9466: train loss: 0.48357340693473816\n",
            "Epoch 9467: train loss: 0.48351117968559265\n",
            "Epoch 9468: train loss: 0.4834488332271576\n",
            "Epoch 9469: train loss: 0.48338648676872253\n",
            "Epoch 9470: train loss: 0.4833240807056427\n",
            "Epoch 9471: train loss: 0.4832615554332733\n",
            "Epoch 9472: train loss: 0.48319894075393677\n",
            "Epoch 9473: train loss: 0.4831363558769226\n",
            "Epoch 9474: train loss: 0.4830736815929413\n",
            "Epoch 9475: train loss: 0.4830109179019928\n",
            "Epoch 9476: train loss: 0.48294806480407715\n",
            "Epoch 9477: train loss: 0.4828851521015167\n",
            "Epoch 9478: train loss: 0.4828222393989563\n",
            "Epoch 9479: train loss: 0.4827592670917511\n",
            "Epoch 9480: train loss: 0.48269620537757874\n",
            "Epoch 9481: train loss: 0.482633113861084\n",
            "Epoch 9482: train loss: 0.4825699031352997\n",
            "Epoch 9483: train loss: 0.4825066030025482\n",
            "Epoch 9484: train loss: 0.48244327306747437\n",
            "Epoch 9485: train loss: 0.4823799133300781\n",
            "Epoch 9486: train loss: 0.48231643438339233\n",
            "Epoch 9487: train loss: 0.48225289583206177\n",
            "Epoch 9488: train loss: 0.4821893572807312\n",
            "Epoch 9489: train loss: 0.4821256995201111\n",
            "Epoch 9490: train loss: 0.48206204175949097\n",
            "Epoch 9491: train loss: 0.4819982647895813\n",
            "Epoch 9492: train loss: 0.48193439841270447\n",
            "Epoch 9493: train loss: 0.48187050223350525\n",
            "Epoch 9494: train loss: 0.48180657625198364\n",
            "Epoch 9495: train loss: 0.4817425310611725\n",
            "Epoch 9496: train loss: 0.48167839646339417\n",
            "Epoch 9497: train loss: 0.48161423206329346\n",
            "Epoch 9498: train loss: 0.48155006766319275\n",
            "Epoch 9499: train loss: 0.4814857244491577\n",
            "Epoch 9500: train loss: 0.48142141103744507\n",
            "Epoch 9501: train loss: 0.4813569486141205\n",
            "Epoch 9502: train loss: 0.4812924861907959\n",
            "Epoch 9503: train loss: 0.48122793436050415\n",
            "Epoch 9504: train loss: 0.48116335272789\n",
            "Epoch 9505: train loss: 0.48109862208366394\n",
            "Epoch 9506: train loss: 0.4810338318347931\n",
            "Epoch 9507: train loss: 0.480969101190567\n",
            "Epoch 9508: train loss: 0.4809041917324066\n",
            "Epoch 9509: train loss: 0.4808392822742462\n",
            "Epoch 9510: train loss: 0.48077425360679626\n",
            "Epoch 9511: train loss: 0.4807092547416687\n",
            "Epoch 9512: train loss: 0.4806440472602844\n",
            "Epoch 9513: train loss: 0.48057886958122253\n",
            "Epoch 9514: train loss: 0.4805135726928711\n",
            "Epoch 9515: train loss: 0.48044824600219727\n",
            "Epoch 9516: train loss: 0.4803828299045563\n",
            "Epoch 9517: train loss: 0.4803173542022705\n",
            "Epoch 9518: train loss: 0.48025187849998474\n",
            "Epoch 9519: train loss: 0.48018622398376465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate"
      ],
      "metadata": {
        "id": "shNvJl8XF6KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() #set model to eval mode\n",
        "\n",
        "#train\n",
        "y_pred = model(X_train) #predict\n",
        "y_pred=(y_pred>0.5).int().flatten() #argmax class lable\n",
        "train_acc =torch.sum(y_pred == y_train.int())/ y_train.shape[0]\n",
        "print(\"train ACC: \",train_acc.float())"
      ],
      "metadata": {
        "id": "FqZLDUM-F5Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "y_pred = model(X_test) #predict\n",
        "y_pred=(y_pred>0.5).int().flatten() #argmax class lable\n",
        "test_acc = torch.sum(y_pred == y_test.int()) / y_test.shape[0]\n",
        "print(\"test ACC: \",test_acc.float())"
      ],
      "metadata": {
        "id": "pUS31BcbJo2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_test[:,0],X_test[:,1],c=y_pred)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "zZXHg6eHJs0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Assignment_Basic_MLP_in_Pytorch.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}